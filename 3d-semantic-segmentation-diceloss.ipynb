{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dd7bbbc",
   "metadata": {
    "papermill": {
     "duration": 0.008966,
     "end_time": "2024-08-30T14:05:36.183103",
     "exception": false,
     "start_time": "2024-08-30T14:05:36.174137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3D Cervical Vertebrae Segmentation (RSNA 2022) with MONAI\n",
    "\n",
    "---\n",
    "\n",
    "The aim of this notebook is to perform 3D semantic segmentation on CT scan provided by Radiological Society of North America during the past kaggle's competition RSNA 2022 targeting cervical vertebrae.\n",
    "\n",
    "We will explit [MONAI](https://monai.io/) library to import 3D UNet Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7f9ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:05:36.201752Z",
     "iopub.status.busy": "2024-08-30T14:05:36.201161Z",
     "iopub.status.idle": "2024-08-30T14:06:29.257818Z",
     "shell.execute_reply": "2024-08-30T14:06:29.256720Z"
    },
    "papermill": {
     "duration": 53.068458,
     "end_time": "2024-08-30T14:06:29.260165",
     "exception": false,
     "start_time": "2024-08-30T14:05:36.191707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-gdcm\r\n",
      "  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\r\n",
      "Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: python-gdcm\r\n",
      "Successfully installed python-gdcm-3.0.24.1\r\n",
      "Collecting pylibjpeg\r\n",
      "  Downloading pylibjpeg-2.0.1-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting pylibjpeg-libjpeg\r\n",
      "  Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.10/site-packages (2.4.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pylibjpeg) (1.26.4)\r\n",
      "Downloading pylibjpeg-2.0.1-py3-none-any.whl (24 kB)\r\n",
      "Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pylibjpeg-libjpeg, pylibjpeg\r\n",
      "Successfully installed pylibjpeg-2.0.1 pylibjpeg-libjpeg-2.2.0\r\n",
      "Collecting pyjpegls\r\n",
      "  Downloading pyjpegls-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.10/site-packages (from pyjpegls) (1.26.4)\r\n",
      "Downloading pyjpegls-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pyjpegls\r\n",
      "Successfully installed pyjpegls-1.4.0\r\n",
      "Collecting monai\r\n",
      "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\r\n",
      "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: monai\r\n",
      "Successfully installed monai-1.3.2\r\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "! pip install python-gdcm\n",
    "! pip install pylibjpeg pylibjpeg-libjpeg pydicom\n",
    "! pip install pyjpegls\n",
    "! pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f01e1b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:06:29.285021Z",
     "iopub.status.busy": "2024-08-30T14:06:29.284705Z",
     "iopub.status.idle": "2024-08-30T14:07:10.795394Z",
     "shell.execute_reply": "2024-08-30T14:07:10.794431Z"
    },
    "papermill": {
     "duration": 41.525618,
     "end_time": "2024-08-30T14:07:10.797755",
     "exception": false,
     "start_time": "2024-08-30T14:06:29.272137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 14:07:01.768090: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-30 14:07:01.768231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-30 14:07:01.898180: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# DICOM image files (.dcm)\n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "\n",
    "# NIfTI image files (.nii)\n",
    "import nibabel as nib\n",
    "\n",
    "# Required dependencies\n",
    "import gdcm\n",
    "import pylibjpeg\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "# Monai\n",
    "import monai\n",
    "from monai.data import ArrayDataset, DataLoader, decollate_batch\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    "    RandFlip,\n",
    "    RandAffine,\n",
    "    RandGridDistortion\n",
    ")\n",
    "from monai.utils import set_determinism, first\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1136c",
   "metadata": {
    "papermill": {
     "duration": 0.011333,
     "end_time": "2024-08-30T14:07:10.820968",
     "exception": false,
     "start_time": "2024-08-30T14:07:10.809635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set Up & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78b68a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:10.846851Z",
     "iopub.status.busy": "2024-08-30T14:07:10.846207Z",
     "iopub.status.idle": "2024-08-30T14:07:10.853515Z",
     "shell.execute_reply": "2024-08-30T14:07:10.852663Z"
    },
    "papermill": {
     "duration": 0.021819,
     "end_time": "2024-08-30T14:07:10.855649",
     "exception": false,
     "start_time": "2024-08-30T14:07:10.833830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT7359RN\n"
     ]
    }
   ],
   "source": [
    "def generate_id():\n",
    "    '''\n",
    "    Generate Notebook ID\n",
    "    '''\n",
    "    letters = string.ascii_uppercase  # Uppercase letters A-Z\n",
    "    digits = string.digits  # Digits 0-9\n",
    "    start_letters = ''.join(random.choice(letters) for _ in range(2))\n",
    "    middle_digits = ''.join(random.choice(digits) for _ in range(4))\n",
    "    end_letters = ''.join(random.choice(letters) for _ in range(2))\n",
    "    id_number = start_letters + middle_digits + end_letters\n",
    "    return id_number\n",
    "\n",
    "# Generate Notebook ID\n",
    "ID = generate_id()\n",
    "print(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba30139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:10.879846Z",
     "iopub.status.busy": "2024-08-30T14:07:10.879577Z",
     "iopub.status.idle": "2024-08-30T14:07:10.885721Z",
     "shell.execute_reply": "2024-08-30T14:07:10.884895Z"
    },
    "papermill": {
     "duration": 0.020336,
     "end_time": "2024-08-30T14:07:10.887612",
     "exception": false,
     "start_time": "2024-08-30T14:07:10.867276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3591eff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:10.911833Z",
     "iopub.status.busy": "2024-08-30T14:07:10.911591Z",
     "iopub.status.idle": "2024-08-30T14:07:10.918990Z",
     "shell.execute_reply": "2024-08-30T14:07:10.918221Z"
    },
    "papermill": {
     "duration": 0.021807,
     "end_time": "2024-08-30T14:07:10.920883",
     "exception": false,
     "start_time": "2024-08-30T14:07:10.899076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Paths\n",
    "base_path = \"../input/rsna-2022-cervical-spine-fracture-detection\"\n",
    "TRAIN_IMAGES_PATH = f'{base_path}/train_images'\n",
    "SEGMENTATIONS_PATH = f'{base_path}/segmentations'\n",
    "OUTPUT_DIR = '.'\n",
    "OUTPUT_FILE = OUTPUT_DIR + f'/{ID}_train_val_losses.csv'\n",
    "CONFIG_FILE = OUTPUT_DIR + f'/{ID}_config.pkl'\n",
    "\n",
    "# Masks to be reverted \n",
    "revert_mask = [\n",
    "    '1.2.826.0.1.3680043.1363',\n",
    "    '1.2.826.0.1.3680043.20120',\n",
    "    '1.2.826.0.1.3680043.2243',\n",
    "    '1.2.826.0.1.3680043.24606',\n",
    "    '1.2.826.0.1.3680043.32071'\n",
    "    ]\n",
    "\n",
    "\n",
    "# Dictionary to store configuration of training and model architecture\n",
    "config = {\n",
    "    'ID' : ID,\n",
    "    # Data Preprocessing params\n",
    "    'spatial_size' : (128, 128, 128), # Target spatial size of the volume (CT scan & segmentation masks)\n",
    "    'prob' : 0.5, # Probability of applying the augmentation technique\n",
    "    'k' : 5, # Number of folders for K-fold\n",
    "     # Training Params\n",
    "    'batch_size' : 4, \n",
    "    'epochs' : 80, \n",
    "    'lr' : 1e-4,\n",
    "    'loss_weights' : (0.0, 1.0),\n",
    "    # Model Architecture Params\n",
    "    'channels' : (16, 32, 64, 128, 256), # Channels per layer\n",
    "    'strides' : (2, 2, 2, 2), # Stride per layers\n",
    "    'kernel_size' : 3, # Size of the kernel for each layer\n",
    "    'up_kernel_size' : 3,\n",
    "    'num_res_units' : 2, # Number of residual units\n",
    "    'act' : 'PRELU', # Activation function\n",
    "    'dropout' : 0.0, # Dropout rate #0.2\n",
    "    'bias' : True,\n",
    "    # K-Fold\n",
    "    'val_fold_idx' : 1 # Validation index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b42413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:10.944831Z",
     "iopub.status.busy": "2024-08-30T14:07:10.944571Z",
     "iopub.status.idle": "2024-08-30T14:07:11.049463Z",
     "shell.execute_reply": "2024-08-30T14:07:11.048441Z"
    },
    "papermill": {
     "duration": 0.119133,
     "end_time": "2024-08-30T14:07:11.051494",
     "exception": false,
     "start_time": "2024-08-30T14:07:10.932361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4 is available.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Enabling GPU\n",
    "# https://www.kaggle.com/dansbecker/running-kaggle-kernels-with-a-gpu\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "    \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# Enable cuDNN benchmark. Set to True whenever the input model does not change over training, False if, eg, some layers are deactivated\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a93820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.076821Z",
     "iopub.status.busy": "2024-08-30T14:07:11.076506Z",
     "iopub.status.idle": "2024-08-30T14:07:11.080838Z",
     "shell.execute_reply": "2024-08-30T14:07:11.080030Z"
    },
    "papermill": {
     "duration": 0.019258,
     "end_time": "2024-08-30T14:07:11.082616",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.063358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save config to pickle file\n",
    "with open(CONFIG_FILE, 'wb') as f:\n",
    "    pickle.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd79174",
   "metadata": {
    "papermill": {
     "duration": 0.011446,
     "end_time": "2024-08-30T14:07:11.105658",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.094212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00363b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.130236Z",
     "iopub.status.busy": "2024-08-30T14:07:11.129933Z",
     "iopub.status.idle": "2024-08-30T14:07:11.462879Z",
     "shell.execute_reply": "2024-08-30T14:07:11.462147Z"
    },
    "papermill": {
     "duration": 0.347448,
     "end_time": "2024-08-30T14:07:11.464926",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.117478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dicom_scan(folder_path):\n",
    "    \"\"\" Read CT scan (dicom files) and stack the slices\"\"\"\n",
    "    slices = []\n",
    "    for filename in sorted(os.listdir(folder_path), key=lambda x: int(x.split(\".\")[0])):\n",
    "        if filename.endswith('.dcm'):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            ds = pydicom.dcmread(filepath)\n",
    "            slices.append(ds.pixel_array)\n",
    "    scan = np.stack(slices, -1).astype('float64')\n",
    "    return scan\n",
    "\n",
    "\n",
    "def read_nifti_file(file_path, revert_mask=revert_mask):\n",
    "    \"\"\" Read nifit file segmentation\"\"\"    \n",
    "    data = nib.load(file_path).get_fdata()\n",
    "    shape = data.shape\n",
    "    # Reorient because segmentations are done over the sagittal plane\n",
    "    data = data.transpose(1, 0, 2)[::-1, :, ::-1]\n",
    "    # Revert the files that have inverted sequence (from bottom to top)\n",
    "    if file_path in revert_mask:\n",
    "        data[:, :, ::-1]\n",
    "    return data\n",
    "\n",
    "\n",
    "def zoom_volume(vol, spatial_size):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    \"\"\" NON UTILIZZATA SOSTITUITA DA RESIZE\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_width, desired_height, desired_depth = spatial_size\n",
    "    # Get current depth\n",
    "    current_depth = vol.shape[-1]\n",
    "    current_width = vol.shape[0]\n",
    "    current_height = vol.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Resize across z-axis\n",
    "    #vol = ndi.zoom(vol, (width_factor, height_factor, depth_factor), order=0, mode='constant')\n",
    "    zoom_transform = Zoom(zoom=(width_factor, height_factor, depth_factor), keep_size=False)\n",
    "    zoom_vol = zoom_transform(vol)\n",
    "    return zoom_vol\n",
    "\n",
    "def one_hot_encoding_multiclass_mask(mask):\n",
    "    \"\"\" Binary OneHot Encoding of Multi-class masks\"\"\"\n",
    "    labels = list(range(8))\n",
    "    num_labels = len(labels)\n",
    "    c, h, w, d = mask.shape\n",
    "    enc_mask = np.zeros((num_labels, h, w, d))\n",
    "    for c in range(1, num_labels):  # this loop starts from label 1 to ignore background 0\n",
    "        enc_mask[c, :, :, :] = (mask == labels[c]) # 1 for the pixel belonging to that class, 0 for the rest of the pixel\n",
    "        \n",
    "    return enc_mask\n",
    "\n",
    "def expand_dims(arr):\n",
    "    return np.expand_dims(arr, axis=0)\n",
    "\n",
    "\n",
    "def training_plot(file, output_path, config):\n",
    "    train_bce_dl_loss = file['Train_bce_dl_loss']\n",
    "    val_bce_dl_loss = file['Val_bce_dl_loss']\n",
    "    epochs = range(1, len(train_bce_dl_loss) + 1)\n",
    "    plt.plot(epochs, train_bce_dl_loss, label='Training BCE-DiceLoss', color='darkblue')\n",
    "    plt.plot(epochs, val_bce_dl_loss, label='Val BCE-DiceLoss', color='darkorange')\n",
    "    plt.title('Training & Val Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_path, f'{config[\"ID\"]}_Training_Losses_plot.png'))\n",
    "    plt.show()\n",
    "    \n",
    "def validation_metric_plot(file, output_path, config):\n",
    "    val_metric = file['Val_metric']\n",
    "    epochs = range(1, len(val_metric)+1)\n",
    "    plt.plot(epochs, val_metric, label='Validation DiceMetric', color='red')\n",
    "    plt.title('Validation Metric')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_path, f'{config[\"ID\"]}_Validation_Metric_plot.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312af63f",
   "metadata": {
    "papermill": {
     "duration": 0.011673,
     "end_time": "2024-08-30T14:07:11.488915",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.477242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "In this section we will build the dataset (pandas dataframe) starting from the input data. The df has 4 columns:\n",
    "\n",
    "* **ID** : identification number of the patient\n",
    "* **label_path**: complete path of the segmentation mask\n",
    "* **image_path**: complete path of the CT scan\n",
    "* **fold**: index of the folder for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5ff1f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.513554Z",
     "iopub.status.busy": "2024-08-30T14:07:11.512982Z",
     "iopub.status.idle": "2024-08-30T14:07:11.599829Z",
     "shell.execute_reply": "2024-08-30T14:07:11.598902Z"
    },
    "papermill": {
     "duration": 0.101309,
     "end_time": "2024-08-30T14:07:11.601815",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.500506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_path</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.780</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.21321</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.6125</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.30067</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.12833</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ID  \\\n",
       "0    1.2.826.0.1.3680043.780   \n",
       "1  1.2.826.0.1.3680043.21321   \n",
       "2   1.2.826.0.1.3680043.6125   \n",
       "3  1.2.826.0.1.3680043.30067   \n",
       "4  1.2.826.0.1.3680043.12833   \n",
       "\n",
       "                                          label_path  \\\n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "3  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "4  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "\n",
       "                                          image_path  fold  \n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...     0  \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...     4  \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...     4  \n",
       "3  ../input/rsna-2022-cervical-spine-fracture-det...     2  \n",
       "4  ../input/rsna-2022-cervical-spine-fracture-det...     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataset\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Store all the nifti files in the segmentation folder\n",
    "df['ID'] = os.listdir(SEGMENTATIONS_PATH)\n",
    "\n",
    "# Remove the extension '.nii'\n",
    "df['ID'] = df['ID'].apply(lambda x: x[:-4])\n",
    "\n",
    "# Add complete path to reach segmentation file (nifti)\n",
    "df['label_path'] = df['ID'].apply(lambda x: os.path.join(SEGMENTATIONS_PATH, x + '.nii'))\n",
    "\n",
    "# Add complete path to reach CT scan folder in train_images\n",
    "df['image_path'] = df['ID'].apply(lambda x: os.path.join(TRAIN_IMAGES_PATH, x))\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=config['k'], shuffle=True, random_state=42)\n",
    "\n",
    "# Create a new column for fold indices\n",
    "df['fold'] = -1\n",
    "\n",
    "# Assign fold indices\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(df)):\n",
    "    df.loc[val_index, 'fold'] = fold\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(df.shape)\n",
    "\n",
    "# Show the head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c1f3d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.627108Z",
     "iopub.status.busy": "2024-08-30T14:07:11.626611Z",
     "iopub.status.idle": "2024-08-30T14:07:11.641927Z",
     "shell.execute_reply": "2024-08-30T14:07:11.640988Z"
    },
    "papermill": {
     "duration": 0.029968,
     "end_time": "2024-08-30T14:07:11.643792",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.613824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 5)\n",
      "(18, 5)\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation dataset\n",
    "\n",
    "val_fold_idx = config['val_fold_idx']\n",
    "\n",
    "df_train = df[df.fold != val_fold_idx].reset_index()\n",
    "print(df_train.shape)\n",
    "\n",
    "df_val = df[df.fold == val_fold_idx].reset_index()\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e0639",
   "metadata": {
    "papermill": {
     "duration": 0.011746,
     "end_time": "2024-08-30T14:07:11.667515",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.655769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transforms\n",
    "\n",
    "In this section we will define the transformation (MONAI) to be applied to both images (CT scan) and segmentation masks. The transforms pipeline are constituted by:\n",
    "\n",
    "**Load Data**. The image and label loading, `read_dicom_scan` and `read_nifti_file` respectively, load and preprocess volumetric data from DICOM and NIfTI formats, ensuring proper orientation and stacking for 3D analysis.\n",
    "\n",
    "**Data Preparation**. It includes expanding dimensions (`expand_dims`), resizing the volumes (`Resize`) to a target spatial size (128, 128, 128) ensuring that all inputs to the model have the same dimensions, scaling intensity (`ScaleIntensity`) for images, and applying one-hot encoding for multi-class masks (`one_hot_encoding_multiclass_mask`) for labels, standardizing the data for model input.\n",
    "\n",
    "**Data Augmentation**. To increase the model's generalization we introduce variability in the training data by using image augmentation techniques such as:\n",
    "* `RandFlip`: Randomly flips the input images and masks along specified axes (width and height) with a probability of 0.5, helping the model become invariant to orientation changes\n",
    "* `RandGridDistortion`: Applies random grid distortion with 5 cells and a distortion limit of (-0.03, 0.03), warping the image grid to simulate deformations and enhance robustness to spatial variations\n",
    "* `RandAffine`: Applies random affine transformations with a probability of 0.5, allowing translations up to 30% of the image size in each dimension, simulating patient movement or slight positioning changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d477cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.693138Z",
     "iopub.status.busy": "2024-08-30T14:07:11.692877Z",
     "iopub.status.idle": "2024-08-30T14:07:11.718107Z",
     "shell.execute_reply": "2024-08-30T14:07:11.717426Z"
    },
    "papermill": {
     "duration": 0.040625,
     "end_time": "2024-08-30T14:07:11.720094",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.679469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training transforms for image and label\n",
    "train_image_trans = Compose(\n",
    "    [   \n",
    "        # Load Data\n",
    "        read_dicom_scan,\n",
    "        # Data Preparation\n",
    "        expand_dims, \n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"), # Resize the volume to target spatial_size\n",
    "        ScaleIntensity(), # scale between (0,1)\n",
    "        # Data Augmentation \n",
    "        RandFlip(prob=config['prob'], spatial_axis=0), # width\n",
    "        RandFlip(prob=config['prob'], spatial_axis=1), # height\n",
    "        RandGridDistortion(num_cells=5, distort_limit=(-0.03, 0.03), prob=config['prob']),\n",
    "        RandAffine(prob=config['prob'], \n",
    "                   translate_range=[int(x*y) for x, y in zip(config['spatial_size'], [0.3, 0.3, 0.3])], padding_mode='zeros')\n",
    "    ]\n",
    ")\n",
    "train_label_trans = Compose(\n",
    "    [   \n",
    "        # Load data\n",
    "        read_nifti_file,\n",
    "        # Data Preparation\n",
    "        expand_dims,\n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"),\n",
    "        one_hot_encoding_multiclass_mask, \n",
    "        # Data Augmentation\n",
    "        RandFlip(prob=config['prob'], spatial_axis=0), # width\n",
    "        RandFlip(prob=config['prob'], spatial_axis=1), # height\n",
    "        RandGridDistortion(num_cells=5, distort_limit=(-0.03, 0.03), prob=config['prob']),\n",
    "        RandAffine(prob=config['prob'], \n",
    "                   translate_range=[int(x*y) for x, y in zip(config['spatial_size'], [0.3, 0.3, 0.3])], padding_mode='zeros')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define validation transforms for image and label (no augmentation)\n",
    "val_image_trans = Compose(\n",
    "    [\n",
    "        # Load data\n",
    "        read_dicom_scan,\n",
    "        # Data Preparation\n",
    "        expand_dims,\n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"), \n",
    "        ScaleIntensity()\n",
    "    ]\n",
    ")\n",
    "val_label_trans = Compose(\n",
    "    [\n",
    "        # Load data\n",
    "        read_nifti_file,\n",
    "        # Data preparation\n",
    "        expand_dims,\n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"),\n",
    "        one_hot_encoding_multiclass_mask\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2d0051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.747266Z",
     "iopub.status.busy": "2024-08-30T14:07:11.746764Z",
     "iopub.status.idle": "2024-08-30T14:07:11.753558Z",
     "shell.execute_reply": "2024-08-30T14:07:11.752610Z"
    },
    "papermill": {
     "duration": 0.022848,
     "end_time": "2024-08-30T14:07:11.755484",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.732636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define train dataset and dataloader\n",
    "train_ds = ArrayDataset(df_train.image_path, train_image_trans, df_train.label_path, train_label_trans)\n",
    "train_loader = DataLoader(train_ds, batch_size=config['batch_size'], num_workers=2)\n",
    "\n",
    "# Define validation dataset and dataloader\n",
    "val_ds = ArrayDataset(df_val.image_path, val_image_trans, df_val.label_path, val_label_trans)\n",
    "val_loader = DataLoader(val_ds, batch_size=config['batch_size'], num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c443d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:11.780359Z",
     "iopub.status.busy": "2024-08-30T14:07:11.780094Z",
     "iopub.status.idle": "2024-08-30T14:07:59.895570Z",
     "shell.execute_reply": "2024-08-30T14:07:59.894375Z"
    },
    "papermill": {
     "duration": 48.146686,
     "end_time": "2024-08-30T14:07:59.914112",
     "exception": false,
     "start_time": "2024-08-30T14:07:11.767426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 128, 128, 128]) torch.Size([4, 8, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Take the first processed train batch and print the shape\n",
    "first_train_image, first_train_label = first(train_loader)\n",
    "print(first_train_image.shape, first_train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc8e34a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:07:59.940308Z",
     "iopub.status.busy": "2024-08-30T14:07:59.939954Z",
     "iopub.status.idle": "2024-08-30T14:08:00.205412Z",
     "shell.execute_reply": "2024-08-30T14:08:00.204192Z"
    },
    "papermill": {
     "duration": 0.281117,
     "end_time": "2024-08-30T14:08:00.207470",
     "exception": false,
     "start_time": "2024-08-30T14:07:59.926353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot example image and label (training dataset)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "s = 29\n",
    "vertebrae = 1\n",
    "\n",
    "ax1.imshow(first_train_image[1, 0, :, :, s])\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(first_train_label[1,vertebrae, :, :, s])\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()  # Optional: improve spacing between plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d8f09",
   "metadata": {
    "papermill": {
     "duration": 0.012995,
     "end_time": "2024-08-30T14:08:00.233958",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.220963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3D Unet model, DiceLoss and Optimizer\n",
    "\n",
    "In this section we will define the model used for 3D segmentation, the loss and the optimization algorithm used during training.\n",
    "\n",
    "- `Model`: has UNet architecture which is *state-of-the-art* for 3D segmentation of medical images. We exploit the [MONAI](https://docs.monai.io/en/stable/networks.html#unet) implementation.\n",
    "- `Loss`: the default loss used in segmentation problem is **Dice Loss**. We exploit the MONAI implementation. Because we are dealing with a mulit-class semantic segmantation problem the **softmax** activation function is applied to the prediction of the model. \n",
    "- `Optimizer`: the optimization algorithm employed for training the 3Dsegmentation model is **Adam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb3339c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.261614Z",
     "iopub.status.busy": "2024-08-30T14:08:00.261304Z",
     "iopub.status.idle": "2024-08-30T14:08:00.510537Z",
     "shell.execute_reply": "2024-08-30T14:08:00.509366Z"
    },
    "papermill": {
     "duration": 0.265939,
     "end_time": "2024-08-30T14:08:00.512877",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.246938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the 3D Unet model\n",
    "unet_model = UNet(\n",
    "    spatial_dims = 3, # (Height, Width, Depth)\n",
    "    in_channels = 1,\n",
    "    out_channels = 8, # 8 Binary mask 7 as the vertebrae(C1->C7) + background\n",
    "    channels = config['channels'], # Channels per layer\n",
    "    strides = config['strides'], # Stride per layers\n",
    "    kernel_size = config['kernel_size'], # Size of the kernel for each layer\n",
    "    up_kernel_size = config['up_kernel_size'], # Upsampling convolution kernel size\n",
    "    num_res_units = config['num_res_units'], # Number of residual units\n",
    "    act = config['act'], # Activation function\n",
    "    dropout = config['dropout'], # Dropout rate\n",
    "    bias = config['bias'] # Presence of bias term in convolution blocks\n",
    ")\n",
    "unet_model = unet_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186873e",
   "metadata": {
    "papermill": {
     "duration": 0.013217,
     "end_time": "2024-08-30T14:08:00.539607",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.526390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Losses & Metrics\n",
    "---\n",
    "\n",
    "The loss function used during training is the weighted sum of **Dice Loss** and **BCE Loss** because combining these two losses yields the best result in terms of segmentation, pixel-wise accuracy, generalization and adversarial attacks as shown in [Robustness of different loss functions and their impact on networks learning capability](https://arxiv.org/abs/2110.08322).\n",
    "\n",
    "The weights allow us to balance the effects of the two losses. The best combination after model selection is $\\alpha=0.05$ and $\\beta=0.95$\n",
    "\n",
    "$$\\alpha \\cdot \\text{BCE} + \\beta \\cdot \\text{Dice loss}$$\n",
    "\n",
    "Below is a brief explanation of the two losses.\n",
    "\n",
    "#### Dice Loss\n",
    "\n",
    " **Dice Loss** is a popular loss function for image segmentation and **measures the overlap between the predicted segmentation and the ground truth**.\n",
    "The advantage of using dice loss is that it can very well **handle the class imbalance** in terms of pixel count for foreground and background. Class imbalances is a common scenario in medical images where the background vastly outnumbers the foreground as in the current case.\n",
    "The dice loss formula is reported below.\n",
    "\n",
    "$$ \\text{Dice Loss} = 1 - \\frac{2\\sum_{i=1}^{n}p_i y_i}{\\sum_{i=1}^{n}p_{i}^{2}+\\sum_{i=1}^{n}y_{i}^{2}}$$\n",
    "\n",
    "Where $y_{i}$ is the real pixel value and $p_{i}$ is the predicted pixel value.\n",
    "\n",
    "We exploit MONAI implementation of Dice Loss, in what follows we will explain the chosen parameters setting:\n",
    "- `softmax=True`. In **multi-class semantic segmentation problem** each voxel of the input volume can belong to at most one class. In the current problem we have 8 classes (background and C1, ..., C7 vertebrae). **Softmax activation** function is applied to the raw output of the segmentation model to ensure that the sum of the predicted probabilities over the 8 binary channels sum up to 1.\n",
    "- `include_background=False`. We decide to exclude the first channel (background) from the loss to focus the attention of the model in the prediction of the C1, ..., C7 vertebrae.\n",
    "- `squared_pred=False`. At the denominator we do NOT use the squared prediction of the real pixel value and predicted pixel value.\n",
    "- `reduction='mean'` The reduction applied to the output, i.e. the mean over the sample in the processed batch.\n",
    "\n",
    "\n",
    "#### BCE - Binary Crossentropy\n",
    "\n",
    "**BCE Loss** (Binary Crossentropy) is commonly used in binary classification problems where the target can only assume value 0 or 1, this is the case of image segmentation if we consider the pixels of the binary encoded masks.\n",
    "\n",
    "$$\\text{BCE Loss} = - \\frac{1}{N}\\sum_{i=1}^{n}[y_i log(p_i) + (1-y_i)log(1-p_i)]$$\n",
    "\n",
    "We exploit Pytorch implementation of BCE, in particular withLogitsLoss version because the output of the model is between $[-inf, +inf]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc12aaa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.566983Z",
     "iopub.status.busy": "2024-08-30T14:08:00.566661Z",
     "iopub.status.idle": "2024-08-30T14:08:00.571037Z",
     "shell.execute_reply": "2024-08-30T14:08:00.570152Z"
    },
    "papermill": {
     "duration": 0.020396,
     "end_time": "2024-08-30T14:08:00.573019",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.552623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define metric\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d3a4b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.600661Z",
     "iopub.status.busy": "2024-08-30T14:08:00.600380Z",
     "iopub.status.idle": "2024-08-30T14:08:00.606450Z",
     "shell.execute_reply": "2024-08-30T14:08:00.605578Z"
    },
    "papermill": {
     "duration": 0.022078,
     "end_time": "2024-08-30T14:08:00.608337",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.586259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Optimizer\n",
    "\n",
    "# Adam optimzier\n",
    "#optimizer = torch.optim.Adam(\n",
    "#    unet_model.parameters(), # Model's params\n",
    "#    lr = 1e-3 # Learning rate\n",
    "#)\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    unet_model.parameters(), \n",
    "    lr = config['lr'] # weight_decay = config['weight_decay'] \n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22794d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.635577Z",
     "iopub.status.busy": "2024-08-30T14:08:00.635327Z",
     "iopub.status.idle": "2024-08-30T14:08:00.640558Z",
     "shell.execute_reply": "2024-08-30T14:08:00.639705Z"
    },
    "papermill": {
     "duration": 0.020971,
     "end_time": "2024-08-30T14:08:00.642466",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.621495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use amp to accelerate training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Define the transforms to apply to model prediction \n",
    "post_trans = Compose([Activations(sigmoid=False, softmax=True, dim=0), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5924b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.669380Z",
     "iopub.status.busy": "2024-08-30T14:08:00.669134Z",
     "iopub.status.idle": "2024-08-30T14:08:00.672920Z",
     "shell.execute_reply": "2024-08-30T14:08:00.672046Z"
    },
    "papermill": {
     "duration": 0.019324,
     "end_time": "2024-08-30T14:08:00.674751",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.655427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(unet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f4e354",
   "metadata": {
    "papermill": {
     "duration": 0.012881,
     "end_time": "2024-08-30T14:08:00.700487",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.687606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2047a492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.727442Z",
     "iopub.status.busy": "2024-08-30T14:08:00.727157Z",
     "iopub.status.idle": "2024-08-30T14:08:00.733666Z",
     "shell.execute_reply": "2024-08-30T14:08:00.732886Z"
    },
    "papermill": {
     "duration": 0.022265,
     "end_time": "2024-08-30T14:08:00.735700",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.713435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Loss function\n",
    "\n",
    "# BCE-DiceLoss function\n",
    "# Define DiceLoss (MONAI)\n",
    "dice_loss_fn = DiceLoss(\n",
    "    include_background=True,  # Include background class in the Dice computation\n",
    "    to_onehot_y=False,  # Assuming the labels are not one-hot encoded\n",
    "    sigmoid=False,  # Apply sigmoid to the input tensor\n",
    "    softmax=True,  # Do not apply softmax to the input tensor\n",
    "    squared_pred=True,  # Do not use squared predictions\n",
    "    reduction='mean', # Reduction to apply to the output\n",
    "    smooth_nr=1.0, # constant added to the numerator to avoid zero\n",
    "    smooth_dr=1.0 # constant added to the denominator to avoid nan\n",
    ")\n",
    "# Define BCEWithLogitsLoss (PyTorch)\n",
    "bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "# Combine BCE and Dice losses\n",
    "def bce_diceloss(input, target, loss_weights=config['loss_weights']):    # Compute the BCE loss\n",
    "    bce_loss = loss_weights[0] * bce_loss_fn(input, target)\n",
    "    # Compute the Dice loss\n",
    "    dice_loss = loss_weights[1] * dice_loss_fn(input, target)\n",
    "    # Combine the losses\n",
    "    total_loss = (bce_loss + dice_loss) / sum(loss_weights)\n",
    "    return total_loss\n",
    "# Set the combined loss function\n",
    "criterion = bce_diceloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab058014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.762887Z",
     "iopub.status.busy": "2024-08-30T14:08:00.762616Z",
     "iopub.status.idle": "2024-08-30T14:08:00.787813Z",
     "shell.execute_reply": "2024-08-30T14:08:00.787016Z"
    },
    "papermill": {
     "duration": 0.041107,
     "end_time": "2024-08-30T14:08:00.789699",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.748592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model,\n",
    "               train_loader,\n",
    "               val_loader,\n",
    "               diceloss_function,\n",
    "               bce_function,\n",
    "               bce_diceloss_function,\n",
    "               metric,\n",
    "               optimizer,\n",
    "               lr_scheduler,\n",
    "               config,\n",
    "               output_dir,\n",
    "               output_file,\n",
    "               device):\n",
    "    \n",
    "    # Container to store train losses values per epoch\n",
    "    train_dl_values = []\n",
    "    train_bce_values = []\n",
    "    train_bce_dl_values = []\n",
    "    \n",
    "    # Container to store val losses values per epoch\n",
    "    val_dl_values = []\n",
    "    val_bce_values = []\n",
    "    val_bce_dl_values = []\n",
    "\n",
    "    # Container to store val metric values per epoch\n",
    "    val_metric_values = []\n",
    "\n",
    "    # Store best val metric\n",
    "    best_val_metric = -1\n",
    "\n",
    "    total_start = time.time()\n",
    "    # Iterate over the epochs\n",
    "    for epoch in range(1, config['epochs']+1):\n",
    "        epoch_start = time.time()\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"EPOCH {epoch}/{config['epochs']}\")\n",
    "        model.train() # Set the model in training mode\n",
    "        epoch_train_dl_loss, epoch_train_bce_loss, epoch_train_bce_dl_loss = 0, 0, 0\n",
    "        epoch_val_dl_loss, epoch_val_bce_loss, epoch_val_bce_dl_loss = 0, 0, 0\n",
    "        # Iterate over the batches\n",
    "        for step, batch_data in enumerate(train_loader):\n",
    "            step_start = time.time()\n",
    "            inputs, labels = batch_data\n",
    "            inputs, labels = (inputs.to(device), labels.to(device))\n",
    "            optimizer.zero_grad() # Clear the old gradients before computing new ones\n",
    "            # Enable automatic mixed precision (amp)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs) # Make predictions for current batch\n",
    "                train_dl_loss = diceloss_function(outputs, labels) # Compute DiceLoss (train)\n",
    "                train_bce_loss = bce_function(outputs, labels) # Compute BCE loss (train)\n",
    "                train_bce_dl_loss = bce_diceloss_function(outputs, labels) # Compute BCE-DiceLoss (train)\n",
    "            scaler.scale(train_bce_dl_loss).backward() # Compute the gradients\n",
    "            scaler.step(optimizer) # Update model weights\n",
    "            scaler.update()\n",
    "            epoch_train_dl_loss += train_dl_loss.item()\n",
    "            epoch_train_bce_loss += train_bce_loss.item()\n",
    "            epoch_train_bce_dl_loss += train_bce_dl_loss.item()\n",
    "            # REPORT PER BATCH \n",
    "            print(\n",
    "                f\"batch: {step}/{len(train_ds) // train_loader.batch_size}\"\n",
    "                f\", train_dl_loss: {train_dl_loss.item():.4f}\"\n",
    "                f\", train_bce_loss: {train_bce_loss.item():.4f}\"\n",
    "                f\", train_bce_dl_loss: {train_bce_dl_loss.item():.4f}\"\n",
    "                f\", step time: {(time.time() - step_start):.4f}\"\n",
    "            )\n",
    "        lr_scheduler.step()\n",
    "        # Compute mean losses over the batches\n",
    "        avg_train_dl_loss = epoch_train_dl_loss / (step+1)\n",
    "        avg_train_bce_loss = epoch_train_bce_loss / (step+1)\n",
    "        avg_train_bce_dl_loss = epoch_train_bce_dl_loss / (step+1)\n",
    "\n",
    "        # EVALUATE MODEL ON VALIDATION SET\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        with torch.no_grad(): # Disable gradient computation and reduce memory consumption\n",
    "            for step, val_data in enumerate(val_loader):\n",
    "                val_inputs, val_labels = val_data\n",
    "                val_inputs, val_labels = (val_inputs.to(device), val_labels.to(device))\n",
    "                val_outputs = model(val_inputs)\n",
    "                # Compute losses\n",
    "                val_dl_loss = diceloss_function(val_outputs, val_labels) # Compute DiceLoss (val)\n",
    "                val_bce_loss = bce_function(val_outputs, val_labels) # Compute BCE (val)\n",
    "                val_bce_dl_loss = bce_diceloss_function(val_outputs, val_labels) # Compute BCE-DiceLoss (val)\n",
    "                # Apply post transforms\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                # Compute metric\n",
    "                metric(y_pred=val_outputs, y=val_labels)\n",
    "                \n",
    "                epoch_val_dl_loss += val_dl_loss.item()\n",
    "                epoch_val_bce_loss += val_bce_loss.item()\n",
    "                epoch_val_bce_dl_loss += val_bce_dl_loss.item()\n",
    "                \n",
    "            # Aggregate the final mean dice result\n",
    "            avg_val_metric = metric.aggregate().item()\n",
    "            \n",
    "        # Compute mean val losses over the batches\n",
    "        avg_val_dl_loss = epoch_val_dl_loss / (step + 1)\n",
    "        avg_val_bce_loss = epoch_val_bce_loss / (step + 1)\n",
    "        avg_val_bce_dl_loss = epoch_val_bce_dl_loss / (step + 1)\n",
    "\n",
    "        # REPORT PER EPOCH\n",
    "        print(f'LOSS train DiceLoss: {avg_train_dl_loss:.4f}, LOSS train BCE: {avg_train_bce_loss:.4f}, LOSS train BCE-DiceLoss: {avg_train_bce_dl_loss:.4f}, LOSS val DiceLoss: {avg_val_dl_loss:.4f}, LOSS val BCE: {avg_val_bce_loss:.4f}, LOSS val BCE-DiceLoss: {avg_val_bce_dl_loss:.4f}, METRIC val: {avg_val_metric:.4f}')\n",
    "\n",
    "        # Store train/val losses and val metric per epoch\n",
    "        train_dl_values.append(avg_train_dl_loss)\n",
    "        train_bce_values.append(avg_train_bce_loss)\n",
    "        train_bce_dl_values.append(avg_train_bce_dl_loss)\n",
    "        val_dl_values.append(avg_val_dl_loss)\n",
    "        val_bce_values.append(avg_val_bce_loss)\n",
    "        val_bce_dl_values.append(avg_val_bce_dl_loss)\n",
    "        val_metric_values.append(avg_val_metric)\n",
    "        \n",
    "        # Reset the metric status\n",
    "        metric.reset()\n",
    "\n",
    "        # Log the running loss averaged per batch for train and the running metric averaged per batch for val\n",
    "        with open(output_file, \"a\") as file:\n",
    "            file.write(f\"{epoch}, {avg_train_dl_loss}, {avg_train_bce_loss}, {avg_train_bce_dl_loss}, {avg_val_dl_loss}, {avg_val_bce_loss}, {avg_val_bce_dl_loss}, {avg_val_metric}\\n\")\n",
    "        \n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_val_metric > best_val_metric:\n",
    "            best_val_metric = avg_val_metric\n",
    "            best_model = {'epoch': epoch,\n",
    "                          'model_state_dict': model.state_dict(),\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                          'train DiceLoss loss': avg_train_dl_loss,\n",
    "                          'train BCE loss': avg_train_bce_loss,\n",
    "                          'train BCE-DiceLoss loss': avg_train_bce_dl_loss,\n",
    "                          'val DiceLoss loss': avg_val_dl_loss,\n",
    "                          'val BCE loss': avg_val_bce_loss,\n",
    "                          'val BCE-DiceLoss loss': avg_val_bce_dl_loss\n",
    "                         }\n",
    "        print(f\"time consuming of epoch {epoch} is: {(time.time() - epoch_start):.4f}\")\n",
    "        \n",
    "        # Save last model's state\n",
    "        if epoch == config['epochs']:\n",
    "            last_model = {'epoch': epoch,\n",
    "                          'model_state_dict': model.state_dict(),\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                          'train DiceLoss loss': avg_train_dl_loss,\n",
    "                          'train BCE loss': avg_train_bce_loss,\n",
    "                          'train BCE-DiceLoss loss': avg_train_bce_dl_loss,\n",
    "                          'val DiceLoss loss': avg_val_dl_loss,\n",
    "                          'val BCE loss': avg_val_bce_loss,\n",
    "                          'val BCE-DiceLoss loss': avg_val_bce_dl_loss\n",
    "                          }\n",
    "            \n",
    "    total_time = time.time() - total_start\n",
    "\n",
    "    # Save Train Losses and Val Metric\n",
    "    with open(OUTPUT_FILE, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Train_dl_loss', 'Train_bce_loss', 'Train_bce_dl_loss', 'Val_dl_loss', 'Val_bce_loss', 'Val_bce_dl_loss', 'Val_metric'])\n",
    "        csvwriter.writerows(zip(train_dl_values, train_bce_values, train_bce_dl_values, val_dl_values, val_bce_values, val_bce_dl_values, val_metric_values))    \n",
    "        \n",
    "    # Save Best Model's State\n",
    "    best_model_path = os.path.join(OUTPUT_DIR, f\"{config['ID']}_best_model\")\n",
    "    torch.save(best_model, best_model_path)\n",
    "\n",
    "    # Save Last Model's State\n",
    "    last_model_path = os.path.join(OUTPUT_DIR, f\"{config['ID']}_last_model\")\n",
    "    torch.save(last_model, last_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6102ea42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T14:08:00.816765Z",
     "iopub.status.busy": "2024-08-30T14:08:00.816520Z",
     "iopub.status.idle": "2024-08-31T00:04:09.115177Z",
     "shell.execute_reply": "2024-08-31T00:04:09.114045Z"
    },
    "papermill": {
     "duration": 35768.381073,
     "end_time": "2024-08-31T00:04:09.183763",
     "exception": false,
     "start_time": "2024-08-30T14:08:00.802690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "EPOCH 1/80\n",
      "batch: 0/17, train_dl_loss: 0.9840, train_bce_loss: 0.8861, train_bce_dl_loss: 0.9840, step time: 5.1891\n",
      "batch: 1/17, train_dl_loss: 0.9850, train_bce_loss: 0.8833, train_bce_dl_loss: 0.9850, step time: 0.3608\n",
      "batch: 2/17, train_dl_loss: 0.9860, train_bce_loss: 0.8848, train_bce_dl_loss: 0.9860, step time: 0.4112\n",
      "batch: 3/17, train_dl_loss: 0.9900, train_bce_loss: 0.8817, train_bce_dl_loss: 0.9900, step time: 0.3629\n",
      "batch: 4/17, train_dl_loss: 0.9781, train_bce_loss: 0.8849, train_bce_dl_loss: 0.9781, step time: 0.4251\n",
      "batch: 5/17, train_dl_loss: 0.9773, train_bce_loss: 0.8835, train_bce_dl_loss: 0.9773, step time: 0.3699\n",
      "batch: 6/17, train_dl_loss: 0.9883, train_bce_loss: 0.8821, train_bce_dl_loss: 0.9883, step time: 0.4104\n",
      "batch: 7/17, train_dl_loss: 0.9792, train_bce_loss: 0.8806, train_bce_dl_loss: 0.9792, step time: 0.3633\n",
      "batch: 8/17, train_dl_loss: 0.9816, train_bce_loss: 0.8790, train_bce_dl_loss: 0.9816, step time: 0.4071\n",
      "batch: 9/17, train_dl_loss: 0.9831, train_bce_loss: 0.8777, train_bce_dl_loss: 0.9831, step time: 0.3653\n",
      "batch: 10/17, train_dl_loss: 0.9780, train_bce_loss: 0.8758, train_bce_dl_loss: 0.9780, step time: 0.4278\n",
      "batch: 11/17, train_dl_loss: 0.9724, train_bce_loss: 0.8605, train_bce_dl_loss: 0.9724, step time: 0.4099\n",
      "batch: 12/17, train_dl_loss: 0.9790, train_bce_loss: 0.8726, train_bce_dl_loss: 0.9790, step time: 0.4443\n",
      "batch: 13/17, train_dl_loss: 0.9894, train_bce_loss: 0.8649, train_bce_dl_loss: 0.9894, step time: 0.3689\n",
      "batch: 14/17, train_dl_loss: 0.9844, train_bce_loss: 0.8641, train_bce_dl_loss: 0.9844, step time: 0.4115\n",
      "batch: 15/17, train_dl_loss: 0.9821, train_bce_loss: 0.8707, train_bce_dl_loss: 0.9821, step time: 0.3694\n",
      "batch: 16/17, train_dl_loss: 0.9869, train_bce_loss: 0.8687, train_bce_dl_loss: 0.9869, step time: 0.4141\n",
      "batch: 17/17, train_dl_loss: 0.9834, train_bce_loss: 0.8697, train_bce_dl_loss: 0.9834, step time: 1.1687\n",
      "LOSS train DiceLoss: 0.9827, LOSS train BCE: 0.8762, LOSS train BCE-DiceLoss: 0.9827, LOSS val DiceLoss: 0.9795, LOSS val BCE: 0.8596, LOSS val BCE-DiceLoss: 0.9795, METRIC val: 0.0002\n",
      "time consuming of epoch 1 is: 502.7258\n",
      "----------\n",
      "EPOCH 2/80\n",
      "batch: 0/17, train_dl_loss: 0.9791, train_bce_loss: 0.8670, train_bce_dl_loss: 0.9791, step time: 0.4215\n",
      "batch: 1/17, train_dl_loss: 0.9801, train_bce_loss: 0.8657, train_bce_dl_loss: 0.9801, step time: 0.3720\n",
      "batch: 2/17, train_dl_loss: 0.9812, train_bce_loss: 0.8665, train_bce_dl_loss: 0.9812, step time: 0.4496\n",
      "batch: 3/17, train_dl_loss: 0.9846, train_bce_loss: 0.8624, train_bce_dl_loss: 0.9846, step time: 0.3714\n",
      "batch: 4/17, train_dl_loss: 0.9713, train_bce_loss: 0.8601, train_bce_dl_loss: 0.9713, step time: 0.4310\n",
      "batch: 5/17, train_dl_loss: 0.9705, train_bce_loss: 0.8577, train_bce_dl_loss: 0.9705, step time: 0.3677\n",
      "batch: 6/17, train_dl_loss: 0.9847, train_bce_loss: 0.8645, train_bce_dl_loss: 0.9847, step time: 0.4275\n",
      "batch: 7/17, train_dl_loss: 0.9741, train_bce_loss: 0.8599, train_bce_dl_loss: 0.9741, step time: 0.3572\n",
      "batch: 8/17, train_dl_loss: 0.9759, train_bce_loss: 0.8560, train_bce_dl_loss: 0.9759, step time: 0.4167\n",
      "batch: 9/17, train_dl_loss: 0.9781, train_bce_loss: 0.8597, train_bce_dl_loss: 0.9781, step time: 0.3669\n",
      "batch: 10/17, train_dl_loss: 0.9727, train_bce_loss: 0.8637, train_bce_dl_loss: 0.9727, step time: 0.4425\n",
      "batch: 11/17, train_dl_loss: 0.9661, train_bce_loss: 0.8521, train_bce_dl_loss: 0.9661, step time: 0.4247\n",
      "batch: 12/17, train_dl_loss: 0.9744, train_bce_loss: 0.8570, train_bce_dl_loss: 0.9744, step time: 0.4341\n",
      "batch: 13/17, train_dl_loss: 0.9871, train_bce_loss: 0.8601, train_bce_dl_loss: 0.9871, step time: 0.3686\n",
      "batch: 14/17, train_dl_loss: 0.9809, train_bce_loss: 0.8585, train_bce_dl_loss: 0.9809, step time: 0.4213\n",
      "batch: 15/17, train_dl_loss: 0.9789, train_bce_loss: 0.8662, train_bce_dl_loss: 0.9789, step time: 0.3803\n",
      "batch: 16/17, train_dl_loss: 0.9842, train_bce_loss: 0.8607, train_bce_dl_loss: 0.9842, step time: 0.4047\n",
      "batch: 17/17, train_dl_loss: 0.9786, train_bce_loss: 0.8616, train_bce_dl_loss: 0.9786, step time: 0.1094\n",
      "LOSS train DiceLoss: 0.9779, LOSS train BCE: 0.8611, LOSS train BCE-DiceLoss: 0.9779, LOSS val DiceLoss: 0.9759, LOSS val BCE: 0.8511, LOSS val BCE-DiceLoss: 0.9759, METRIC val: 0.0000\n",
      "time consuming of epoch 2 is: 438.5763\n",
      "----------\n",
      "EPOCH 3/80\n",
      "batch: 0/17, train_dl_loss: 0.9759, train_bce_loss: 0.8595, train_bce_dl_loss: 0.9759, step time: 0.4256\n",
      "batch: 1/17, train_dl_loss: 0.9757, train_bce_loss: 0.8525, train_bce_dl_loss: 0.9757, step time: 0.3716\n",
      "batch: 2/17, train_dl_loss: 0.9776, train_bce_loss: 0.8530, train_bce_dl_loss: 0.9776, step time: 0.4364\n",
      "batch: 3/17, train_dl_loss: 0.9817, train_bce_loss: 0.8547, train_bce_dl_loss: 0.9817, step time: 0.3738\n",
      "batch: 4/17, train_dl_loss: 0.9650, train_bce_loss: 0.8580, train_bce_dl_loss: 0.9650, step time: 0.4398\n",
      "batch: 5/17, train_dl_loss: 0.9646, train_bce_loss: 0.8585, train_bce_dl_loss: 0.9646, step time: 0.3700\n",
      "batch: 6/17, train_dl_loss: 0.9805, train_bce_loss: 0.8613, train_bce_dl_loss: 0.9805, step time: 0.4363\n",
      "batch: 7/17, train_dl_loss: 0.9721, train_bce_loss: 0.8604, train_bce_dl_loss: 0.9721, step time: 0.3682\n",
      "batch: 8/17, train_dl_loss: 0.9706, train_bce_loss: 0.8525, train_bce_dl_loss: 0.9706, step time: 0.4178\n",
      "batch: 9/17, train_dl_loss: 0.9732, train_bce_loss: 0.8533, train_bce_dl_loss: 0.9732, step time: 0.3685\n",
      "batch: 10/17, train_dl_loss: 0.9634, train_bce_loss: 0.8627, train_bce_dl_loss: 0.9634, step time: 0.4182\n",
      "batch: 11/17, train_dl_loss: 0.9624, train_bce_loss: 0.8565, train_bce_dl_loss: 0.9624, step time: 0.3744\n",
      "batch: 12/17, train_dl_loss: 0.9663, train_bce_loss: 0.8609, train_bce_dl_loss: 0.9663, step time: 0.4319\n",
      "batch: 13/17, train_dl_loss: 0.9831, train_bce_loss: 0.8585, train_bce_dl_loss: 0.9831, step time: 0.3731\n",
      "batch: 14/17, train_dl_loss: 0.9766, train_bce_loss: 0.8607, train_bce_dl_loss: 0.9766, step time: 0.4339\n",
      "batch: 15/17, train_dl_loss: 0.9727, train_bce_loss: 0.8596, train_bce_dl_loss: 0.9727, step time: 0.3732\n",
      "batch: 16/17, train_dl_loss: 0.9783, train_bce_loss: 0.8615, train_bce_dl_loss: 0.9783, step time: 0.4129\n",
      "batch: 17/17, train_dl_loss: 0.9844, train_bce_loss: 0.8692, train_bce_dl_loss: 0.9844, step time: 0.1092\n",
      "LOSS train DiceLoss: 0.9736, LOSS train BCE: 0.8585, LOSS train BCE-DiceLoss: 0.9736, LOSS val DiceLoss: 0.9696, LOSS val BCE: 0.8597, LOSS val BCE-DiceLoss: 0.9696, METRIC val: 0.0125\n",
      "time consuming of epoch 3 is: 388.0853\n",
      "----------\n",
      "EPOCH 4/80\n",
      "batch: 0/17, train_dl_loss: 0.9706, train_bce_loss: 0.8619, train_bce_dl_loss: 0.9706, step time: 0.4383\n",
      "batch: 1/17, train_dl_loss: 0.9732, train_bce_loss: 0.8708, train_bce_dl_loss: 0.9732, step time: 0.3716\n",
      "batch: 2/17, train_dl_loss: 0.9740, train_bce_loss: 0.8697, train_bce_dl_loss: 0.9740, step time: 0.4226\n",
      "batch: 3/17, train_dl_loss: 0.9747, train_bce_loss: 0.8659, train_bce_dl_loss: 0.9747, step time: 0.3670\n",
      "batch: 4/17, train_dl_loss: 0.9539, train_bce_loss: 0.8717, train_bce_dl_loss: 0.9539, step time: 0.4351\n",
      "batch: 5/17, train_dl_loss: 0.9572, train_bce_loss: 0.8669, train_bce_dl_loss: 0.9572, step time: 0.3746\n",
      "batch: 6/17, train_dl_loss: 0.9747, train_bce_loss: 0.8682, train_bce_dl_loss: 0.9747, step time: 0.4424\n",
      "batch: 7/17, train_dl_loss: 0.9553, train_bce_loss: 0.8695, train_bce_dl_loss: 0.9553, step time: 0.4647\n",
      "batch: 8/17, train_dl_loss: 0.9578, train_bce_loss: 0.8706, train_bce_dl_loss: 0.9578, step time: 0.4282\n",
      "batch: 9/17, train_dl_loss: 0.9617, train_bce_loss: 0.8724, train_bce_dl_loss: 0.9617, step time: 0.4228\n",
      "batch: 10/17, train_dl_loss: 0.9579, train_bce_loss: 0.8747, train_bce_dl_loss: 0.9579, step time: 0.4250\n",
      "batch: 11/17, train_dl_loss: 0.9454, train_bce_loss: 0.8659, train_bce_dl_loss: 0.9454, step time: 0.4122\n",
      "batch: 12/17, train_dl_loss: 0.9622, train_bce_loss: 0.8742, train_bce_dl_loss: 0.9622, step time: 0.4782\n",
      "batch: 13/17, train_dl_loss: 0.9766, train_bce_loss: 0.8724, train_bce_dl_loss: 0.9766, step time: 0.3904\n",
      "batch: 14/17, train_dl_loss: 0.9662, train_bce_loss: 0.8802, train_bce_dl_loss: 0.9662, step time: 0.4165\n",
      "batch: 15/17, train_dl_loss: 0.9578, train_bce_loss: 0.8806, train_bce_dl_loss: 0.9578, step time: 0.3694\n",
      "batch: 16/17, train_dl_loss: 0.9657, train_bce_loss: 0.8799, train_bce_dl_loss: 0.9657, step time: 0.4242\n",
      "batch: 17/17, train_dl_loss: 0.9583, train_bce_loss: 0.8834, train_bce_dl_loss: 0.9583, step time: 0.1084\n",
      "LOSS train DiceLoss: 0.9635, LOSS train BCE: 0.8722, LOSS train BCE-DiceLoss: 0.9635, LOSS val DiceLoss: 0.9542, LOSS val BCE: 0.8779, LOSS val BCE-DiceLoss: 0.9542, METRIC val: 0.0334\n",
      "time consuming of epoch 4 is: 366.3251\n",
      "----------\n",
      "EPOCH 5/80\n",
      "batch: 0/17, train_dl_loss: 0.9549, train_bce_loss: 0.8821, train_bce_dl_loss: 0.9549, step time: 0.4271\n",
      "batch: 1/17, train_dl_loss: 0.9606, train_bce_loss: 0.8906, train_bce_dl_loss: 0.9606, step time: 0.3753\n",
      "batch: 2/17, train_dl_loss: 0.9610, train_bce_loss: 0.8820, train_bce_dl_loss: 0.9610, step time: 0.4353\n",
      "batch: 3/17, train_dl_loss: 0.9630, train_bce_loss: 0.8848, train_bce_dl_loss: 0.9630, step time: 0.3698\n",
      "batch: 4/17, train_dl_loss: 0.9382, train_bce_loss: 0.8826, train_bce_dl_loss: 0.9382, step time: 0.4292\n",
      "batch: 5/17, train_dl_loss: 0.9359, train_bce_loss: 0.8889, train_bce_dl_loss: 0.9359, step time: 0.4412\n",
      "batch: 6/17, train_dl_loss: 0.9581, train_bce_loss: 0.8939, train_bce_dl_loss: 0.9581, step time: 0.4385\n",
      "batch: 7/17, train_dl_loss: 0.9351, train_bce_loss: 0.8889, train_bce_dl_loss: 0.9351, step time: 0.3741\n",
      "batch: 8/17, train_dl_loss: 0.9428, train_bce_loss: 0.8911, train_bce_dl_loss: 0.9428, step time: 0.4314\n",
      "batch: 9/17, train_dl_loss: 0.9435, train_bce_loss: 0.8992, train_bce_dl_loss: 0.9435, step time: 0.4233\n",
      "batch: 10/17, train_dl_loss: 0.9432, train_bce_loss: 0.8984, train_bce_dl_loss: 0.9432, step time: 0.4344\n",
      "batch: 11/17, train_dl_loss: 0.9194, train_bce_loss: 0.8934, train_bce_dl_loss: 0.9194, step time: 0.4461\n",
      "batch: 12/17, train_dl_loss: 0.9390, train_bce_loss: 0.9000, train_bce_dl_loss: 0.9390, step time: 0.4231\n",
      "batch: 13/17, train_dl_loss: 0.9663, train_bce_loss: 0.9045, train_bce_dl_loss: 0.9663, step time: 0.4554\n",
      "batch: 14/17, train_dl_loss: 0.9552, train_bce_loss: 0.9048, train_bce_dl_loss: 0.9552, step time: 0.4230\n",
      "batch: 15/17, train_dl_loss: 0.9408, train_bce_loss: 0.9030, train_bce_dl_loss: 0.9408, step time: 0.3702\n",
      "batch: 16/17, train_dl_loss: 0.9430, train_bce_loss: 0.9125, train_bce_dl_loss: 0.9430, step time: 0.4255\n",
      "batch: 17/17, train_dl_loss: 0.9640, train_bce_loss: 0.9118, train_bce_dl_loss: 0.9640, step time: 0.1094\n",
      "LOSS train DiceLoss: 0.9480, LOSS train BCE: 0.8951, LOSS train BCE-DiceLoss: 0.9480, LOSS val DiceLoss: 0.9367, LOSS val BCE: 0.9069, LOSS val BCE-DiceLoss: 0.9367, METRIC val: 0.0462\n",
      "time consuming of epoch 5 is: 408.6991\n",
      "----------\n",
      "EPOCH 6/80\n",
      "batch: 0/17, train_dl_loss: 0.9329, train_bce_loss: 0.9151, train_bce_dl_loss: 0.9329, step time: 0.4356\n",
      "batch: 1/17, train_dl_loss: 0.9300, train_bce_loss: 0.9111, train_bce_dl_loss: 0.9300, step time: 0.3752\n",
      "batch: 2/17, train_dl_loss: 0.9424, train_bce_loss: 0.9166, train_bce_dl_loss: 0.9424, step time: 0.4170\n",
      "batch: 3/17, train_dl_loss: 0.9508, train_bce_loss: 0.9176, train_bce_dl_loss: 0.9508, step time: 0.3781\n",
      "batch: 4/17, train_dl_loss: 0.9139, train_bce_loss: 0.9201, train_bce_dl_loss: 0.9139, step time: 0.4182\n",
      "batch: 5/17, train_dl_loss: 0.9148, train_bce_loss: 0.9215, train_bce_dl_loss: 0.9148, step time: 0.3719\n",
      "batch: 6/17, train_dl_loss: 0.9456, train_bce_loss: 0.9261, train_bce_dl_loss: 0.9456, step time: 0.4117\n",
      "batch: 7/17, train_dl_loss: 0.9159, train_bce_loss: 0.9178, train_bce_dl_loss: 0.9159, step time: 0.3659\n",
      "batch: 8/17, train_dl_loss: 0.9315, train_bce_loss: 0.9296, train_bce_dl_loss: 0.9315, step time: 0.4343\n",
      "batch: 9/17, train_dl_loss: 0.9308, train_bce_loss: 0.9287, train_bce_dl_loss: 0.9308, step time: 0.3788\n",
      "batch: 10/17, train_dl_loss: 0.9226, train_bce_loss: 0.9337, train_bce_dl_loss: 0.9226, step time: 0.4244\n",
      "batch: 11/17, train_dl_loss: 0.9055, train_bce_loss: 0.9238, train_bce_dl_loss: 0.9055, step time: 0.4191\n",
      "batch: 12/17, train_dl_loss: 0.9264, train_bce_loss: 0.9370, train_bce_dl_loss: 0.9264, step time: 0.4333\n",
      "batch: 13/17, train_dl_loss: 0.9500, train_bce_loss: 0.9347, train_bce_dl_loss: 0.9500, step time: 0.3742\n",
      "batch: 14/17, train_dl_loss: 0.9299, train_bce_loss: 0.9340, train_bce_dl_loss: 0.9299, step time: 0.4146\n",
      "batch: 15/17, train_dl_loss: 0.9234, train_bce_loss: 0.9360, train_bce_dl_loss: 0.9234, step time: 0.3756\n",
      "batch: 16/17, train_dl_loss: 0.9223, train_bce_loss: 0.9488, train_bce_dl_loss: 0.9223, step time: 0.4079\n",
      "batch: 17/17, train_dl_loss: 0.9084, train_bce_loss: 0.9506, train_bce_dl_loss: 0.9084, step time: 0.1108\n",
      "LOSS train DiceLoss: 0.9276, LOSS train BCE: 0.9279, LOSS train BCE-DiceLoss: 0.9276, LOSS val DiceLoss: 0.9303, LOSS val BCE: 0.9391, LOSS val BCE-DiceLoss: 0.9303, METRIC val: 0.0376\n",
      "time consuming of epoch 6 is: 376.3415\n",
      "----------\n",
      "EPOCH 7/80\n",
      "batch: 0/17, train_dl_loss: 0.9348, train_bce_loss: 0.9552, train_bce_dl_loss: 0.9348, step time: 0.4409\n",
      "batch: 1/17, train_dl_loss: 0.9150, train_bce_loss: 0.9464, train_bce_dl_loss: 0.9150, step time: 0.3757\n",
      "batch: 2/17, train_dl_loss: 0.9346, train_bce_loss: 0.9527, train_bce_dl_loss: 0.9346, step time: 0.4161\n",
      "batch: 3/17, train_dl_loss: 0.9330, train_bce_loss: 0.9551, train_bce_dl_loss: 0.9330, step time: 0.3696\n",
      "batch: 4/17, train_dl_loss: 0.8874, train_bce_loss: 0.9439, train_bce_dl_loss: 0.8874, step time: 0.4335\n",
      "batch: 5/17, train_dl_loss: 0.8937, train_bce_loss: 0.9572, train_bce_dl_loss: 0.8937, step time: 0.3766\n",
      "batch: 6/17, train_dl_loss: 0.9163, train_bce_loss: 0.9561, train_bce_dl_loss: 0.9163, step time: 0.4081\n",
      "batch: 7/17, train_dl_loss: 0.8847, train_bce_loss: 0.9513, train_bce_dl_loss: 0.8847, step time: 0.3686\n",
      "batch: 8/17, train_dl_loss: 0.9018, train_bce_loss: 0.9548, train_bce_dl_loss: 0.9018, step time: 0.4265\n",
      "batch: 9/17, train_dl_loss: 0.9043, train_bce_loss: 0.9701, train_bce_dl_loss: 0.9043, step time: 0.3714\n",
      "batch: 10/17, train_dl_loss: 0.8892, train_bce_loss: 0.9726, train_bce_dl_loss: 0.8892, step time: 0.4239\n",
      "batch: 11/17, train_dl_loss: 0.8706, train_bce_loss: 0.9508, train_bce_dl_loss: 0.8706, step time: 0.3756\n",
      "batch: 12/17, train_dl_loss: 0.8948, train_bce_loss: 0.9669, train_bce_dl_loss: 0.8948, step time: 0.4098\n",
      "batch: 13/17, train_dl_loss: 0.9312, train_bce_loss: 0.9744, train_bce_dl_loss: 0.9312, step time: 0.3704\n",
      "batch: 14/17, train_dl_loss: 0.9032, train_bce_loss: 0.9787, train_bce_dl_loss: 0.9032, step time: 0.4257\n",
      "batch: 15/17, train_dl_loss: 0.8814, train_bce_loss: 0.9821, train_bce_dl_loss: 0.8814, step time: 0.3717\n",
      "batch: 16/17, train_dl_loss: 0.8978, train_bce_loss: 0.9734, train_bce_dl_loss: 0.8978, step time: 0.4174\n",
      "batch: 17/17, train_dl_loss: 0.8806, train_bce_loss: 0.9756, train_bce_dl_loss: 0.8806, step time: 0.1100\n",
      "LOSS train DiceLoss: 0.9030, LOSS train BCE: 0.9621, LOSS train BCE-DiceLoss: 0.9030, LOSS val DiceLoss: 0.8964, LOSS val BCE: 0.9739, LOSS val BCE-DiceLoss: 0.8964, METRIC val: 0.0594\n",
      "time consuming of epoch 7 is: 494.5432\n",
      "----------\n",
      "EPOCH 8/80\n",
      "batch: 0/17, train_dl_loss: 0.8926, train_bce_loss: 0.9810, train_bce_dl_loss: 0.8926, step time: 0.4252\n",
      "batch: 1/17, train_dl_loss: 0.8908, train_bce_loss: 0.9811, train_bce_dl_loss: 0.8908, step time: 0.4299\n",
      "batch: 2/17, train_dl_loss: 0.9028, train_bce_loss: 0.9891, train_bce_dl_loss: 0.9028, step time: 0.4314\n",
      "batch: 3/17, train_dl_loss: 0.8976, train_bce_loss: 0.9846, train_bce_dl_loss: 0.8976, step time: 0.3754\n",
      "batch: 4/17, train_dl_loss: 0.8542, train_bce_loss: 0.9892, train_bce_dl_loss: 0.8542, step time: 0.4218\n",
      "batch: 5/17, train_dl_loss: 0.8737, train_bce_loss: 0.9943, train_bce_dl_loss: 0.8737, step time: 0.3779\n",
      "batch: 6/17, train_dl_loss: 0.8938, train_bce_loss: 0.9991, train_bce_dl_loss: 0.8938, step time: 0.4375\n",
      "batch: 7/17, train_dl_loss: 0.8488, train_bce_loss: 0.9997, train_bce_dl_loss: 0.8488, step time: 0.3700\n",
      "batch: 8/17, train_dl_loss: 0.8720, train_bce_loss: 0.9908, train_bce_dl_loss: 0.8720, step time: 0.4231\n",
      "batch: 9/17, train_dl_loss: 0.8600, train_bce_loss: 1.0017, train_bce_dl_loss: 0.8600, step time: 0.3705\n",
      "batch: 10/17, train_dl_loss: 0.8599, train_bce_loss: 1.0078, train_bce_dl_loss: 0.8599, step time: 0.5154\n",
      "batch: 11/17, train_dl_loss: 0.8408, train_bce_loss: 1.0092, train_bce_dl_loss: 0.8408, step time: 0.4372\n",
      "batch: 12/17, train_dl_loss: 0.8656, train_bce_loss: 1.0041, train_bce_dl_loss: 0.8656, step time: 0.4172\n",
      "batch: 13/17, train_dl_loss: 0.9284, train_bce_loss: 1.0133, train_bce_dl_loss: 0.9284, step time: 0.3701\n",
      "batch: 14/17, train_dl_loss: 0.8814, train_bce_loss: 1.0139, train_bce_dl_loss: 0.8814, step time: 0.4292\n",
      "batch: 15/17, train_dl_loss: 0.8672, train_bce_loss: 1.0097, train_bce_dl_loss: 0.8672, step time: 0.3683\n",
      "batch: 16/17, train_dl_loss: 0.8715, train_bce_loss: 1.0159, train_bce_dl_loss: 0.8715, step time: 0.4255\n",
      "batch: 17/17, train_dl_loss: 0.8987, train_bce_loss: 1.0273, train_bce_dl_loss: 0.8987, step time: 0.1102\n",
      "LOSS train DiceLoss: 0.8778, LOSS train BCE: 1.0007, LOSS train BCE-DiceLoss: 0.8778, LOSS val DiceLoss: 0.8764, LOSS val BCE: 1.0163, LOSS val BCE-DiceLoss: 0.8764, METRIC val: 0.0685\n",
      "time consuming of epoch 8 is: 399.7459\n",
      "----------\n",
      "EPOCH 9/80\n",
      "batch: 0/17, train_dl_loss: 0.8623, train_bce_loss: 1.0224, train_bce_dl_loss: 0.8623, step time: 0.4231\n",
      "batch: 1/17, train_dl_loss: 0.8473, train_bce_loss: 1.0245, train_bce_dl_loss: 0.8473, step time: 0.3748\n",
      "batch: 2/17, train_dl_loss: 0.8776, train_bce_loss: 1.0287, train_bce_dl_loss: 0.8776, step time: 0.4148\n",
      "batch: 3/17, train_dl_loss: 0.8910, train_bce_loss: 1.0298, train_bce_dl_loss: 0.8910, step time: 0.3733\n",
      "batch: 4/17, train_dl_loss: 0.8544, train_bce_loss: 1.0424, train_bce_dl_loss: 0.8544, step time: 0.4323\n",
      "batch: 5/17, train_dl_loss: 0.8388, train_bce_loss: 1.0309, train_bce_dl_loss: 0.8388, step time: 0.3866\n",
      "batch: 6/17, train_dl_loss: 0.8619, train_bce_loss: 1.0424, train_bce_dl_loss: 0.8619, step time: 0.4404\n",
      "batch: 7/17, train_dl_loss: 0.8298, train_bce_loss: 1.0470, train_bce_dl_loss: 0.8298, step time: 0.3777\n",
      "batch: 8/17, train_dl_loss: 0.8594, train_bce_loss: 1.0469, train_bce_dl_loss: 0.8594, step time: 0.4206\n",
      "batch: 9/17, train_dl_loss: 0.8735, train_bce_loss: 1.0496, train_bce_dl_loss: 0.8735, step time: 0.3735\n",
      "batch: 10/17, train_dl_loss: 0.8372, train_bce_loss: 1.0436, train_bce_dl_loss: 0.8372, step time: 0.4346\n",
      "batch: 11/17, train_dl_loss: 0.8252, train_bce_loss: 1.0396, train_bce_dl_loss: 0.8252, step time: 0.3803\n",
      "batch: 12/17, train_dl_loss: 0.8412, train_bce_loss: 1.0422, train_bce_dl_loss: 0.8412, step time: 0.4151\n",
      "batch: 13/17, train_dl_loss: 0.8912, train_bce_loss: 1.0506, train_bce_dl_loss: 0.8912, step time: 0.3801\n",
      "batch: 14/17, train_dl_loss: 0.8702, train_bce_loss: 1.0623, train_bce_dl_loss: 0.8702, step time: 0.4241\n",
      "batch: 15/17, train_dl_loss: 0.8410, train_bce_loss: 1.0472, train_bce_dl_loss: 0.8410, step time: 0.3748\n",
      "batch: 16/17, train_dl_loss: 0.8371, train_bce_loss: 1.0542, train_bce_dl_loss: 0.8371, step time: 0.4166\n",
      "batch: 17/17, train_dl_loss: 0.8212, train_bce_loss: 1.0666, train_bce_dl_loss: 0.8212, step time: 0.1107\n",
      "LOSS train DiceLoss: 0.8534, LOSS train BCE: 1.0428, LOSS train BCE-DiceLoss: 0.8534, LOSS val DiceLoss: 0.8489, LOSS val BCE: 1.0544, LOSS val BCE-DiceLoss: 0.8489, METRIC val: 0.0787\n",
      "time consuming of epoch 9 is: 476.1816\n",
      "----------\n",
      "EPOCH 10/80\n",
      "batch: 0/17, train_dl_loss: 0.8197, train_bce_loss: 1.0546, train_bce_dl_loss: 0.8197, step time: 0.4427\n",
      "batch: 1/17, train_dl_loss: 0.8237, train_bce_loss: 1.0649, train_bce_dl_loss: 0.8237, step time: 0.3716\n",
      "batch: 2/17, train_dl_loss: 0.8579, train_bce_loss: 1.0580, train_bce_dl_loss: 0.8579, step time: 0.4373\n",
      "batch: 3/17, train_dl_loss: 0.8601, train_bce_loss: 1.0658, train_bce_dl_loss: 0.8601, step time: 0.3674\n",
      "batch: 4/17, train_dl_loss: 0.8275, train_bce_loss: 1.0717, train_bce_dl_loss: 0.8275, step time: 0.4412\n",
      "batch: 5/17, train_dl_loss: 0.8285, train_bce_loss: 1.0729, train_bce_dl_loss: 0.8285, step time: 0.3806\n",
      "batch: 6/17, train_dl_loss: 0.8520, train_bce_loss: 1.0765, train_bce_dl_loss: 0.8520, step time: 0.4204\n",
      "batch: 7/17, train_dl_loss: 0.8193, train_bce_loss: 1.0679, train_bce_dl_loss: 0.8193, step time: 0.3727\n",
      "batch: 8/17, train_dl_loss: 0.8231, train_bce_loss: 1.0839, train_bce_dl_loss: 0.8231, step time: 0.4161\n",
      "batch: 9/17, train_dl_loss: 0.8408, train_bce_loss: 1.0869, train_bce_dl_loss: 0.8408, step time: 0.3681\n",
      "batch: 10/17, train_dl_loss: 0.8297, train_bce_loss: 1.0803, train_bce_dl_loss: 0.8297, step time: 0.4314\n",
      "batch: 11/17, train_dl_loss: 0.8143, train_bce_loss: 1.0736, train_bce_dl_loss: 0.8143, step time: 0.4476\n",
      "batch: 12/17, train_dl_loss: 0.8250, train_bce_loss: 1.0816, train_bce_dl_loss: 0.8250, step time: 0.4344\n",
      "batch: 13/17, train_dl_loss: 0.8769, train_bce_loss: 1.0887, train_bce_dl_loss: 0.8769, step time: 0.3745\n",
      "batch: 14/17, train_dl_loss: 0.8346, train_bce_loss: 1.0897, train_bce_dl_loss: 0.8346, step time: 0.4317\n",
      "batch: 15/17, train_dl_loss: 0.8122, train_bce_loss: 1.0932, train_bce_dl_loss: 0.8122, step time: 0.3821\n",
      "batch: 16/17, train_dl_loss: 0.8050, train_bce_loss: 1.0951, train_bce_dl_loss: 0.8050, step time: 0.4267\n",
      "batch: 17/17, train_dl_loss: 0.8072, train_bce_loss: 1.0871, train_bce_dl_loss: 0.8072, step time: 0.1108\n",
      "LOSS train DiceLoss: 0.8310, LOSS train BCE: 1.0774, LOSS train BCE-DiceLoss: 0.8310, LOSS val DiceLoss: 0.8501, LOSS val BCE: 1.0903, LOSS val BCE-DiceLoss: 0.8501, METRIC val: 0.0673\n",
      "time consuming of epoch 10 is: 439.3249\n",
      "----------\n",
      "EPOCH 11/80\n",
      "batch: 0/17, train_dl_loss: 0.7961, train_bce_loss: 1.0987, train_bce_dl_loss: 0.7961, step time: 0.4294\n",
      "batch: 1/17, train_dl_loss: 0.8039, train_bce_loss: 1.0996, train_bce_dl_loss: 0.8039, step time: 0.3808\n",
      "batch: 2/17, train_dl_loss: 0.8538, train_bce_loss: 1.1022, train_bce_dl_loss: 0.8538, step time: 0.4250\n",
      "batch: 3/17, train_dl_loss: 0.8356, train_bce_loss: 1.1019, train_bce_dl_loss: 0.8356, step time: 0.3733\n",
      "batch: 4/17, train_dl_loss: 0.8043, train_bce_loss: 1.1023, train_bce_dl_loss: 0.8043, step time: 0.4353\n",
      "batch: 5/17, train_dl_loss: 0.7888, train_bce_loss: 1.1131, train_bce_dl_loss: 0.7888, step time: 0.3746\n",
      "batch: 6/17, train_dl_loss: 0.8210, train_bce_loss: 1.1058, train_bce_dl_loss: 0.8210, step time: 0.4180\n",
      "batch: 7/17, train_dl_loss: 0.7884, train_bce_loss: 1.1102, train_bce_dl_loss: 0.7884, step time: 0.3766\n",
      "batch: 8/17, train_dl_loss: 0.8154, train_bce_loss: 1.1041, train_bce_dl_loss: 0.8154, step time: 0.4164\n",
      "batch: 9/17, train_dl_loss: 0.8154, train_bce_loss: 1.1148, train_bce_dl_loss: 0.8154, step time: 0.3696\n",
      "batch: 10/17, train_dl_loss: 0.8127, train_bce_loss: 1.1062, train_bce_dl_loss: 0.8127, step time: 0.4200\n",
      "batch: 11/17, train_dl_loss: 0.7753, train_bce_loss: 1.0892, train_bce_dl_loss: 0.7753, step time: 0.4266\n",
      "batch: 12/17, train_dl_loss: 0.8133, train_bce_loss: 1.1140, train_bce_dl_loss: 0.8133, step time: 0.4207\n",
      "batch: 13/17, train_dl_loss: 0.8695, train_bce_loss: 1.1163, train_bce_dl_loss: 0.8695, step time: 0.4204\n",
      "batch: 14/17, train_dl_loss: 0.8333, train_bce_loss: 1.1205, train_bce_dl_loss: 0.8333, step time: 0.4375\n",
      "batch: 15/17, train_dl_loss: 0.7934, train_bce_loss: 1.1083, train_bce_dl_loss: 0.7934, step time: 0.3758\n",
      "batch: 16/17, train_dl_loss: 0.7861, train_bce_loss: 1.1130, train_bce_dl_loss: 0.7861, step time: 0.4098\n",
      "batch: 17/17, train_dl_loss: 0.7853, train_bce_loss: 1.1169, train_bce_dl_loss: 0.7853, step time: 0.1108\n",
      "LOSS train DiceLoss: 0.8107, LOSS train BCE: 1.1076, LOSS train BCE-DiceLoss: 0.8107, LOSS val DiceLoss: 0.8243, LOSS val BCE: 1.1156, LOSS val BCE-DiceLoss: 0.8243, METRIC val: 0.1048\n",
      "time consuming of epoch 11 is: 421.9696\n",
      "----------\n",
      "EPOCH 12/80\n",
      "batch: 0/17, train_dl_loss: 0.7997, train_bce_loss: 1.1185, train_bce_dl_loss: 0.7997, step time: 0.4347\n",
      "batch: 1/17, train_dl_loss: 0.7888, train_bce_loss: 1.1358, train_bce_dl_loss: 0.7888, step time: 0.3774\n",
      "batch: 2/17, train_dl_loss: 0.8270, train_bce_loss: 1.1191, train_bce_dl_loss: 0.8270, step time: 0.4379\n",
      "batch: 3/17, train_dl_loss: 0.8211, train_bce_loss: 1.1196, train_bce_dl_loss: 0.8211, step time: 0.4401\n",
      "batch: 4/17, train_dl_loss: 0.7833, train_bce_loss: 1.1217, train_bce_dl_loss: 0.7833, step time: 0.4189\n",
      "batch: 5/17, train_dl_loss: 0.7799, train_bce_loss: 1.1267, train_bce_dl_loss: 0.7799, step time: 0.3755\n",
      "batch: 6/17, train_dl_loss: 0.8092, train_bce_loss: 1.1358, train_bce_dl_loss: 0.8092, step time: 0.4244\n",
      "batch: 7/17, train_dl_loss: 0.7562, train_bce_loss: 1.1268, train_bce_dl_loss: 0.7562, step time: 0.3722\n",
      "batch: 8/17, train_dl_loss: 0.7943, train_bce_loss: 1.1321, train_bce_dl_loss: 0.7943, step time: 0.4193\n",
      "batch: 9/17, train_dl_loss: 0.7868, train_bce_loss: 1.1396, train_bce_dl_loss: 0.7868, step time: 0.3789\n",
      "batch: 10/17, train_dl_loss: 0.7937, train_bce_loss: 1.1393, train_bce_dl_loss: 0.7937, step time: 0.4208\n",
      "batch: 11/17, train_dl_loss: 0.7653, train_bce_loss: 1.1204, train_bce_dl_loss: 0.7653, step time: 0.3786\n",
      "batch: 12/17, train_dl_loss: 0.7742, train_bce_loss: 1.1253, train_bce_dl_loss: 0.7742, step time: 0.4225\n",
      "batch: 13/17, train_dl_loss: 0.8587, train_bce_loss: 1.1363, train_bce_dl_loss: 0.8587, step time: 0.3749\n",
      "batch: 14/17, train_dl_loss: 0.8177, train_bce_loss: 1.1517, train_bce_dl_loss: 0.8177, step time: 0.4279\n",
      "batch: 15/17, train_dl_loss: 0.7824, train_bce_loss: 1.1446, train_bce_dl_loss: 0.7824, step time: 0.3774\n",
      "batch: 16/17, train_dl_loss: 0.7740, train_bce_loss: 1.1376, train_bce_dl_loss: 0.7740, step time: 0.4098\n",
      "batch: 17/17, train_dl_loss: 0.7548, train_bce_loss: 1.1338, train_bce_dl_loss: 0.7548, step time: 0.1111\n",
      "LOSS train DiceLoss: 0.7926, LOSS train BCE: 1.1314, LOSS train BCE-DiceLoss: 0.7926, LOSS val DiceLoss: 0.8167, LOSS val BCE: 1.1364, LOSS val BCE-DiceLoss: 0.8167, METRIC val: 0.1295\n",
      "time consuming of epoch 12 is: 414.7638\n",
      "----------\n",
      "EPOCH 13/80\n",
      "batch: 0/17, train_dl_loss: 0.7493, train_bce_loss: 1.1314, train_bce_dl_loss: 0.7493, step time: 0.4411\n",
      "batch: 1/17, train_dl_loss: 0.7785, train_bce_loss: 1.1410, train_bce_dl_loss: 0.7785, step time: 0.3776\n",
      "batch: 2/17, train_dl_loss: 0.8258, train_bce_loss: 1.1327, train_bce_dl_loss: 0.8258, step time: 0.4162\n",
      "batch: 3/17, train_dl_loss: 0.8342, train_bce_loss: 1.1433, train_bce_dl_loss: 0.8342, step time: 0.3749\n",
      "batch: 4/17, train_dl_loss: 0.7401, train_bce_loss: 1.1466, train_bce_dl_loss: 0.7401, step time: 0.4289\n",
      "batch: 5/17, train_dl_loss: 0.7741, train_bce_loss: 1.1382, train_bce_dl_loss: 0.7741, step time: 0.3735\n",
      "batch: 6/17, train_dl_loss: 0.8021, train_bce_loss: 1.1561, train_bce_dl_loss: 0.8021, step time: 0.4388\n",
      "batch: 7/17, train_dl_loss: 0.7383, train_bce_loss: 1.1438, train_bce_dl_loss: 0.7383, step time: 0.3848\n",
      "batch: 8/17, train_dl_loss: 0.7644, train_bce_loss: 1.1525, train_bce_dl_loss: 0.7644, step time: 0.4239\n",
      "batch: 9/17, train_dl_loss: 0.7569, train_bce_loss: 1.1670, train_bce_dl_loss: 0.7569, step time: 0.3878\n",
      "batch: 10/17, train_dl_loss: 0.7698, train_bce_loss: 1.1600, train_bce_dl_loss: 0.7698, step time: 0.4374\n",
      "batch: 11/17, train_dl_loss: 0.7298, train_bce_loss: 1.1312, train_bce_dl_loss: 0.7298, step time: 0.4383\n",
      "batch: 12/17, train_dl_loss: 0.7940, train_bce_loss: 1.1618, train_bce_dl_loss: 0.7940, step time: 0.4376\n",
      "batch: 13/17, train_dl_loss: 0.8288, train_bce_loss: 1.1542, train_bce_dl_loss: 0.8288, step time: 0.3841\n",
      "batch: 14/17, train_dl_loss: 0.8254, train_bce_loss: 1.1586, train_bce_dl_loss: 0.8254, step time: 0.4207\n",
      "batch: 15/17, train_dl_loss: 0.7391, train_bce_loss: 1.1539, train_bce_dl_loss: 0.7391, step time: 0.3787\n",
      "batch: 16/17, train_dl_loss: 0.7420, train_bce_loss: 1.1565, train_bce_dl_loss: 0.7420, step time: 0.4122\n",
      "batch: 17/17, train_dl_loss: 0.8351, train_bce_loss: 1.1739, train_bce_dl_loss: 0.8351, step time: 0.1119\n",
      "LOSS train DiceLoss: 0.7793, LOSS train BCE: 1.1501, LOSS train BCE-DiceLoss: 0.7793, LOSS val DiceLoss: 0.7970, LOSS val BCE: 1.1514, LOSS val BCE-DiceLoss: 0.7970, METRIC val: 0.1607\n",
      "time consuming of epoch 13 is: 466.7747\n",
      "----------\n",
      "EPOCH 14/80\n",
      "batch: 0/17, train_dl_loss: 0.7316, train_bce_loss: 1.1484, train_bce_dl_loss: 0.7316, step time: 0.4154\n",
      "batch: 1/17, train_dl_loss: 0.7776, train_bce_loss: 1.1618, train_bce_dl_loss: 0.7776, step time: 0.3730\n",
      "batch: 2/17, train_dl_loss: 0.8028, train_bce_loss: 1.1551, train_bce_dl_loss: 0.8028, step time: 0.4150\n",
      "batch: 3/17, train_dl_loss: 0.8242, train_bce_loss: 1.1565, train_bce_dl_loss: 0.8242, step time: 0.3758\n",
      "batch: 4/17, train_dl_loss: 0.7118, train_bce_loss: 1.1585, train_bce_dl_loss: 0.7118, step time: 0.4366\n",
      "batch: 5/17, train_dl_loss: 0.7365, train_bce_loss: 1.1583, train_bce_dl_loss: 0.7365, step time: 0.4269\n",
      "batch: 6/17, train_dl_loss: 0.7509, train_bce_loss: 1.1691, train_bce_dl_loss: 0.7509, step time: 0.4224\n",
      "batch: 7/17, train_dl_loss: 0.7208, train_bce_loss: 1.1577, train_bce_dl_loss: 0.7208, step time: 0.3722\n",
      "batch: 8/17, train_dl_loss: 0.7330, train_bce_loss: 1.1684, train_bce_dl_loss: 0.7330, step time: 0.4255\n",
      "batch: 9/17, train_dl_loss: 0.7443, train_bce_loss: 1.1763, train_bce_dl_loss: 0.7443, step time: 0.3727\n",
      "batch: 10/17, train_dl_loss: 0.7704, train_bce_loss: 1.1769, train_bce_dl_loss: 0.7704, step time: 0.4207\n",
      "batch: 11/17, train_dl_loss: 0.7391, train_bce_loss: 1.1710, train_bce_dl_loss: 0.7391, step time: 0.4182\n",
      "batch: 12/17, train_dl_loss: 0.7585, train_bce_loss: 1.1621, train_bce_dl_loss: 0.7585, step time: 0.4151\n",
      "batch: 13/17, train_dl_loss: 0.8282, train_bce_loss: 1.1730, train_bce_dl_loss: 0.8282, step time: 0.3745\n",
      "batch: 14/17, train_dl_loss: 0.7857, train_bce_loss: 1.1897, train_bce_dl_loss: 0.7857, step time: 0.4222\n",
      "batch: 15/17, train_dl_loss: 0.7220, train_bce_loss: 1.1758, train_bce_dl_loss: 0.7220, step time: 0.3792\n",
      "batch: 16/17, train_dl_loss: 0.7373, train_bce_loss: 1.1802, train_bce_dl_loss: 0.7373, step time: 0.4274\n",
      "batch: 17/17, train_dl_loss: 0.6931, train_bce_loss: 1.1856, train_bce_dl_loss: 0.6931, step time: 0.1111\n",
      "LOSS train DiceLoss: 0.7538, LOSS train BCE: 1.1680, LOSS train BCE-DiceLoss: 0.7538, LOSS val DiceLoss: 0.7745, LOSS val BCE: 1.1756, LOSS val BCE-DiceLoss: 0.7745, METRIC val: 0.1857\n",
      "time consuming of epoch 14 is: 517.3895\n",
      "----------\n",
      "EPOCH 15/80\n",
      "batch: 0/17, train_dl_loss: 0.7123, train_bce_loss: 1.1751, train_bce_dl_loss: 0.7123, step time: 0.4374\n",
      "batch: 1/17, train_dl_loss: 0.7522, train_bce_loss: 1.1873, train_bce_dl_loss: 0.7522, step time: 0.3701\n",
      "batch: 2/17, train_dl_loss: 0.8061, train_bce_loss: 1.1833, train_bce_dl_loss: 0.8061, step time: 0.4358\n",
      "batch: 3/17, train_dl_loss: 0.7937, train_bce_loss: 1.1903, train_bce_dl_loss: 0.7937, step time: 0.3741\n",
      "batch: 4/17, train_dl_loss: 0.7180, train_bce_loss: 1.1807, train_bce_dl_loss: 0.7180, step time: 0.4311\n",
      "batch: 5/17, train_dl_loss: 0.7125, train_bce_loss: 1.1904, train_bce_dl_loss: 0.7125, step time: 0.3779\n",
      "batch: 6/17, train_dl_loss: 0.7502, train_bce_loss: 1.1996, train_bce_dl_loss: 0.7502, step time: 0.4280\n",
      "batch: 7/17, train_dl_loss: 0.7148, train_bce_loss: 1.1832, train_bce_dl_loss: 0.7148, step time: 0.3746\n",
      "batch: 8/17, train_dl_loss: 0.7245, train_bce_loss: 1.1746, train_bce_dl_loss: 0.7245, step time: 0.4256\n",
      "batch: 9/17, train_dl_loss: 0.7617, train_bce_loss: 1.2082, train_bce_dl_loss: 0.7617, step time: 0.3791\n",
      "batch: 10/17, train_dl_loss: 0.7745, train_bce_loss: 1.1882, train_bce_dl_loss: 0.7745, step time: 0.4183\n",
      "batch: 11/17, train_dl_loss: 0.6861, train_bce_loss: 1.1805, train_bce_dl_loss: 0.6861, step time: 0.4359\n",
      "batch: 12/17, train_dl_loss: 0.7151, train_bce_loss: 1.1909, train_bce_dl_loss: 0.7151, step time: 0.4245\n",
      "batch: 13/17, train_dl_loss: 0.8289, train_bce_loss: 1.1985, train_bce_dl_loss: 0.8289, step time: 0.3908\n",
      "batch: 14/17, train_dl_loss: 0.7516, train_bce_loss: 1.2053, train_bce_dl_loss: 0.7516, step time: 0.4280\n",
      "batch: 15/17, train_dl_loss: 0.7379, train_bce_loss: 1.2060, train_bce_dl_loss: 0.7379, step time: 0.3742\n",
      "batch: 16/17, train_dl_loss: 0.7137, train_bce_loss: 1.2004, train_bce_dl_loss: 0.7137, step time: 0.4082\n",
      "batch: 17/17, train_dl_loss: 0.6624, train_bce_loss: 1.1979, train_bce_dl_loss: 0.6624, step time: 0.1108\n",
      "LOSS train DiceLoss: 0.7398, LOSS train BCE: 1.1911, LOSS train BCE-DiceLoss: 0.7398, LOSS val DiceLoss: 0.7595, LOSS val BCE: 1.1984, LOSS val BCE-DiceLoss: 0.7595, METRIC val: 0.2069\n",
      "time consuming of epoch 15 is: 516.6021\n",
      "----------\n",
      "EPOCH 16/80\n",
      "batch: 0/17, train_dl_loss: 0.6848, train_bce_loss: 1.1899, train_bce_dl_loss: 0.6848, step time: 0.4258\n",
      "batch: 1/17, train_dl_loss: 0.7289, train_bce_loss: 1.2064, train_bce_dl_loss: 0.7289, step time: 0.3755\n",
      "batch: 2/17, train_dl_loss: 0.8032, train_bce_loss: 1.1964, train_bce_dl_loss: 0.8032, step time: 0.4348\n",
      "batch: 3/17, train_dl_loss: 0.7375, train_bce_loss: 1.2011, train_bce_dl_loss: 0.7375, step time: 0.3753\n",
      "batch: 4/17, train_dl_loss: 0.6699, train_bce_loss: 1.2002, train_bce_dl_loss: 0.6699, step time: 0.4390\n",
      "batch: 5/17, train_dl_loss: 0.6829, train_bce_loss: 1.2040, train_bce_dl_loss: 0.6829, step time: 0.3851\n",
      "batch: 6/17, train_dl_loss: 0.7352, train_bce_loss: 1.2071, train_bce_dl_loss: 0.7352, step time: 0.4358\n",
      "batch: 7/17, train_dl_loss: 0.6723, train_bce_loss: 1.2077, train_bce_dl_loss: 0.6723, step time: 0.3726\n",
      "batch: 8/17, train_dl_loss: 0.7020, train_bce_loss: 1.2156, train_bce_dl_loss: 0.7020, step time: 0.4211\n",
      "batch: 9/17, train_dl_loss: 0.7268, train_bce_loss: 1.2270, train_bce_dl_loss: 0.7268, step time: 0.3758\n",
      "batch: 10/17, train_dl_loss: 0.7375, train_bce_loss: 1.2166, train_bce_dl_loss: 0.7375, step time: 0.4377\n",
      "batch: 11/17, train_dl_loss: 0.6931, train_bce_loss: 1.2124, train_bce_dl_loss: 0.6931, step time: 0.4325\n",
      "batch: 12/17, train_dl_loss: 0.6985, train_bce_loss: 1.2128, train_bce_dl_loss: 0.6985, step time: 0.4345\n",
      "batch: 13/17, train_dl_loss: 0.8137, train_bce_loss: 1.2147, train_bce_dl_loss: 0.8137, step time: 0.3734\n",
      "batch: 14/17, train_dl_loss: 0.7196, train_bce_loss: 1.2278, train_bce_dl_loss: 0.7196, step time: 0.4294\n",
      "batch: 15/17, train_dl_loss: 0.6819, train_bce_loss: 1.2217, train_bce_dl_loss: 0.6819, step time: 0.3682\n",
      "batch: 16/17, train_dl_loss: 0.6827, train_bce_loss: 1.2225, train_bce_dl_loss: 0.6827, step time: 0.4133\n",
      "batch: 17/17, train_dl_loss: 0.6572, train_bce_loss: 1.2319, train_bce_dl_loss: 0.6572, step time: 0.1100\n",
      "LOSS train DiceLoss: 0.7126, LOSS train BCE: 1.2120, LOSS train BCE-DiceLoss: 0.7126, LOSS val DiceLoss: 0.7473, LOSS val BCE: 1.2197, LOSS val BCE-DiceLoss: 0.7473, METRIC val: 0.2258\n",
      "time consuming of epoch 16 is: 457.8595\n",
      "----------\n",
      "EPOCH 17/80\n",
      "batch: 0/17, train_dl_loss: 0.6687, train_bce_loss: 1.2156, train_bce_dl_loss: 0.6687, step time: 0.4315\n",
      "batch: 1/17, train_dl_loss: 0.7072, train_bce_loss: 1.2230, train_bce_dl_loss: 0.7072, step time: 0.3762\n",
      "batch: 2/17, train_dl_loss: 0.7158, train_bce_loss: 1.2250, train_bce_dl_loss: 0.7158, step time: 0.4307\n",
      "batch: 3/17, train_dl_loss: 0.6962, train_bce_loss: 1.2249, train_bce_dl_loss: 0.6962, step time: 0.3719\n",
      "batch: 4/17, train_dl_loss: 0.6993, train_bce_loss: 1.2288, train_bce_dl_loss: 0.6993, step time: 0.4371\n",
      "batch: 5/17, train_dl_loss: 0.6579, train_bce_loss: 1.2195, train_bce_dl_loss: 0.6579, step time: 0.3805\n",
      "batch: 6/17, train_dl_loss: 0.7230, train_bce_loss: 1.2352, train_bce_dl_loss: 0.7230, step time: 0.4241\n",
      "batch: 7/17, train_dl_loss: 0.6992, train_bce_loss: 1.2247, train_bce_dl_loss: 0.6992, step time: 0.3783\n",
      "batch: 8/17, train_dl_loss: 0.7074, train_bce_loss: 1.2193, train_bce_dl_loss: 0.7074, step time: 0.4129\n",
      "batch: 9/17, train_dl_loss: 0.7146, train_bce_loss: 1.2265, train_bce_dl_loss: 0.7146, step time: 0.3717\n",
      "batch: 10/17, train_dl_loss: 0.7041, train_bce_loss: 1.2330, train_bce_dl_loss: 0.7041, step time: 0.4382\n",
      "batch: 11/17, train_dl_loss: 0.6551, train_bce_loss: 1.2187, train_bce_dl_loss: 0.6551, step time: 0.3807\n",
      "batch: 12/17, train_dl_loss: 0.6971, train_bce_loss: 1.2283, train_bce_dl_loss: 0.6971, step time: 0.4234\n",
      "batch: 13/17, train_dl_loss: 0.7904, train_bce_loss: 1.2338, train_bce_dl_loss: 0.7904, step time: 0.3755\n",
      "batch: 14/17, train_dl_loss: 0.7308, train_bce_loss: 1.2474, train_bce_dl_loss: 0.7308, step time: 0.4120\n",
      "batch: 15/17, train_dl_loss: 0.6651, train_bce_loss: 1.2468, train_bce_dl_loss: 0.6651, step time: 0.3727\n",
      "batch: 16/17, train_dl_loss: 0.6929, train_bce_loss: 1.2363, train_bce_dl_loss: 0.6929, step time: 0.4175\n",
      "batch: 17/17, train_dl_loss: 0.6246, train_bce_loss: 1.2555, train_bce_dl_loss: 0.6246, step time: 0.1120\n",
      "LOSS train DiceLoss: 0.6972, LOSS train BCE: 1.2301, LOSS train BCE-DiceLoss: 0.6972, LOSS val DiceLoss: 0.7259, LOSS val BCE: 1.2422, LOSS val BCE-DiceLoss: 0.7259, METRIC val: 0.2673\n",
      "time consuming of epoch 17 is: 451.8716\n",
      "----------\n",
      "EPOCH 18/80\n",
      "batch: 0/17, train_dl_loss: 0.6561, train_bce_loss: 1.2356, train_bce_dl_loss: 0.6561, step time: 0.4367\n",
      "batch: 1/17, train_dl_loss: 0.6877, train_bce_loss: 1.2601, train_bce_dl_loss: 0.6877, step time: 0.3789\n",
      "batch: 2/17, train_dl_loss: 0.7415, train_bce_loss: 1.2450, train_bce_dl_loss: 0.7415, step time: 0.4158\n",
      "batch: 3/17, train_dl_loss: 0.7520, train_bce_loss: 1.2474, train_bce_dl_loss: 0.7520, step time: 0.3749\n",
      "batch: 4/17, train_dl_loss: 0.6682, train_bce_loss: 1.2562, train_bce_dl_loss: 0.6682, step time: 0.4263\n",
      "batch: 5/17, train_dl_loss: 0.7062, train_bce_loss: 1.2340, train_bce_dl_loss: 0.7062, step time: 0.3814\n",
      "batch: 6/17, train_dl_loss: 0.6966, train_bce_loss: 1.2533, train_bce_dl_loss: 0.6966, step time: 0.4340\n",
      "batch: 7/17, train_dl_loss: 0.6372, train_bce_loss: 1.2448, train_bce_dl_loss: 0.6372, step time: 0.3824\n",
      "batch: 8/17, train_dl_loss: 0.7151, train_bce_loss: 1.2432, train_bce_dl_loss: 0.7151, step time: 0.4150\n",
      "batch: 9/17, train_dl_loss: 0.6752, train_bce_loss: 1.2595, train_bce_dl_loss: 0.6752, step time: 0.4181\n",
      "batch: 10/17, train_dl_loss: 0.7020, train_bce_loss: 1.2515, train_bce_dl_loss: 0.7020, step time: 0.4301\n",
      "batch: 11/17, train_dl_loss: 0.6954, train_bce_loss: 1.2456, train_bce_dl_loss: 0.6954, step time: 0.4341\n",
      "batch: 12/17, train_dl_loss: 0.6599, train_bce_loss: 1.2460, train_bce_dl_loss: 0.6599, step time: 0.4265\n",
      "batch: 13/17, train_dl_loss: 0.7890, train_bce_loss: 1.2549, train_bce_dl_loss: 0.7890, step time: 0.4346\n",
      "batch: 14/17, train_dl_loss: 0.7210, train_bce_loss: 1.2624, train_bce_dl_loss: 0.7210, step time: 0.4213\n",
      "batch: 15/17, train_dl_loss: 0.7053, train_bce_loss: 1.2544, train_bce_dl_loss: 0.7053, step time: 0.3755\n",
      "batch: 16/17, train_dl_loss: 0.6468, train_bce_loss: 1.2566, train_bce_dl_loss: 0.6468, step time: 0.4294\n",
      "batch: 17/17, train_dl_loss: 0.6578, train_bce_loss: 1.2544, train_bce_dl_loss: 0.6578, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.6952, LOSS train BCE: 1.2503, LOSS train BCE-DiceLoss: 0.6952, LOSS val DiceLoss: 0.7162, LOSS val BCE: 1.2576, LOSS val BCE-DiceLoss: 0.7162, METRIC val: 0.2852\n",
      "time consuming of epoch 18 is: 481.2101\n",
      "----------\n",
      "EPOCH 19/80\n",
      "batch: 0/17, train_dl_loss: 0.6806, train_bce_loss: 1.2709, train_bce_dl_loss: 0.6806, step time: 0.4270\n",
      "batch: 1/17, train_dl_loss: 0.6704, train_bce_loss: 1.2764, train_bce_dl_loss: 0.6704, step time: 0.3797\n",
      "batch: 2/17, train_dl_loss: 0.7545, train_bce_loss: 1.2599, train_bce_dl_loss: 0.7545, step time: 0.4188\n",
      "batch: 3/17, train_dl_loss: 0.7218, train_bce_loss: 1.2534, train_bce_dl_loss: 0.7218, step time: 0.3685\n",
      "batch: 4/17, train_dl_loss: 0.6850, train_bce_loss: 1.2692, train_bce_dl_loss: 0.6850, step time: 0.4298\n",
      "batch: 5/17, train_dl_loss: 0.6844, train_bce_loss: 1.2616, train_bce_dl_loss: 0.6844, step time: 0.4107\n",
      "batch: 6/17, train_dl_loss: 0.7285, train_bce_loss: 1.2698, train_bce_dl_loss: 0.7285, step time: 0.4336\n",
      "batch: 7/17, train_dl_loss: 0.6492, train_bce_loss: 1.2582, train_bce_dl_loss: 0.6492, step time: 0.3868\n",
      "batch: 8/17, train_dl_loss: 0.6874, train_bce_loss: 1.2516, train_bce_dl_loss: 0.6874, step time: 0.4389\n",
      "batch: 9/17, train_dl_loss: 0.6497, train_bce_loss: 1.2605, train_bce_dl_loss: 0.6497, step time: 0.4309\n",
      "batch: 10/17, train_dl_loss: 0.6853, train_bce_loss: 1.2660, train_bce_dl_loss: 0.6853, step time: 0.4197\n",
      "batch: 11/17, train_dl_loss: 0.6212, train_bce_loss: 1.2538, train_bce_dl_loss: 0.6212, step time: 0.4266\n",
      "batch: 12/17, train_dl_loss: 0.7076, train_bce_loss: 1.2627, train_bce_dl_loss: 0.7076, step time: 0.4221\n",
      "batch: 13/17, train_dl_loss: 0.7663, train_bce_loss: 1.2759, train_bce_dl_loss: 0.7663, step time: 0.3838\n",
      "batch: 14/17, train_dl_loss: 0.7094, train_bce_loss: 1.2790, train_bce_dl_loss: 0.7094, step time: 0.4213\n",
      "batch: 15/17, train_dl_loss: 0.6644, train_bce_loss: 1.2802, train_bce_dl_loss: 0.6644, step time: 0.3809\n",
      "batch: 16/17, train_dl_loss: 0.6562, train_bce_loss: 1.2721, train_bce_dl_loss: 0.6562, step time: 0.4223\n",
      "batch: 17/17, train_dl_loss: 0.6117, train_bce_loss: 1.2648, train_bce_dl_loss: 0.6117, step time: 0.1114\n",
      "LOSS train DiceLoss: 0.6852, LOSS train BCE: 1.2659, LOSS train BCE-DiceLoss: 0.6852, LOSS val DiceLoss: 0.7133, LOSS val BCE: 1.2682, LOSS val BCE-DiceLoss: 0.7133, METRIC val: 0.2904\n",
      "time consuming of epoch 19 is: 419.9428\n",
      "----------\n",
      "EPOCH 20/80\n",
      "batch: 0/17, train_dl_loss: 0.7241, train_bce_loss: 1.2756, train_bce_dl_loss: 0.7241, step time: 0.4376\n",
      "batch: 1/17, train_dl_loss: 0.6429, train_bce_loss: 1.2752, train_bce_dl_loss: 0.6429, step time: 0.3839\n",
      "batch: 2/17, train_dl_loss: 0.7086, train_bce_loss: 1.2770, train_bce_dl_loss: 0.7086, step time: 0.4370\n",
      "batch: 3/17, train_dl_loss: 0.7288, train_bce_loss: 1.2858, train_bce_dl_loss: 0.7288, step time: 0.3694\n",
      "batch: 4/17, train_dl_loss: 0.6590, train_bce_loss: 1.2784, train_bce_dl_loss: 0.6590, step time: 0.4335\n",
      "batch: 5/17, train_dl_loss: 0.6493, train_bce_loss: 1.2706, train_bce_dl_loss: 0.6493, step time: 0.3783\n",
      "batch: 6/17, train_dl_loss: 0.6936, train_bce_loss: 1.2847, train_bce_dl_loss: 0.6936, step time: 0.4175\n",
      "batch: 7/17, train_dl_loss: 0.6318, train_bce_loss: 1.2620, train_bce_dl_loss: 0.6318, step time: 0.3708\n",
      "batch: 8/17, train_dl_loss: 0.6569, train_bce_loss: 1.2784, train_bce_dl_loss: 0.6569, step time: 0.4190\n",
      "batch: 9/17, train_dl_loss: 0.7288, train_bce_loss: 1.2849, train_bce_dl_loss: 0.7288, step time: 0.3736\n",
      "batch: 10/17, train_dl_loss: 0.7350, train_bce_loss: 1.2770, train_bce_dl_loss: 0.7350, step time: 0.4847\n",
      "batch: 11/17, train_dl_loss: 0.6286, train_bce_loss: 1.2653, train_bce_dl_loss: 0.6286, step time: 0.3720\n",
      "batch: 12/17, train_dl_loss: 0.6670, train_bce_loss: 1.2736, train_bce_dl_loss: 0.6670, step time: 0.4383\n",
      "batch: 13/17, train_dl_loss: 0.7998, train_bce_loss: 1.2867, train_bce_dl_loss: 0.7998, step time: 0.3690\n",
      "batch: 14/17, train_dl_loss: 0.6889, train_bce_loss: 1.2872, train_bce_dl_loss: 0.6889, step time: 0.4314\n",
      "batch: 15/17, train_dl_loss: 0.6371, train_bce_loss: 1.2887, train_bce_dl_loss: 0.6371, step time: 0.3849\n",
      "batch: 16/17, train_dl_loss: 0.6391, train_bce_loss: 1.2924, train_bce_dl_loss: 0.6391, step time: 0.4225\n",
      "batch: 17/17, train_dl_loss: 0.6130, train_bce_loss: 1.2995, train_bce_dl_loss: 0.6130, step time: 0.1114\n",
      "LOSS train DiceLoss: 0.6796, LOSS train BCE: 1.2802, LOSS train BCE-DiceLoss: 0.6796, LOSS val DiceLoss: 0.6933, LOSS val BCE: 1.2861, LOSS val BCE-DiceLoss: 0.6933, METRIC val: 0.3118\n",
      "time consuming of epoch 20 is: 429.7869\n",
      "----------\n",
      "EPOCH 21/80\n",
      "batch: 0/17, train_dl_loss: 0.6409, train_bce_loss: 1.2813, train_bce_dl_loss: 0.6409, step time: 0.4253\n",
      "batch: 1/17, train_dl_loss: 0.6445, train_bce_loss: 1.3062, train_bce_dl_loss: 0.6445, step time: 0.3766\n",
      "batch: 2/17, train_dl_loss: 0.7030, train_bce_loss: 1.2869, train_bce_dl_loss: 0.7030, step time: 0.4247\n",
      "batch: 3/17, train_dl_loss: 0.7256, train_bce_loss: 1.2890, train_bce_dl_loss: 0.7256, step time: 0.3752\n",
      "batch: 4/17, train_dl_loss: 0.6198, train_bce_loss: 1.2800, train_bce_dl_loss: 0.6198, step time: 0.4368\n",
      "batch: 5/17, train_dl_loss: 0.6317, train_bce_loss: 1.2840, train_bce_dl_loss: 0.6317, step time: 0.4313\n",
      "batch: 6/17, train_dl_loss: 0.6752, train_bce_loss: 1.3044, train_bce_dl_loss: 0.6752, step time: 0.4185\n",
      "batch: 7/17, train_dl_loss: 0.6044, train_bce_loss: 1.2872, train_bce_dl_loss: 0.6044, step time: 0.4335\n",
      "batch: 8/17, train_dl_loss: 0.6622, train_bce_loss: 1.2994, train_bce_dl_loss: 0.6622, step time: 0.4249\n",
      "batch: 9/17, train_dl_loss: 0.6293, train_bce_loss: 1.2898, train_bce_dl_loss: 0.6293, step time: 0.4186\n",
      "batch: 10/17, train_dl_loss: 0.6878, train_bce_loss: 1.3038, train_bce_dl_loss: 0.6878, step time: 0.4224\n",
      "batch: 11/17, train_dl_loss: 0.6285, train_bce_loss: 1.2881, train_bce_dl_loss: 0.6285, step time: 0.4251\n",
      "batch: 12/17, train_dl_loss: 0.6422, train_bce_loss: 1.2855, train_bce_dl_loss: 0.6422, step time: 0.4351\n",
      "batch: 13/17, train_dl_loss: 0.7978, train_bce_loss: 1.3040, train_bce_dl_loss: 0.7978, step time: 0.4374\n",
      "batch: 14/17, train_dl_loss: 0.6404, train_bce_loss: 1.3094, train_bce_dl_loss: 0.6404, step time: 0.4364\n",
      "batch: 15/17, train_dl_loss: 0.6776, train_bce_loss: 1.3018, train_bce_dl_loss: 0.6776, step time: 0.3720\n",
      "batch: 16/17, train_dl_loss: 0.6178, train_bce_loss: 1.2946, train_bce_dl_loss: 0.6178, step time: 0.4176\n",
      "batch: 17/17, train_dl_loss: 0.6357, train_bce_loss: 1.2993, train_bce_dl_loss: 0.6357, step time: 0.1104\n",
      "LOSS train DiceLoss: 0.6591, LOSS train BCE: 1.2941, LOSS train BCE-DiceLoss: 0.6591, LOSS val DiceLoss: 0.6897, LOSS val BCE: 1.2980, LOSS val BCE-DiceLoss: 0.6897, METRIC val: 0.3168\n",
      "time consuming of epoch 21 is: 425.9612\n",
      "----------\n",
      "EPOCH 22/80\n",
      "batch: 0/17, train_dl_loss: 0.6021, train_bce_loss: 1.2884, train_bce_dl_loss: 0.6021, step time: 0.4398\n",
      "batch: 1/17, train_dl_loss: 0.6475, train_bce_loss: 1.3060, train_bce_dl_loss: 0.6475, step time: 0.3731\n",
      "batch: 2/17, train_dl_loss: 0.6959, train_bce_loss: 1.3041, train_bce_dl_loss: 0.6959, step time: 0.4822\n",
      "batch: 3/17, train_dl_loss: 0.7235, train_bce_loss: 1.3041, train_bce_dl_loss: 0.7235, step time: 0.3728\n",
      "batch: 4/17, train_dl_loss: 0.6316, train_bce_loss: 1.2965, train_bce_dl_loss: 0.6316, step time: 0.4287\n",
      "batch: 5/17, train_dl_loss: 0.6212, train_bce_loss: 1.3008, train_bce_dl_loss: 0.6212, step time: 0.4316\n",
      "batch: 6/17, train_dl_loss: 0.6595, train_bce_loss: 1.3088, train_bce_dl_loss: 0.6595, step time: 0.4280\n",
      "batch: 7/17, train_dl_loss: 0.5895, train_bce_loss: 1.2862, train_bce_dl_loss: 0.5895, step time: 0.4349\n",
      "batch: 8/17, train_dl_loss: 0.6500, train_bce_loss: 1.2881, train_bce_dl_loss: 0.6500, step time: 0.4100\n",
      "batch: 9/17, train_dl_loss: 0.6164, train_bce_loss: 1.3046, train_bce_dl_loss: 0.6164, step time: 0.4300\n",
      "batch: 10/17, train_dl_loss: 0.7114, train_bce_loss: 1.3167, train_bce_dl_loss: 0.7114, step time: 0.4138\n",
      "batch: 11/17, train_dl_loss: 0.6502, train_bce_loss: 1.2932, train_bce_dl_loss: 0.6502, step time: 0.4334\n",
      "batch: 12/17, train_dl_loss: 0.6620, train_bce_loss: 1.3224, train_bce_dl_loss: 0.6620, step time: 0.4228\n",
      "batch: 13/17, train_dl_loss: 0.7747, train_bce_loss: 1.3159, train_bce_dl_loss: 0.7747, step time: 0.3730\n",
      "batch: 14/17, train_dl_loss: 0.6768, train_bce_loss: 1.3255, train_bce_dl_loss: 0.6768, step time: 0.4367\n",
      "batch: 15/17, train_dl_loss: 0.6149, train_bce_loss: 1.3038, train_bce_dl_loss: 0.6149, step time: 0.3763\n",
      "batch: 16/17, train_dl_loss: 0.6339, train_bce_loss: 1.3254, train_bce_dl_loss: 0.6339, step time: 0.4097\n",
      "batch: 17/17, train_dl_loss: 0.5625, train_bce_loss: 1.3233, train_bce_dl_loss: 0.5625, step time: 0.1105\n",
      "LOSS train DiceLoss: 0.6513, LOSS train BCE: 1.3063, LOSS train BCE-DiceLoss: 0.6513, LOSS val DiceLoss: 0.6933, LOSS val BCE: 1.3115, LOSS val BCE-DiceLoss: 0.6933, METRIC val: 0.3118\n",
      "time consuming of epoch 22 is: 417.8080\n",
      "----------\n",
      "EPOCH 23/80\n",
      "batch: 0/17, train_dl_loss: 0.7081, train_bce_loss: 1.3219, train_bce_dl_loss: 0.7081, step time: 0.4286\n",
      "batch: 1/17, train_dl_loss: 0.6340, train_bce_loss: 1.3158, train_bce_dl_loss: 0.6340, step time: 0.3793\n",
      "batch: 2/17, train_dl_loss: 0.7257, train_bce_loss: 1.3164, train_bce_dl_loss: 0.7257, step time: 0.4201\n",
      "batch: 3/17, train_dl_loss: 0.7101, train_bce_loss: 1.3237, train_bce_dl_loss: 0.7101, step time: 0.3749\n",
      "batch: 4/17, train_dl_loss: 0.5902, train_bce_loss: 1.3202, train_bce_dl_loss: 0.5902, step time: 0.4137\n",
      "batch: 5/17, train_dl_loss: 0.6009, train_bce_loss: 1.3162, train_bce_dl_loss: 0.6009, step time: 0.3717\n",
      "batch: 6/17, train_dl_loss: 0.6846, train_bce_loss: 1.3182, train_bce_dl_loss: 0.6846, step time: 0.4252\n",
      "batch: 7/17, train_dl_loss: 0.6169, train_bce_loss: 1.3003, train_bce_dl_loss: 0.6169, step time: 0.3696\n",
      "batch: 8/17, train_dl_loss: 0.6411, train_bce_loss: 1.3011, train_bce_dl_loss: 0.6411, step time: 0.4357\n",
      "batch: 9/17, train_dl_loss: 0.6784, train_bce_loss: 1.3325, train_bce_dl_loss: 0.6784, step time: 0.3755\n",
      "batch: 10/17, train_dl_loss: 0.6860, train_bce_loss: 1.3134, train_bce_dl_loss: 0.6860, step time: 0.4437\n",
      "batch: 11/17, train_dl_loss: 0.5996, train_bce_loss: 1.3030, train_bce_dl_loss: 0.5996, step time: 0.3798\n",
      "batch: 12/17, train_dl_loss: 0.6002, train_bce_loss: 1.3073, train_bce_dl_loss: 0.6002, step time: 0.4412\n",
      "batch: 13/17, train_dl_loss: 0.7662, train_bce_loss: 1.3234, train_bce_dl_loss: 0.7662, step time: 0.3783\n",
      "batch: 14/17, train_dl_loss: 0.6978, train_bce_loss: 1.3302, train_bce_dl_loss: 0.6978, step time: 0.4441\n",
      "batch: 15/17, train_dl_loss: 0.6349, train_bce_loss: 1.3165, train_bce_dl_loss: 0.6349, step time: 0.3821\n",
      "batch: 16/17, train_dl_loss: 0.6415, train_bce_loss: 1.3250, train_bce_dl_loss: 0.6415, step time: 0.4200\n",
      "batch: 17/17, train_dl_loss: 0.5353, train_bce_loss: 1.3235, train_bce_dl_loss: 0.5353, step time: 0.1091\n",
      "LOSS train DiceLoss: 0.6529, LOSS train BCE: 1.3171, LOSS train BCE-DiceLoss: 0.6529, LOSS val DiceLoss: 0.6838, LOSS val BCE: 1.3223, LOSS val BCE-DiceLoss: 0.6838, METRIC val: 0.3226\n",
      "time consuming of epoch 23 is: 415.0908\n",
      "----------\n",
      "EPOCH 24/80\n",
      "batch: 0/17, train_dl_loss: 0.6053, train_bce_loss: 1.3161, train_bce_dl_loss: 0.6053, step time: 0.4199\n",
      "batch: 1/17, train_dl_loss: 0.6244, train_bce_loss: 1.3247, train_bce_dl_loss: 0.6244, step time: 0.3756\n",
      "batch: 2/17, train_dl_loss: 0.7013, train_bce_loss: 1.3282, train_bce_dl_loss: 0.7013, step time: 0.4152\n",
      "batch: 3/17, train_dl_loss: 0.6933, train_bce_loss: 1.3298, train_bce_dl_loss: 0.6933, step time: 0.3742\n",
      "batch: 4/17, train_dl_loss: 0.5660, train_bce_loss: 1.3292, train_bce_dl_loss: 0.5660, step time: 0.4290\n",
      "batch: 5/17, train_dl_loss: 0.5852, train_bce_loss: 1.3146, train_bce_dl_loss: 0.5852, step time: 0.3768\n",
      "batch: 6/17, train_dl_loss: 0.7162, train_bce_loss: 1.3474, train_bce_dl_loss: 0.7162, step time: 0.4398\n",
      "batch: 7/17, train_dl_loss: 0.6225, train_bce_loss: 1.3388, train_bce_dl_loss: 0.6225, step time: 0.3750\n",
      "batch: 8/17, train_dl_loss: 0.6495, train_bce_loss: 1.3223, train_bce_dl_loss: 0.6495, step time: 0.4270\n",
      "batch: 9/17, train_dl_loss: 0.6397, train_bce_loss: 1.3372, train_bce_dl_loss: 0.6397, step time: 0.3791\n",
      "batch: 10/17, train_dl_loss: 0.6587, train_bce_loss: 1.3233, train_bce_dl_loss: 0.6587, step time: 0.4404\n",
      "batch: 11/17, train_dl_loss: 0.5782, train_bce_loss: 1.3275, train_bce_dl_loss: 0.5782, step time: 0.4208\n",
      "batch: 12/17, train_dl_loss: 0.6704, train_bce_loss: 1.3339, train_bce_dl_loss: 0.6704, step time: 0.4212\n",
      "batch: 13/17, train_dl_loss: 0.7445, train_bce_loss: 1.3348, train_bce_dl_loss: 0.7445, step time: 0.4409\n",
      "batch: 14/17, train_dl_loss: 0.6450, train_bce_loss: 1.3395, train_bce_dl_loss: 0.6450, step time: 0.4341\n",
      "batch: 15/17, train_dl_loss: 0.6417, train_bce_loss: 1.3356, train_bce_dl_loss: 0.6417, step time: 0.4400\n",
      "batch: 16/17, train_dl_loss: 0.6174, train_bce_loss: 1.3356, train_bce_dl_loss: 0.6174, step time: 0.4125\n",
      "batch: 17/17, train_dl_loss: 0.5953, train_bce_loss: 1.3337, train_bce_dl_loss: 0.5953, step time: 0.1104\n",
      "LOSS train DiceLoss: 0.6419, LOSS train BCE: 1.3307, LOSS train BCE-DiceLoss: 0.6419, LOSS val DiceLoss: 0.6888, LOSS val BCE: 1.3342, LOSS val BCE-DiceLoss: 0.6888, METRIC val: 0.3127\n",
      "time consuming of epoch 24 is: 437.0771\n",
      "----------\n",
      "EPOCH 25/80\n",
      "batch: 0/17, train_dl_loss: 0.6607, train_bce_loss: 1.3373, train_bce_dl_loss: 0.6607, step time: 0.4304\n",
      "batch: 1/17, train_dl_loss: 0.6718, train_bce_loss: 1.3492, train_bce_dl_loss: 0.6718, step time: 0.3868\n",
      "batch: 2/17, train_dl_loss: 0.6405, train_bce_loss: 1.3319, train_bce_dl_loss: 0.6405, step time: 0.4341\n",
      "batch: 3/17, train_dl_loss: 0.7022, train_bce_loss: 1.3516, train_bce_dl_loss: 0.7022, step time: 0.3709\n",
      "batch: 4/17, train_dl_loss: 0.6022, train_bce_loss: 1.3391, train_bce_dl_loss: 0.6022, step time: 0.4199\n",
      "batch: 5/17, train_dl_loss: 0.5900, train_bce_loss: 1.3283, train_bce_dl_loss: 0.5900, step time: 0.3742\n",
      "batch: 6/17, train_dl_loss: 0.6609, train_bce_loss: 1.3408, train_bce_dl_loss: 0.6609, step time: 0.4501\n",
      "batch: 7/17, train_dl_loss: 0.5814, train_bce_loss: 1.3197, train_bce_dl_loss: 0.5814, step time: 0.3832\n",
      "batch: 8/17, train_dl_loss: 0.6265, train_bce_loss: 1.3226, train_bce_dl_loss: 0.6265, step time: 0.4296\n",
      "batch: 9/17, train_dl_loss: 0.6181, train_bce_loss: 1.3449, train_bce_dl_loss: 0.6181, step time: 0.3774\n",
      "batch: 10/17, train_dl_loss: 0.6679, train_bce_loss: 1.3367, train_bce_dl_loss: 0.6679, step time: 0.4290\n",
      "batch: 11/17, train_dl_loss: 0.6095, train_bce_loss: 1.3289, train_bce_dl_loss: 0.6095, step time: 0.4434\n",
      "batch: 12/17, train_dl_loss: 0.6093, train_bce_loss: 1.3304, train_bce_dl_loss: 0.6093, step time: 0.4378\n",
      "batch: 13/17, train_dl_loss: 0.7680, train_bce_loss: 1.3533, train_bce_dl_loss: 0.7680, step time: 0.3764\n",
      "batch: 14/17, train_dl_loss: 0.7041, train_bce_loss: 1.3561, train_bce_dl_loss: 0.7041, step time: 0.4384\n",
      "batch: 15/17, train_dl_loss: 0.6097, train_bce_loss: 1.3341, train_bce_dl_loss: 0.6097, step time: 0.3784\n",
      "batch: 16/17, train_dl_loss: 0.6106, train_bce_loss: 1.3441, train_bce_dl_loss: 0.6106, step time: 0.4077\n",
      "batch: 17/17, train_dl_loss: 0.5774, train_bce_loss: 1.3356, train_bce_dl_loss: 0.5774, step time: 0.1105\n",
      "LOSS train DiceLoss: 0.6395, LOSS train BCE: 1.3380, LOSS train BCE-DiceLoss: 0.6395, LOSS val DiceLoss: 0.6791, LOSS val BCE: 1.3428, LOSS val BCE-DiceLoss: 0.6791, METRIC val: 0.3244\n",
      "time consuming of epoch 25 is: 429.0409\n",
      "----------\n",
      "EPOCH 26/80\n",
      "batch: 0/17, train_dl_loss: 0.5984, train_bce_loss: 1.3358, train_bce_dl_loss: 0.5984, step time: 0.4269\n",
      "batch: 1/17, train_dl_loss: 0.6429, train_bce_loss: 1.3560, train_bce_dl_loss: 0.6429, step time: 0.3714\n",
      "batch: 2/17, train_dl_loss: 0.6964, train_bce_loss: 1.3524, train_bce_dl_loss: 0.6964, step time: 0.4169\n",
      "batch: 3/17, train_dl_loss: 0.6406, train_bce_loss: 1.3455, train_bce_dl_loss: 0.6406, step time: 0.3739\n",
      "batch: 4/17, train_dl_loss: 0.5854, train_bce_loss: 1.3385, train_bce_dl_loss: 0.5854, step time: 0.4242\n",
      "batch: 5/17, train_dl_loss: 0.5839, train_bce_loss: 1.3521, train_bce_dl_loss: 0.5839, step time: 0.4230\n",
      "batch: 6/17, train_dl_loss: 0.6392, train_bce_loss: 1.3546, train_bce_dl_loss: 0.6392, step time: 0.4278\n",
      "batch: 7/17, train_dl_loss: 0.5783, train_bce_loss: 1.3222, train_bce_dl_loss: 0.5783, step time: 0.3820\n",
      "batch: 8/17, train_dl_loss: 0.5850, train_bce_loss: 1.3364, train_bce_dl_loss: 0.5850, step time: 0.4161\n",
      "batch: 9/17, train_dl_loss: 0.6299, train_bce_loss: 1.3488, train_bce_dl_loss: 0.6299, step time: 0.3765\n",
      "batch: 10/17, train_dl_loss: 0.7047, train_bce_loss: 1.3422, train_bce_dl_loss: 0.7047, step time: 0.4286\n",
      "batch: 11/17, train_dl_loss: 0.5832, train_bce_loss: 1.3491, train_bce_dl_loss: 0.5832, step time: 0.4286\n",
      "batch: 12/17, train_dl_loss: 0.6833, train_bce_loss: 1.3715, train_bce_dl_loss: 0.6833, step time: 0.4229\n",
      "batch: 13/17, train_dl_loss: 0.7465, train_bce_loss: 1.3526, train_bce_dl_loss: 0.7465, step time: 0.3746\n",
      "batch: 14/17, train_dl_loss: 0.6064, train_bce_loss: 1.3606, train_bce_dl_loss: 0.6064, step time: 0.4163\n",
      "batch: 15/17, train_dl_loss: 0.5802, train_bce_loss: 1.3586, train_bce_dl_loss: 0.5802, step time: 0.3698\n",
      "batch: 16/17, train_dl_loss: 0.5926, train_bce_loss: 1.3548, train_bce_dl_loss: 0.5926, step time: 0.4289\n",
      "batch: 17/17, train_dl_loss: 0.5303, train_bce_loss: 1.3465, train_bce_dl_loss: 0.5303, step time: 0.1107\n",
      "LOSS train DiceLoss: 0.6226, LOSS train BCE: 1.3488, LOSS train BCE-DiceLoss: 0.6226, LOSS val DiceLoss: 0.6604, LOSS val BCE: 1.3480, LOSS val BCE-DiceLoss: 0.6604, METRIC val: 0.3523\n",
      "time consuming of epoch 26 is: 455.9603\n",
      "----------\n",
      "EPOCH 27/80\n",
      "batch: 0/17, train_dl_loss: 0.5995, train_bce_loss: 1.3478, train_bce_dl_loss: 0.5995, step time: 0.4264\n",
      "batch: 1/17, train_dl_loss: 0.6077, train_bce_loss: 1.3575, train_bce_dl_loss: 0.6077, step time: 0.3736\n",
      "batch: 2/17, train_dl_loss: 0.6238, train_bce_loss: 1.3540, train_bce_dl_loss: 0.6238, step time: 0.4382\n",
      "batch: 3/17, train_dl_loss: 0.6736, train_bce_loss: 1.3586, train_bce_dl_loss: 0.6736, step time: 0.3769\n",
      "batch: 4/17, train_dl_loss: 0.5725, train_bce_loss: 1.3527, train_bce_dl_loss: 0.5725, step time: 0.4328\n",
      "batch: 5/17, train_dl_loss: 0.5786, train_bce_loss: 1.3463, train_bce_dl_loss: 0.5786, step time: 0.3777\n",
      "batch: 6/17, train_dl_loss: 0.6543, train_bce_loss: 1.3498, train_bce_dl_loss: 0.6543, step time: 0.4200\n",
      "batch: 7/17, train_dl_loss: 0.5794, train_bce_loss: 1.3547, train_bce_dl_loss: 0.5794, step time: 0.3743\n",
      "batch: 8/17, train_dl_loss: 0.6323, train_bce_loss: 1.3440, train_bce_dl_loss: 0.6323, step time: 0.4193\n",
      "batch: 9/17, train_dl_loss: 0.6246, train_bce_loss: 1.3543, train_bce_dl_loss: 0.6246, step time: 0.3834\n",
      "batch: 10/17, train_dl_loss: 0.6653, train_bce_loss: 1.3575, train_bce_dl_loss: 0.6653, step time: 0.4268\n",
      "batch: 11/17, train_dl_loss: 0.5867, train_bce_loss: 1.3516, train_bce_dl_loss: 0.5867, step time: 0.4199\n",
      "batch: 12/17, train_dl_loss: 0.5917, train_bce_loss: 1.3565, train_bce_dl_loss: 0.5917, step time: 0.4399\n",
      "batch: 13/17, train_dl_loss: 0.7412, train_bce_loss: 1.3690, train_bce_dl_loss: 0.7412, step time: 0.3790\n",
      "batch: 14/17, train_dl_loss: 0.6726, train_bce_loss: 1.3685, train_bce_dl_loss: 0.6726, step time: 0.4268\n",
      "batch: 15/17, train_dl_loss: 0.5917, train_bce_loss: 1.3696, train_bce_dl_loss: 0.5917, step time: 0.3703\n",
      "batch: 16/17, train_dl_loss: 0.5748, train_bce_loss: 1.3610, train_bce_dl_loss: 0.5748, step time: 0.4369\n",
      "batch: 17/17, train_dl_loss: 0.5982, train_bce_loss: 1.3563, train_bce_dl_loss: 0.5982, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.6205, LOSS train BCE: 1.3561, LOSS train BCE-DiceLoss: 0.6205, LOSS val DiceLoss: 0.6568, LOSS val BCE: 1.3556, LOSS val BCE-DiceLoss: 0.6568, METRIC val: 0.3625\n",
      "time consuming of epoch 27 is: 478.2408\n",
      "----------\n",
      "EPOCH 28/80\n",
      "batch: 0/17, train_dl_loss: 0.6509, train_bce_loss: 1.3611, train_bce_dl_loss: 0.6509, step time: 0.4374\n",
      "batch: 1/17, train_dl_loss: 0.5711, train_bce_loss: 1.3666, train_bce_dl_loss: 0.5711, step time: 0.3791\n",
      "batch: 2/17, train_dl_loss: 0.6337, train_bce_loss: 1.3547, train_bce_dl_loss: 0.6337, step time: 0.4442\n",
      "batch: 3/17, train_dl_loss: 0.6715, train_bce_loss: 1.3672, train_bce_dl_loss: 0.6715, step time: 0.3753\n",
      "batch: 4/17, train_dl_loss: 0.5826, train_bce_loss: 1.3520, train_bce_dl_loss: 0.5826, step time: 0.4356\n",
      "batch: 5/17, train_dl_loss: 0.5804, train_bce_loss: 1.3616, train_bce_dl_loss: 0.5804, step time: 0.3819\n",
      "batch: 6/17, train_dl_loss: 0.6295, train_bce_loss: 1.3666, train_bce_dl_loss: 0.6295, step time: 0.4463\n",
      "batch: 7/17, train_dl_loss: 0.6185, train_bce_loss: 1.3678, train_bce_dl_loss: 0.6185, step time: 0.3730\n",
      "batch: 8/17, train_dl_loss: 0.5675, train_bce_loss: 1.3528, train_bce_dl_loss: 0.5675, step time: 0.4652\n",
      "batch: 9/17, train_dl_loss: 0.5818, train_bce_loss: 1.3523, train_bce_dl_loss: 0.5818, step time: 0.3751\n",
      "batch: 10/17, train_dl_loss: 0.6798, train_bce_loss: 1.3680, train_bce_dl_loss: 0.6798, step time: 0.4353\n",
      "batch: 11/17, train_dl_loss: 0.5845, train_bce_loss: 1.3318, train_bce_dl_loss: 0.5845, step time: 0.3817\n",
      "batch: 12/17, train_dl_loss: 0.6166, train_bce_loss: 1.3505, train_bce_dl_loss: 0.6166, step time: 0.4229\n",
      "batch: 13/17, train_dl_loss: 0.7486, train_bce_loss: 1.3683, train_bce_dl_loss: 0.7486, step time: 0.3748\n",
      "batch: 14/17, train_dl_loss: 0.6345, train_bce_loss: 1.3765, train_bce_dl_loss: 0.6345, step time: 0.4292\n",
      "batch: 15/17, train_dl_loss: 0.5927, train_bce_loss: 1.3659, train_bce_dl_loss: 0.5927, step time: 0.3778\n",
      "batch: 16/17, train_dl_loss: 0.5612, train_bce_loss: 1.3730, train_bce_dl_loss: 0.5612, step time: 0.4111\n",
      "batch: 17/17, train_dl_loss: 0.5476, train_bce_loss: 1.3816, train_bce_dl_loss: 0.5476, step time: 0.1106\n",
      "LOSS train DiceLoss: 0.6141, LOSS train BCE: 1.3621, LOSS train BCE-DiceLoss: 0.6141, LOSS val DiceLoss: 0.6782, LOSS val BCE: 1.3703, LOSS val BCE-DiceLoss: 0.6782, METRIC val: 0.3200\n",
      "time consuming of epoch 28 is: 448.2364\n",
      "----------\n",
      "EPOCH 29/80\n",
      "batch: 0/17, train_dl_loss: 0.6149, train_bce_loss: 1.3691, train_bce_dl_loss: 0.6149, step time: 0.4395\n",
      "batch: 1/17, train_dl_loss: 0.5874, train_bce_loss: 1.3678, train_bce_dl_loss: 0.5874, step time: 0.3754\n",
      "batch: 2/17, train_dl_loss: 0.6027, train_bce_loss: 1.3712, train_bce_dl_loss: 0.6027, step time: 0.4362\n",
      "batch: 3/17, train_dl_loss: 0.6766, train_bce_loss: 1.3869, train_bce_dl_loss: 0.6766, step time: 0.3780\n",
      "batch: 4/17, train_dl_loss: 0.5716, train_bce_loss: 1.3698, train_bce_dl_loss: 0.5716, step time: 0.4435\n",
      "batch: 5/17, train_dl_loss: 0.5756, train_bce_loss: 1.3627, train_bce_dl_loss: 0.5756, step time: 0.3814\n",
      "batch: 6/17, train_dl_loss: 0.6421, train_bce_loss: 1.3663, train_bce_dl_loss: 0.6421, step time: 0.4211\n",
      "batch: 7/17, train_dl_loss: 0.5701, train_bce_loss: 1.3538, train_bce_dl_loss: 0.5701, step time: 0.3768\n",
      "batch: 8/17, train_dl_loss: 0.6015, train_bce_loss: 1.3459, train_bce_dl_loss: 0.6015, step time: 0.4398\n",
      "batch: 9/17, train_dl_loss: 0.5761, train_bce_loss: 1.3616, train_bce_dl_loss: 0.5761, step time: 0.4216\n",
      "batch: 10/17, train_dl_loss: 0.6317, train_bce_loss: 1.3618, train_bce_dl_loss: 0.6317, step time: 0.4399\n",
      "batch: 11/17, train_dl_loss: 0.5860, train_bce_loss: 1.3680, train_bce_dl_loss: 0.5860, step time: 0.4284\n",
      "batch: 12/17, train_dl_loss: 0.5869, train_bce_loss: 1.3648, train_bce_dl_loss: 0.5869, step time: 0.4302\n",
      "batch: 13/17, train_dl_loss: 0.7423, train_bce_loss: 1.3759, train_bce_dl_loss: 0.7423, step time: 0.4269\n",
      "batch: 14/17, train_dl_loss: 0.6032, train_bce_loss: 1.3781, train_bce_dl_loss: 0.6032, step time: 0.4351\n",
      "batch: 15/17, train_dl_loss: 0.5593, train_bce_loss: 1.3705, train_bce_dl_loss: 0.5593, step time: 0.3781\n",
      "batch: 16/17, train_dl_loss: 0.5645, train_bce_loss: 1.3821, train_bce_dl_loss: 0.5645, step time: 0.4087\n",
      "batch: 17/17, train_dl_loss: 0.5013, train_bce_loss: 1.3778, train_bce_dl_loss: 0.5013, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5997, LOSS train BCE: 1.3686, LOSS train BCE-DiceLoss: 0.5997, LOSS val DiceLoss: 0.6550, LOSS val BCE: 1.3711, LOSS val BCE-DiceLoss: 0.6550, METRIC val: 0.3584\n",
      "time consuming of epoch 29 is: 446.7808\n",
      "----------\n",
      "EPOCH 30/80\n",
      "batch: 0/17, train_dl_loss: 0.5869, train_bce_loss: 1.3666, train_bce_dl_loss: 0.5869, step time: 0.4257\n",
      "batch: 1/17, train_dl_loss: 0.5796, train_bce_loss: 1.3687, train_bce_dl_loss: 0.5796, step time: 0.3727\n",
      "batch: 2/17, train_dl_loss: 0.6609, train_bce_loss: 1.3770, train_bce_dl_loss: 0.6609, step time: 0.4255\n",
      "batch: 3/17, train_dl_loss: 0.6524, train_bce_loss: 1.3633, train_bce_dl_loss: 0.6524, step time: 0.3757\n",
      "batch: 4/17, train_dl_loss: 0.5569, train_bce_loss: 1.3639, train_bce_dl_loss: 0.5569, step time: 0.4227\n",
      "batch: 5/17, train_dl_loss: 0.5966, train_bce_loss: 1.3875, train_bce_dl_loss: 0.5966, step time: 0.4225\n",
      "batch: 6/17, train_dl_loss: 0.6309, train_bce_loss: 1.3827, train_bce_dl_loss: 0.6309, step time: 0.4202\n",
      "batch: 7/17, train_dl_loss: 0.5848, train_bce_loss: 1.3699, train_bce_dl_loss: 0.5848, step time: 0.4455\n",
      "batch: 8/17, train_dl_loss: 0.6667, train_bce_loss: 1.3729, train_bce_dl_loss: 0.6667, step time: 0.4382\n",
      "batch: 9/17, train_dl_loss: 0.5819, train_bce_loss: 1.3858, train_bce_dl_loss: 0.5819, step time: 0.4283\n",
      "batch: 10/17, train_dl_loss: 0.6396, train_bce_loss: 1.3728, train_bce_dl_loss: 0.6396, step time: 0.4278\n",
      "batch: 11/17, train_dl_loss: 0.5774, train_bce_loss: 1.3780, train_bce_dl_loss: 0.5774, step time: 0.4362\n",
      "batch: 12/17, train_dl_loss: 0.5681, train_bce_loss: 1.3786, train_bce_dl_loss: 0.5681, step time: 0.4160\n",
      "batch: 13/17, train_dl_loss: 0.7376, train_bce_loss: 1.3916, train_bce_dl_loss: 0.7376, step time: 0.4383\n",
      "batch: 14/17, train_dl_loss: 0.6603, train_bce_loss: 1.3935, train_bce_dl_loss: 0.6603, step time: 0.4458\n",
      "batch: 15/17, train_dl_loss: 0.5569, train_bce_loss: 1.3879, train_bce_dl_loss: 0.5569, step time: 0.4210\n",
      "batch: 16/17, train_dl_loss: 0.5759, train_bce_loss: 1.3857, train_bce_dl_loss: 0.5759, step time: 0.4285\n",
      "batch: 17/17, train_dl_loss: 0.5294, train_bce_loss: 1.3831, train_bce_dl_loss: 0.5294, step time: 0.1107\n",
      "LOSS train DiceLoss: 0.6079, LOSS train BCE: 1.3783, LOSS train BCE-DiceLoss: 0.6079, LOSS val DiceLoss: 0.6534, LOSS val BCE: 1.3823, LOSS val BCE-DiceLoss: 0.6534, METRIC val: 0.3634\n",
      "time consuming of epoch 30 is: 434.9424\n",
      "----------\n",
      "EPOCH 31/80\n",
      "batch: 0/17, train_dl_loss: 0.5608, train_bce_loss: 1.3745, train_bce_dl_loss: 0.5608, step time: 0.4398\n",
      "batch: 1/17, train_dl_loss: 0.5973, train_bce_loss: 1.3831, train_bce_dl_loss: 0.5973, step time: 0.3737\n",
      "batch: 2/17, train_dl_loss: 0.6258, train_bce_loss: 1.3725, train_bce_dl_loss: 0.6258, step time: 0.4412\n",
      "batch: 3/17, train_dl_loss: 0.6444, train_bce_loss: 1.3920, train_bce_dl_loss: 0.6444, step time: 0.3694\n",
      "batch: 4/17, train_dl_loss: 0.5579, train_bce_loss: 1.3694, train_bce_dl_loss: 0.5579, step time: 0.4334\n",
      "batch: 5/17, train_dl_loss: 0.5978, train_bce_loss: 1.3756, train_bce_dl_loss: 0.5978, step time: 0.3772\n",
      "batch: 6/17, train_dl_loss: 0.6536, train_bce_loss: 1.3987, train_bce_dl_loss: 0.6536, step time: 0.4179\n",
      "batch: 7/17, train_dl_loss: 0.5665, train_bce_loss: 1.3751, train_bce_dl_loss: 0.5665, step time: 0.3721\n",
      "batch: 8/17, train_dl_loss: 0.5881, train_bce_loss: 1.3702, train_bce_dl_loss: 0.5881, step time: 0.4295\n",
      "batch: 9/17, train_dl_loss: 0.6217, train_bce_loss: 1.3936, train_bce_dl_loss: 0.6217, step time: 0.4206\n",
      "batch: 10/17, train_dl_loss: 0.6460, train_bce_loss: 1.3749, train_bce_dl_loss: 0.6460, step time: 0.4331\n",
      "batch: 11/17, train_dl_loss: 0.5733, train_bce_loss: 1.3696, train_bce_dl_loss: 0.5733, step time: 0.4248\n",
      "batch: 12/17, train_dl_loss: 0.5910, train_bce_loss: 1.3824, train_bce_dl_loss: 0.5910, step time: 0.4362\n",
      "batch: 13/17, train_dl_loss: 0.7092, train_bce_loss: 1.3897, train_bce_dl_loss: 0.7092, step time: 0.3799\n",
      "batch: 14/17, train_dl_loss: 0.5971, train_bce_loss: 1.4132, train_bce_dl_loss: 0.5971, step time: 0.4202\n",
      "batch: 15/17, train_dl_loss: 0.5629, train_bce_loss: 1.3922, train_bce_dl_loss: 0.5629, step time: 0.3718\n",
      "batch: 16/17, train_dl_loss: 0.5748, train_bce_loss: 1.3965, train_bce_dl_loss: 0.5748, step time: 0.4282\n",
      "batch: 17/17, train_dl_loss: 0.5312, train_bce_loss: 1.4036, train_bce_dl_loss: 0.5312, step time: 0.1104\n",
      "LOSS train DiceLoss: 0.6000, LOSS train BCE: 1.3848, LOSS train BCE-DiceLoss: 0.6000, LOSS val DiceLoss: 0.6494, LOSS val BCE: 1.3879, LOSS val BCE-DiceLoss: 0.6494, METRIC val: 0.3622\n",
      "time consuming of epoch 31 is: 499.9334\n",
      "----------\n",
      "EPOCH 32/80\n",
      "batch: 0/17, train_dl_loss: 0.5783, train_bce_loss: 1.3777, train_bce_dl_loss: 0.5783, step time: 0.4226\n",
      "batch: 1/17, train_dl_loss: 0.5945, train_bce_loss: 1.4112, train_bce_dl_loss: 0.5945, step time: 0.3740\n",
      "batch: 2/17, train_dl_loss: 0.6416, train_bce_loss: 1.3913, train_bce_dl_loss: 0.6416, step time: 0.4713\n",
      "batch: 3/17, train_dl_loss: 0.6822, train_bce_loss: 1.4035, train_bce_dl_loss: 0.6822, step time: 0.3800\n",
      "batch: 4/17, train_dl_loss: 0.5756, train_bce_loss: 1.3991, train_bce_dl_loss: 0.5756, step time: 0.4425\n",
      "batch: 5/17, train_dl_loss: 0.6066, train_bce_loss: 1.3859, train_bce_dl_loss: 0.6066, step time: 0.3797\n",
      "batch: 6/17, train_dl_loss: 0.6070, train_bce_loss: 1.3872, train_bce_dl_loss: 0.6070, step time: 0.4366\n",
      "batch: 7/17, train_dl_loss: 0.5472, train_bce_loss: 1.3801, train_bce_dl_loss: 0.5472, step time: 0.3743\n",
      "batch: 8/17, train_dl_loss: 0.5784, train_bce_loss: 1.3817, train_bce_dl_loss: 0.5784, step time: 0.4230\n",
      "batch: 9/17, train_dl_loss: 0.7576, train_bce_loss: 1.4042, train_bce_dl_loss: 0.7576, step time: 0.3815\n",
      "batch: 10/17, train_dl_loss: 0.6556, train_bce_loss: 1.3845, train_bce_dl_loss: 0.6556, step time: 0.4562\n",
      "batch: 11/17, train_dl_loss: 0.5507, train_bce_loss: 1.3842, train_bce_dl_loss: 0.5507, step time: 0.4433\n",
      "batch: 12/17, train_dl_loss: 0.5728, train_bce_loss: 1.3864, train_bce_dl_loss: 0.5728, step time: 0.4144\n",
      "batch: 13/17, train_dl_loss: 0.7384, train_bce_loss: 1.4019, train_bce_dl_loss: 0.7384, step time: 0.4401\n",
      "batch: 14/17, train_dl_loss: 0.6581, train_bce_loss: 1.3964, train_bce_dl_loss: 0.6581, step time: 0.4247\n",
      "batch: 15/17, train_dl_loss: 0.5798, train_bce_loss: 1.3887, train_bce_dl_loss: 0.5798, step time: 0.3793\n",
      "batch: 16/17, train_dl_loss: 0.6250, train_bce_loss: 1.4028, train_bce_dl_loss: 0.6250, step time: 0.4282\n",
      "batch: 17/17, train_dl_loss: 0.5268, train_bce_loss: 1.4003, train_bce_dl_loss: 0.5268, step time: 0.1101\n",
      "LOSS train DiceLoss: 0.6153, LOSS train BCE: 1.3926, LOSS train BCE-DiceLoss: 0.6153, LOSS val DiceLoss: 0.6499, LOSS val BCE: 1.3892, LOSS val BCE-DiceLoss: 0.6499, METRIC val: 0.3613\n",
      "time consuming of epoch 32 is: 454.3622\n",
      "----------\n",
      "EPOCH 33/80\n",
      "batch: 0/17, train_dl_loss: 0.5683, train_bce_loss: 1.3872, train_bce_dl_loss: 0.5683, step time: 0.4259\n",
      "batch: 1/17, train_dl_loss: 0.5570, train_bce_loss: 1.3927, train_bce_dl_loss: 0.5570, step time: 0.3769\n",
      "batch: 2/17, train_dl_loss: 0.5966, train_bce_loss: 1.3907, train_bce_dl_loss: 0.5966, step time: 0.4219\n",
      "batch: 3/17, train_dl_loss: 0.6831, train_bce_loss: 1.3865, train_bce_dl_loss: 0.6831, step time: 0.3834\n",
      "batch: 4/17, train_dl_loss: 0.5634, train_bce_loss: 1.3924, train_bce_dl_loss: 0.5634, step time: 0.4548\n",
      "batch: 5/17, train_dl_loss: 0.5694, train_bce_loss: 1.3938, train_bce_dl_loss: 0.5694, step time: 0.4397\n",
      "batch: 6/17, train_dl_loss: 0.6376, train_bce_loss: 1.3955, train_bce_dl_loss: 0.6376, step time: 0.4440\n",
      "batch: 7/17, train_dl_loss: 0.5663, train_bce_loss: 1.3768, train_bce_dl_loss: 0.5663, step time: 0.4395\n",
      "batch: 8/17, train_dl_loss: 0.6048, train_bce_loss: 1.3782, train_bce_dl_loss: 0.6048, step time: 0.4320\n",
      "batch: 9/17, train_dl_loss: 0.5879, train_bce_loss: 1.3840, train_bce_dl_loss: 0.5879, step time: 0.4315\n",
      "batch: 10/17, train_dl_loss: 0.6310, train_bce_loss: 1.3803, train_bce_dl_loss: 0.6310, step time: 0.4329\n",
      "batch: 11/17, train_dl_loss: 0.5433, train_bce_loss: 1.3862, train_bce_dl_loss: 0.5433, step time: 0.4260\n",
      "batch: 12/17, train_dl_loss: 0.5560, train_bce_loss: 1.3813, train_bce_dl_loss: 0.5560, step time: 0.4394\n",
      "batch: 13/17, train_dl_loss: 0.7255, train_bce_loss: 1.4019, train_bce_dl_loss: 0.7255, step time: 0.4247\n",
      "batch: 14/17, train_dl_loss: 0.6265, train_bce_loss: 1.4110, train_bce_dl_loss: 0.6265, step time: 0.4152\n",
      "batch: 15/17, train_dl_loss: 0.6408, train_bce_loss: 1.4120, train_bce_dl_loss: 0.6408, step time: 0.3731\n",
      "batch: 16/17, train_dl_loss: 0.5769, train_bce_loss: 1.3996, train_bce_dl_loss: 0.5769, step time: 0.4126\n",
      "batch: 17/17, train_dl_loss: 0.4978, train_bce_loss: 1.3918, train_bce_dl_loss: 0.4978, step time: 0.1103\n",
      "LOSS train DiceLoss: 0.5962, LOSS train BCE: 1.3912, LOSS train BCE-DiceLoss: 0.5962, LOSS val DiceLoss: 0.6413, LOSS val BCE: 1.3931, LOSS val BCE-DiceLoss: 0.6413, METRIC val: 0.3730\n",
      "time consuming of epoch 33 is: 436.4351\n",
      "----------\n",
      "EPOCH 34/80\n",
      "batch: 0/17, train_dl_loss: 0.5460, train_bce_loss: 1.3990, train_bce_dl_loss: 0.5460, step time: 0.4279\n",
      "batch: 1/17, train_dl_loss: 0.5922, train_bce_loss: 1.4004, train_bce_dl_loss: 0.5922, step time: 0.3736\n",
      "batch: 2/17, train_dl_loss: 0.6570, train_bce_loss: 1.3951, train_bce_dl_loss: 0.6570, step time: 0.4253\n",
      "batch: 3/17, train_dl_loss: 0.6545, train_bce_loss: 1.4106, train_bce_dl_loss: 0.6545, step time: 0.3789\n",
      "batch: 4/17, train_dl_loss: 0.5444, train_bce_loss: 1.3953, train_bce_dl_loss: 0.5444, step time: 0.4376\n",
      "batch: 5/17, train_dl_loss: 0.5472, train_bce_loss: 1.3956, train_bce_dl_loss: 0.5472, step time: 0.3833\n",
      "batch: 6/17, train_dl_loss: 0.5953, train_bce_loss: 1.3965, train_bce_dl_loss: 0.5953, step time: 0.4325\n",
      "batch: 7/17, train_dl_loss: 0.5795, train_bce_loss: 1.3987, train_bce_dl_loss: 0.5795, step time: 0.3725\n",
      "batch: 8/17, train_dl_loss: 0.6132, train_bce_loss: 1.3991, train_bce_dl_loss: 0.6132, step time: 0.4220\n",
      "batch: 9/17, train_dl_loss: 0.5757, train_bce_loss: 1.4014, train_bce_dl_loss: 0.5757, step time: 0.3855\n",
      "batch: 10/17, train_dl_loss: 0.6416, train_bce_loss: 1.3970, train_bce_dl_loss: 0.6416, step time: 0.4193\n",
      "batch: 11/17, train_dl_loss: 0.5486, train_bce_loss: 1.3997, train_bce_dl_loss: 0.5486, step time: 0.4284\n",
      "batch: 12/17, train_dl_loss: 0.5815, train_bce_loss: 1.3978, train_bce_dl_loss: 0.5815, step time: 0.4231\n",
      "batch: 13/17, train_dl_loss: 0.7551, train_bce_loss: 1.4147, train_bce_dl_loss: 0.7551, step time: 0.3831\n",
      "batch: 14/17, train_dl_loss: 0.6080, train_bce_loss: 1.4256, train_bce_dl_loss: 0.6080, step time: 0.4156\n",
      "batch: 15/17, train_dl_loss: 0.5514, train_bce_loss: 1.4119, train_bce_dl_loss: 0.5514, step time: 0.3770\n",
      "batch: 16/17, train_dl_loss: 0.5509, train_bce_loss: 1.4065, train_bce_dl_loss: 0.5509, step time: 0.4114\n",
      "batch: 17/17, train_dl_loss: 0.4999, train_bce_loss: 1.4014, train_bce_dl_loss: 0.4999, step time: 0.1109\n",
      "LOSS train DiceLoss: 0.5912, LOSS train BCE: 1.4026, LOSS train BCE-DiceLoss: 0.5912, LOSS val DiceLoss: 0.6418, LOSS val BCE: 1.4013, LOSS val BCE-DiceLoss: 0.6418, METRIC val: 0.3701\n",
      "time consuming of epoch 34 is: 432.8935\n",
      "----------\n",
      "EPOCH 35/80\n",
      "batch: 0/17, train_dl_loss: 0.5620, train_bce_loss: 1.4040, train_bce_dl_loss: 0.5620, step time: 0.4237\n",
      "batch: 1/17, train_dl_loss: 0.5674, train_bce_loss: 1.4067, train_bce_dl_loss: 0.5674, step time: 0.3749\n",
      "batch: 2/17, train_dl_loss: 0.6154, train_bce_loss: 1.3981, train_bce_dl_loss: 0.6154, step time: 0.4189\n",
      "batch: 3/17, train_dl_loss: 0.6482, train_bce_loss: 1.4135, train_bce_dl_loss: 0.6482, step time: 0.4351\n",
      "batch: 4/17, train_dl_loss: 0.5536, train_bce_loss: 1.4037, train_bce_dl_loss: 0.5536, step time: 0.4278\n",
      "batch: 5/17, train_dl_loss: 0.5718, train_bce_loss: 1.3882, train_bce_dl_loss: 0.5718, step time: 0.4348\n",
      "batch: 6/17, train_dl_loss: 0.6183, train_bce_loss: 1.4098, train_bce_dl_loss: 0.6183, step time: 0.4209\n",
      "batch: 7/17, train_dl_loss: 0.5574, train_bce_loss: 1.3898, train_bce_dl_loss: 0.5574, step time: 0.4194\n",
      "batch: 8/17, train_dl_loss: 0.5946, train_bce_loss: 1.3913, train_bce_dl_loss: 0.5946, step time: 0.4234\n",
      "batch: 9/17, train_dl_loss: 0.5693, train_bce_loss: 1.4121, train_bce_dl_loss: 0.5693, step time: 0.4158\n",
      "batch: 10/17, train_dl_loss: 0.6195, train_bce_loss: 1.4124, train_bce_dl_loss: 0.6195, step time: 0.4205\n",
      "batch: 11/17, train_dl_loss: 0.5596, train_bce_loss: 1.4065, train_bce_dl_loss: 0.5596, step time: 0.4286\n",
      "batch: 12/17, train_dl_loss: 0.5951, train_bce_loss: 1.4018, train_bce_dl_loss: 0.5951, step time: 0.4356\n",
      "batch: 13/17, train_dl_loss: 0.7215, train_bce_loss: 1.4239, train_bce_dl_loss: 0.7215, step time: 0.4451\n",
      "batch: 14/17, train_dl_loss: 0.6309, train_bce_loss: 1.4236, train_bce_dl_loss: 0.6309, step time: 0.4225\n",
      "batch: 15/17, train_dl_loss: 0.5717, train_bce_loss: 1.4082, train_bce_dl_loss: 0.5717, step time: 0.3681\n",
      "batch: 16/17, train_dl_loss: 0.5489, train_bce_loss: 1.4088, train_bce_dl_loss: 0.5489, step time: 0.4313\n",
      "batch: 17/17, train_dl_loss: 0.5461, train_bce_loss: 1.4061, train_bce_dl_loss: 0.5461, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.5917, LOSS train BCE: 1.4060, LOSS train BCE-DiceLoss: 0.5917, LOSS val DiceLoss: 0.6373, LOSS val BCE: 1.4043, LOSS val BCE-DiceLoss: 0.6373, METRIC val: 0.3775\n",
      "time consuming of epoch 35 is: 530.0880\n",
      "----------\n",
      "EPOCH 36/80\n",
      "batch: 0/17, train_dl_loss: 0.5562, train_bce_loss: 1.3939, train_bce_dl_loss: 0.5562, step time: 0.4438\n",
      "batch: 1/17, train_dl_loss: 0.6076, train_bce_loss: 1.4116, train_bce_dl_loss: 0.6076, step time: 0.3866\n",
      "batch: 2/17, train_dl_loss: 0.6038, train_bce_loss: 1.4074, train_bce_dl_loss: 0.6038, step time: 0.4282\n",
      "batch: 3/17, train_dl_loss: 0.5985, train_bce_loss: 1.4147, train_bce_dl_loss: 0.5985, step time: 0.3695\n",
      "batch: 4/17, train_dl_loss: 0.5346, train_bce_loss: 1.4055, train_bce_dl_loss: 0.5346, step time: 0.4400\n",
      "batch: 5/17, train_dl_loss: 0.5556, train_bce_loss: 1.3992, train_bce_dl_loss: 0.5556, step time: 0.3723\n",
      "batch: 6/17, train_dl_loss: 0.5865, train_bce_loss: 1.4259, train_bce_dl_loss: 0.5865, step time: 0.4164\n",
      "batch: 7/17, train_dl_loss: 0.5382, train_bce_loss: 1.4042, train_bce_dl_loss: 0.5382, step time: 0.3879\n",
      "batch: 8/17, train_dl_loss: 0.5521, train_bce_loss: 1.3917, train_bce_dl_loss: 0.5521, step time: 0.4208\n",
      "batch: 9/17, train_dl_loss: 0.5526, train_bce_loss: 1.4153, train_bce_dl_loss: 0.5526, step time: 0.3723\n",
      "batch: 10/17, train_dl_loss: 0.6915, train_bce_loss: 1.4146, train_bce_dl_loss: 0.6915, step time: 0.4413\n",
      "batch: 11/17, train_dl_loss: 0.5697, train_bce_loss: 1.3890, train_bce_dl_loss: 0.5697, step time: 0.3814\n",
      "batch: 12/17, train_dl_loss: 0.6058, train_bce_loss: 1.4096, train_bce_dl_loss: 0.6058, step time: 0.4334\n",
      "batch: 13/17, train_dl_loss: 0.7111, train_bce_loss: 1.4040, train_bce_dl_loss: 0.7111, step time: 0.3814\n",
      "batch: 14/17, train_dl_loss: 0.6398, train_bce_loss: 1.4172, train_bce_dl_loss: 0.6398, step time: 0.4176\n",
      "batch: 15/17, train_dl_loss: 0.5537, train_bce_loss: 1.4156, train_bce_dl_loss: 0.5537, step time: 0.3766\n",
      "batch: 16/17, train_dl_loss: 0.5362, train_bce_loss: 1.4184, train_bce_dl_loss: 0.5362, step time: 0.4281\n",
      "batch: 17/17, train_dl_loss: 0.5017, train_bce_loss: 1.4110, train_bce_dl_loss: 0.5017, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5831, LOSS train BCE: 1.4083, LOSS train BCE-DiceLoss: 0.5831, LOSS val DiceLoss: 0.6499, LOSS val BCE: 1.4120, LOSS val BCE-DiceLoss: 0.6499, METRIC val: 0.3618\n",
      "time consuming of epoch 36 is: 455.5353\n",
      "----------\n",
      "EPOCH 37/80\n",
      "batch: 0/17, train_dl_loss: 0.5410, train_bce_loss: 1.4178, train_bce_dl_loss: 0.5410, step time: 0.4252\n",
      "batch: 1/17, train_dl_loss: 0.6257, train_bce_loss: 1.4210, train_bce_dl_loss: 0.6257, step time: 0.3760\n",
      "batch: 2/17, train_dl_loss: 0.5994, train_bce_loss: 1.4197, train_bce_dl_loss: 0.5994, step time: 0.4120\n",
      "batch: 3/17, train_dl_loss: 0.6808, train_bce_loss: 1.4078, train_bce_dl_loss: 0.6808, step time: 0.3736\n",
      "batch: 4/17, train_dl_loss: 0.5199, train_bce_loss: 1.3990, train_bce_dl_loss: 0.5199, step time: 0.4403\n",
      "batch: 5/17, train_dl_loss: 0.6159, train_bce_loss: 1.4148, train_bce_dl_loss: 0.6159, step time: 0.3821\n",
      "batch: 6/17, train_dl_loss: 0.5994, train_bce_loss: 1.4139, train_bce_dl_loss: 0.5994, step time: 0.4579\n",
      "batch: 7/17, train_dl_loss: 0.5641, train_bce_loss: 1.3931, train_bce_dl_loss: 0.5641, step time: 0.3793\n",
      "batch: 8/17, train_dl_loss: 0.5820, train_bce_loss: 1.3983, train_bce_dl_loss: 0.5820, step time: 0.4347\n",
      "batch: 9/17, train_dl_loss: 0.5683, train_bce_loss: 1.4106, train_bce_dl_loss: 0.5683, step time: 0.3724\n",
      "batch: 10/17, train_dl_loss: 0.6226, train_bce_loss: 1.4034, train_bce_dl_loss: 0.6226, step time: 0.4446\n",
      "batch: 11/17, train_dl_loss: 0.5649, train_bce_loss: 1.4013, train_bce_dl_loss: 0.5649, step time: 0.4218\n",
      "batch: 12/17, train_dl_loss: 0.5537, train_bce_loss: 1.4096, train_bce_dl_loss: 0.5537, step time: 0.4405\n",
      "batch: 13/17, train_dl_loss: 0.7555, train_bce_loss: 1.4226, train_bce_dl_loss: 0.7555, step time: 0.3751\n",
      "batch: 14/17, train_dl_loss: 0.6091, train_bce_loss: 1.4350, train_bce_dl_loss: 0.6091, step time: 0.4493\n",
      "batch: 15/17, train_dl_loss: 0.5517, train_bce_loss: 1.4307, train_bce_dl_loss: 0.5517, step time: 0.3919\n",
      "batch: 16/17, train_dl_loss: 0.5699, train_bce_loss: 1.4321, train_bce_dl_loss: 0.5699, step time: 0.4251\n",
      "batch: 17/17, train_dl_loss: 0.4913, train_bce_loss: 1.4201, train_bce_dl_loss: 0.4913, step time: 0.1095\n",
      "LOSS train DiceLoss: 0.5897, LOSS train BCE: 1.4139, LOSS train BCE-DiceLoss: 0.5897, LOSS val DiceLoss: 0.6513, LOSS val BCE: 1.4184, LOSS val BCE-DiceLoss: 0.6513, METRIC val: 0.3599\n",
      "time consuming of epoch 37 is: 447.0676\n",
      "----------\n",
      "EPOCH 38/80\n",
      "batch: 0/17, train_dl_loss: 0.5695, train_bce_loss: 1.4092, train_bce_dl_loss: 0.5695, step time: 0.4284\n",
      "batch: 1/17, train_dl_loss: 0.5791, train_bce_loss: 1.4363, train_bce_dl_loss: 0.5791, step time: 0.3741\n",
      "batch: 2/17, train_dl_loss: 0.5706, train_bce_loss: 1.4029, train_bce_dl_loss: 0.5706, step time: 0.4306\n",
      "batch: 3/17, train_dl_loss: 0.6565, train_bce_loss: 1.4279, train_bce_dl_loss: 0.6565, step time: 0.3675\n",
      "batch: 4/17, train_dl_loss: 0.5479, train_bce_loss: 1.4063, train_bce_dl_loss: 0.5479, step time: 0.4213\n",
      "batch: 5/17, train_dl_loss: 0.5358, train_bce_loss: 1.4078, train_bce_dl_loss: 0.5358, step time: 0.4269\n",
      "batch: 6/17, train_dl_loss: 0.6040, train_bce_loss: 1.4189, train_bce_dl_loss: 0.6040, step time: 0.4226\n",
      "batch: 7/17, train_dl_loss: 0.5248, train_bce_loss: 1.4039, train_bce_dl_loss: 0.5248, step time: 0.4322\n",
      "batch: 8/17, train_dl_loss: 0.5971, train_bce_loss: 1.4063, train_bce_dl_loss: 0.5971, step time: 0.4263\n",
      "batch: 9/17, train_dl_loss: 0.6022, train_bce_loss: 1.4201, train_bce_dl_loss: 0.6022, step time: 0.4217\n",
      "batch: 10/17, train_dl_loss: 0.6575, train_bce_loss: 1.4218, train_bce_dl_loss: 0.6575, step time: 0.4462\n",
      "batch: 11/17, train_dl_loss: 0.5489, train_bce_loss: 1.4160, train_bce_dl_loss: 0.5489, step time: 0.4283\n",
      "batch: 12/17, train_dl_loss: 0.5744, train_bce_loss: 1.4125, train_bce_dl_loss: 0.5744, step time: 0.4291\n",
      "batch: 13/17, train_dl_loss: 0.7225, train_bce_loss: 1.4216, train_bce_dl_loss: 0.7225, step time: 0.4226\n",
      "batch: 14/17, train_dl_loss: 0.6024, train_bce_loss: 1.4362, train_bce_dl_loss: 0.6024, step time: 0.4250\n",
      "batch: 15/17, train_dl_loss: 0.5244, train_bce_loss: 1.4246, train_bce_dl_loss: 0.5244, step time: 0.4248\n",
      "batch: 16/17, train_dl_loss: 0.5504, train_bce_loss: 1.4209, train_bce_dl_loss: 0.5504, step time: 0.4285\n",
      "batch: 17/17, train_dl_loss: 0.5562, train_bce_loss: 1.4357, train_bce_dl_loss: 0.5562, step time: 0.1098\n",
      "LOSS train DiceLoss: 0.5847, LOSS train BCE: 1.4183, LOSS train BCE-DiceLoss: 0.5847, LOSS val DiceLoss: 0.6456, LOSS val BCE: 1.4202, LOSS val BCE-DiceLoss: 0.6456, METRIC val: 0.3688\n",
      "time consuming of epoch 38 is: 515.1941\n",
      "----------\n",
      "EPOCH 39/80\n",
      "batch: 0/17, train_dl_loss: 0.5525, train_bce_loss: 1.4128, train_bce_dl_loss: 0.5525, step time: 0.4248\n",
      "batch: 1/17, train_dl_loss: 0.5495, train_bce_loss: 1.4224, train_bce_dl_loss: 0.5495, step time: 0.3791\n",
      "batch: 2/17, train_dl_loss: 0.5816, train_bce_loss: 1.4136, train_bce_dl_loss: 0.5816, step time: 0.4347\n",
      "batch: 3/17, train_dl_loss: 0.6485, train_bce_loss: 1.4120, train_bce_dl_loss: 0.6485, step time: 0.3708\n",
      "batch: 4/17, train_dl_loss: 0.5779, train_bce_loss: 1.4251, train_bce_dl_loss: 0.5779, step time: 0.4330\n",
      "batch: 5/17, train_dl_loss: 0.6022, train_bce_loss: 1.4146, train_bce_dl_loss: 0.6022, step time: 0.3807\n",
      "batch: 6/17, train_dl_loss: 0.5964, train_bce_loss: 1.4331, train_bce_dl_loss: 0.5964, step time: 0.4402\n",
      "batch: 7/17, train_dl_loss: 0.5450, train_bce_loss: 1.4022, train_bce_dl_loss: 0.5450, step time: 0.3808\n",
      "batch: 8/17, train_dl_loss: 0.5512, train_bce_loss: 1.4146, train_bce_dl_loss: 0.5512, step time: 0.4332\n",
      "batch: 9/17, train_dl_loss: 0.5911, train_bce_loss: 1.4332, train_bce_dl_loss: 0.5911, step time: 0.3799\n",
      "batch: 10/17, train_dl_loss: 0.6760, train_bce_loss: 1.4307, train_bce_dl_loss: 0.6760, step time: 0.4166\n",
      "batch: 11/17, train_dl_loss: 0.5935, train_bce_loss: 1.4191, train_bce_dl_loss: 0.5935, step time: 0.4166\n",
      "batch: 12/17, train_dl_loss: 0.5355, train_bce_loss: 1.4273, train_bce_dl_loss: 0.5355, step time: 0.4286\n",
      "batch: 13/17, train_dl_loss: 0.7101, train_bce_loss: 1.4417, train_bce_dl_loss: 0.7101, step time: 0.4415\n",
      "batch: 14/17, train_dl_loss: 0.6198, train_bce_loss: 1.4420, train_bce_dl_loss: 0.6198, step time: 0.4267\n",
      "batch: 15/17, train_dl_loss: 0.5470, train_bce_loss: 1.4191, train_bce_dl_loss: 0.5470, step time: 0.4458\n",
      "batch: 16/17, train_dl_loss: 0.5749, train_bce_loss: 1.4336, train_bce_dl_loss: 0.5749, step time: 0.4093\n",
      "batch: 17/17, train_dl_loss: 0.5398, train_bce_loss: 1.4223, train_bce_dl_loss: 0.5398, step time: 0.1117\n",
      "LOSS train DiceLoss: 0.5885, LOSS train BCE: 1.4233, LOSS train BCE-DiceLoss: 0.5885, LOSS val DiceLoss: 0.6344, LOSS val BCE: 1.4218, LOSS val BCE-DiceLoss: 0.6344, METRIC val: 0.3840\n",
      "time consuming of epoch 39 is: 445.8604\n",
      "----------\n",
      "EPOCH 40/80\n",
      "batch: 0/17, train_dl_loss: 0.5874, train_bce_loss: 1.4122, train_bce_dl_loss: 0.5874, step time: 0.4384\n",
      "batch: 1/17, train_dl_loss: 0.5580, train_bce_loss: 1.4341, train_bce_dl_loss: 0.5580, step time: 0.3766\n",
      "batch: 2/17, train_dl_loss: 0.6156, train_bce_loss: 1.4169, train_bce_dl_loss: 0.6156, step time: 0.4208\n",
      "batch: 3/17, train_dl_loss: 0.6005, train_bce_loss: 1.4267, train_bce_dl_loss: 0.6005, step time: 0.4261\n",
      "batch: 4/17, train_dl_loss: 0.5516, train_bce_loss: 1.4113, train_bce_dl_loss: 0.5516, step time: 0.4158\n",
      "batch: 5/17, train_dl_loss: 0.5842, train_bce_loss: 1.4349, train_bce_dl_loss: 0.5842, step time: 0.4561\n",
      "batch: 6/17, train_dl_loss: 0.5831, train_bce_loss: 1.4278, train_bce_dl_loss: 0.5831, step time: 0.4185\n",
      "batch: 7/17, train_dl_loss: 0.6198, train_bce_loss: 1.4292, train_bce_dl_loss: 0.6198, step time: 0.4294\n",
      "batch: 8/17, train_dl_loss: 0.5670, train_bce_loss: 1.4171, train_bce_dl_loss: 0.5670, step time: 0.4184\n",
      "batch: 9/17, train_dl_loss: 0.5761, train_bce_loss: 1.4286, train_bce_dl_loss: 0.5761, step time: 0.4351\n",
      "batch: 10/17, train_dl_loss: 0.6318, train_bce_loss: 1.4252, train_bce_dl_loss: 0.6318, step time: 0.4283\n",
      "batch: 11/17, train_dl_loss: 0.5410, train_bce_loss: 1.3976, train_bce_dl_loss: 0.5410, step time: 0.4291\n",
      "batch: 12/17, train_dl_loss: 0.6031, train_bce_loss: 1.4330, train_bce_dl_loss: 0.6031, step time: 0.4196\n",
      "batch: 13/17, train_dl_loss: 0.6914, train_bce_loss: 1.4411, train_bce_dl_loss: 0.6914, step time: 0.3872\n",
      "batch: 14/17, train_dl_loss: 0.6068, train_bce_loss: 1.4466, train_bce_dl_loss: 0.6068, step time: 0.4354\n",
      "batch: 15/17, train_dl_loss: 0.5609, train_bce_loss: 1.4307, train_bce_dl_loss: 0.5609, step time: 0.3723\n",
      "batch: 16/17, train_dl_loss: 0.5839, train_bce_loss: 1.4356, train_bce_dl_loss: 0.5839, step time: 0.4132\n",
      "batch: 17/17, train_dl_loss: 0.4972, train_bce_loss: 1.4293, train_bce_dl_loss: 0.4972, step time: 0.1108\n",
      "LOSS train DiceLoss: 0.5866, LOSS train BCE: 1.4266, LOSS train BCE-DiceLoss: 0.5866, LOSS val DiceLoss: 0.6325, LOSS val BCE: 1.4273, LOSS val BCE-DiceLoss: 0.6325, METRIC val: 0.3883\n",
      "time consuming of epoch 40 is: 455.5254\n",
      "----------\n",
      "EPOCH 41/80\n",
      "batch: 0/17, train_dl_loss: 0.5423, train_bce_loss: 1.4383, train_bce_dl_loss: 0.5423, step time: 0.4411\n",
      "batch: 1/17, train_dl_loss: 0.5281, train_bce_loss: 1.4321, train_bce_dl_loss: 0.5281, step time: 0.3808\n",
      "batch: 2/17, train_dl_loss: 0.6331, train_bce_loss: 1.4339, train_bce_dl_loss: 0.6331, step time: 0.4244\n",
      "batch: 3/17, train_dl_loss: 0.6821, train_bce_loss: 1.4509, train_bce_dl_loss: 0.6821, step time: 0.3670\n",
      "batch: 4/17, train_dl_loss: 0.5518, train_bce_loss: 1.4320, train_bce_dl_loss: 0.5518, step time: 0.4252\n",
      "batch: 5/17, train_dl_loss: 0.5860, train_bce_loss: 1.4218, train_bce_dl_loss: 0.5860, step time: 0.3828\n",
      "batch: 6/17, train_dl_loss: 0.6062, train_bce_loss: 1.4358, train_bce_dl_loss: 0.6062, step time: 0.4204\n",
      "batch: 7/17, train_dl_loss: 0.5148, train_bce_loss: 1.4194, train_bce_dl_loss: 0.5148, step time: 0.3757\n",
      "batch: 8/17, train_dl_loss: 0.5556, train_bce_loss: 1.4271, train_bce_dl_loss: 0.5556, step time: 0.4195\n",
      "batch: 9/17, train_dl_loss: 0.5855, train_bce_loss: 1.4391, train_bce_dl_loss: 0.5855, step time: 0.3729\n",
      "batch: 10/17, train_dl_loss: 0.6589, train_bce_loss: 1.4163, train_bce_dl_loss: 0.6589, step time: 0.4274\n",
      "batch: 11/17, train_dl_loss: 0.5780, train_bce_loss: 1.4117, train_bce_dl_loss: 0.5780, step time: 0.3791\n",
      "batch: 12/17, train_dl_loss: 0.6201, train_bce_loss: 1.4422, train_bce_dl_loss: 0.6201, step time: 0.4258\n",
      "batch: 13/17, train_dl_loss: 0.7097, train_bce_loss: 1.4338, train_bce_dl_loss: 0.7097, step time: 0.3758\n",
      "batch: 14/17, train_dl_loss: 0.5931, train_bce_loss: 1.4492, train_bce_dl_loss: 0.5931, step time: 0.4391\n",
      "batch: 15/17, train_dl_loss: 0.5428, train_bce_loss: 1.4307, train_bce_dl_loss: 0.5428, step time: 0.3762\n",
      "batch: 16/17, train_dl_loss: 0.5463, train_bce_loss: 1.4376, train_bce_dl_loss: 0.5463, step time: 0.4216\n",
      "batch: 17/17, train_dl_loss: 0.4882, train_bce_loss: 1.4292, train_bce_dl_loss: 0.4882, step time: 0.1104\n",
      "LOSS train DiceLoss: 0.5846, LOSS train BCE: 1.4323, LOSS train BCE-DiceLoss: 0.5846, LOSS val DiceLoss: 0.6588, LOSS val BCE: 1.4313, LOSS val BCE-DiceLoss: 0.6588, METRIC val: 0.3476\n",
      "time consuming of epoch 41 is: 446.6222\n",
      "----------\n",
      "EPOCH 42/80\n",
      "batch: 0/17, train_dl_loss: 0.5574, train_bce_loss: 1.4238, train_bce_dl_loss: 0.5574, step time: 0.4198\n",
      "batch: 1/17, train_dl_loss: 0.5923, train_bce_loss: 1.4435, train_bce_dl_loss: 0.5923, step time: 0.4253\n",
      "batch: 2/17, train_dl_loss: 0.6188, train_bce_loss: 1.4417, train_bce_dl_loss: 0.6188, step time: 0.4384\n",
      "batch: 3/17, train_dl_loss: 0.5928, train_bce_loss: 1.4369, train_bce_dl_loss: 0.5928, step time: 0.3785\n",
      "batch: 4/17, train_dl_loss: 0.5619, train_bce_loss: 1.4416, train_bce_dl_loss: 0.5619, step time: 0.4365\n",
      "batch: 5/17, train_dl_loss: 0.6391, train_bce_loss: 1.4348, train_bce_dl_loss: 0.6391, step time: 0.3883\n",
      "batch: 6/17, train_dl_loss: 0.6214, train_bce_loss: 1.4476, train_bce_dl_loss: 0.6214, step time: 0.4409\n",
      "batch: 7/17, train_dl_loss: 0.5326, train_bce_loss: 1.4167, train_bce_dl_loss: 0.5326, step time: 0.3808\n",
      "batch: 8/17, train_dl_loss: 0.5736, train_bce_loss: 1.4220, train_bce_dl_loss: 0.5736, step time: 0.4138\n",
      "batch: 9/17, train_dl_loss: 0.5679, train_bce_loss: 1.4271, train_bce_dl_loss: 0.5679, step time: 0.3692\n",
      "batch: 10/17, train_dl_loss: 0.6114, train_bce_loss: 1.4119, train_bce_dl_loss: 0.6114, step time: 0.4309\n",
      "batch: 11/17, train_dl_loss: 0.5276, train_bce_loss: 1.4167, train_bce_dl_loss: 0.5276, step time: 0.3784\n",
      "batch: 12/17, train_dl_loss: 0.5611, train_bce_loss: 1.4292, train_bce_dl_loss: 0.5611, step time: 0.4431\n",
      "batch: 13/17, train_dl_loss: 0.6984, train_bce_loss: 1.4407, train_bce_dl_loss: 0.6984, step time: 0.3816\n",
      "batch: 14/17, train_dl_loss: 0.6051, train_bce_loss: 1.4543, train_bce_dl_loss: 0.6051, step time: 0.4182\n",
      "batch: 15/17, train_dl_loss: 0.5410, train_bce_loss: 1.4353, train_bce_dl_loss: 0.5410, step time: 0.3744\n",
      "batch: 16/17, train_dl_loss: 0.5290, train_bce_loss: 1.4392, train_bce_dl_loss: 0.5290, step time: 0.4110\n",
      "batch: 17/17, train_dl_loss: 0.4851, train_bce_loss: 1.4477, train_bce_dl_loss: 0.4851, step time: 0.1126\n",
      "LOSS train DiceLoss: 0.5787, LOSS train BCE: 1.4339, LOSS train BCE-DiceLoss: 0.5787, LOSS val DiceLoss: 0.6314, LOSS val BCE: 1.4314, LOSS val BCE-DiceLoss: 0.6314, METRIC val: 0.3867\n",
      "time consuming of epoch 42 is: 495.5480\n",
      "----------\n",
      "EPOCH 43/80\n",
      "batch: 0/17, train_dl_loss: 0.5396, train_bce_loss: 1.4174, train_bce_dl_loss: 0.5396, step time: 0.4232\n",
      "batch: 1/17, train_dl_loss: 0.6437, train_bce_loss: 1.4401, train_bce_dl_loss: 0.6437, step time: 0.4180\n",
      "batch: 2/17, train_dl_loss: 0.6297, train_bce_loss: 1.4396, train_bce_dl_loss: 0.6297, step time: 0.4378\n",
      "batch: 3/17, train_dl_loss: 0.6384, train_bce_loss: 1.4534, train_bce_dl_loss: 0.6384, step time: 0.3720\n",
      "batch: 4/17, train_dl_loss: 0.5866, train_bce_loss: 1.4341, train_bce_dl_loss: 0.5866, step time: 0.4133\n",
      "batch: 5/17, train_dl_loss: 0.5483, train_bce_loss: 1.4176, train_bce_dl_loss: 0.5483, step time: 0.4304\n",
      "batch: 6/17, train_dl_loss: 0.5801, train_bce_loss: 1.4417, train_bce_dl_loss: 0.5801, step time: 0.4295\n",
      "batch: 7/17, train_dl_loss: 0.5322, train_bce_loss: 1.4141, train_bce_dl_loss: 0.5322, step time: 0.4200\n",
      "batch: 8/17, train_dl_loss: 0.5619, train_bce_loss: 1.4083, train_bce_dl_loss: 0.5619, step time: 0.4316\n",
      "batch: 9/17, train_dl_loss: 0.5695, train_bce_loss: 1.4455, train_bce_dl_loss: 0.5695, step time: 0.4136\n",
      "batch: 10/17, train_dl_loss: 0.6122, train_bce_loss: 1.4311, train_bce_dl_loss: 0.6122, step time: 0.4255\n",
      "batch: 11/17, train_dl_loss: 0.5785, train_bce_loss: 1.4230, train_bce_dl_loss: 0.5785, step time: 0.4325\n",
      "batch: 12/17, train_dl_loss: 0.5801, train_bce_loss: 1.4262, train_bce_dl_loss: 0.5801, step time: 0.4336\n",
      "batch: 13/17, train_dl_loss: 0.6948, train_bce_loss: 1.4426, train_bce_dl_loss: 0.6948, step time: 0.4386\n",
      "batch: 14/17, train_dl_loss: 0.5793, train_bce_loss: 1.4533, train_bce_dl_loss: 0.5793, step time: 0.4400\n",
      "batch: 15/17, train_dl_loss: 0.5503, train_bce_loss: 1.4382, train_bce_dl_loss: 0.5503, step time: 0.4421\n",
      "batch: 16/17, train_dl_loss: 0.5422, train_bce_loss: 1.4387, train_bce_dl_loss: 0.5422, step time: 0.4149\n",
      "batch: 17/17, train_dl_loss: 0.5428, train_bce_loss: 1.4352, train_bce_dl_loss: 0.5428, step time: 0.1100\n",
      "LOSS train DiceLoss: 0.5839, LOSS train BCE: 1.4333, LOSS train BCE-DiceLoss: 0.5839, LOSS val DiceLoss: 0.6301, LOSS val BCE: 1.4350, LOSS val BCE-DiceLoss: 0.6301, METRIC val: 0.3896\n",
      "time consuming of epoch 43 is: 534.2896\n",
      "----------\n",
      "EPOCH 44/80\n",
      "batch: 0/17, train_dl_loss: 0.5635, train_bce_loss: 1.4488, train_bce_dl_loss: 0.5635, step time: 0.4191\n",
      "batch: 1/17, train_dl_loss: 0.5664, train_bce_loss: 1.4503, train_bce_dl_loss: 0.5664, step time: 0.3816\n",
      "batch: 2/17, train_dl_loss: 0.6370, train_bce_loss: 1.4309, train_bce_dl_loss: 0.6370, step time: 0.4104\n",
      "batch: 3/17, train_dl_loss: 0.6094, train_bce_loss: 1.4211, train_bce_dl_loss: 0.6094, step time: 0.3697\n",
      "batch: 4/17, train_dl_loss: 0.5555, train_bce_loss: 1.4430, train_bce_dl_loss: 0.5555, step time: 0.4479\n",
      "batch: 5/17, train_dl_loss: 0.5573, train_bce_loss: 1.4209, train_bce_dl_loss: 0.5573, step time: 0.4313\n",
      "batch: 6/17, train_dl_loss: 0.5761, train_bce_loss: 1.4419, train_bce_dl_loss: 0.5761, step time: 0.4219\n",
      "batch: 7/17, train_dl_loss: 0.5152, train_bce_loss: 1.4185, train_bce_dl_loss: 0.5152, step time: 0.4238\n",
      "batch: 8/17, train_dl_loss: 0.5552, train_bce_loss: 1.4300, train_bce_dl_loss: 0.5552, step time: 0.4296\n",
      "batch: 9/17, train_dl_loss: 0.5531, train_bce_loss: 1.4355, train_bce_dl_loss: 0.5531, step time: 0.4306\n",
      "batch: 10/17, train_dl_loss: 0.6050, train_bce_loss: 1.4405, train_bce_dl_loss: 0.6050, step time: 0.4326\n",
      "batch: 11/17, train_dl_loss: 0.5260, train_bce_loss: 1.4245, train_bce_dl_loss: 0.5260, step time: 0.4379\n",
      "batch: 12/17, train_dl_loss: 0.5546, train_bce_loss: 1.4171, train_bce_dl_loss: 0.5546, step time: 0.4211\n",
      "batch: 13/17, train_dl_loss: 0.7196, train_bce_loss: 1.4454, train_bce_dl_loss: 0.7196, step time: 0.4312\n",
      "batch: 14/17, train_dl_loss: 0.5731, train_bce_loss: 1.4570, train_bce_dl_loss: 0.5731, step time: 0.4257\n",
      "batch: 15/17, train_dl_loss: 0.5437, train_bce_loss: 1.4402, train_bce_dl_loss: 0.5437, step time: 0.4161\n",
      "batch: 16/17, train_dl_loss: 0.5766, train_bce_loss: 1.4428, train_bce_dl_loss: 0.5766, step time: 0.4284\n",
      "batch: 17/17, train_dl_loss: 0.4815, train_bce_loss: 1.4408, train_bce_dl_loss: 0.4815, step time: 0.1111\n",
      "LOSS train DiceLoss: 0.5705, LOSS train BCE: 1.4361, LOSS train BCE-DiceLoss: 0.5705, LOSS val DiceLoss: 0.6293, LOSS val BCE: 1.4371, LOSS val BCE-DiceLoss: 0.6293, METRIC val: 0.3889\n",
      "time consuming of epoch 44 is: 522.1535\n",
      "----------\n",
      "EPOCH 45/80\n",
      "batch: 0/17, train_dl_loss: 0.5625, train_bce_loss: 1.4402, train_bce_dl_loss: 0.5625, step time: 0.4237\n",
      "batch: 1/17, train_dl_loss: 0.5670, train_bce_loss: 1.4409, train_bce_dl_loss: 0.5670, step time: 0.3783\n",
      "batch: 2/17, train_dl_loss: 0.5653, train_bce_loss: 1.4365, train_bce_dl_loss: 0.5653, step time: 0.4140\n",
      "batch: 3/17, train_dl_loss: 0.6087, train_bce_loss: 1.4417, train_bce_dl_loss: 0.6087, step time: 0.3740\n",
      "batch: 4/17, train_dl_loss: 0.5466, train_bce_loss: 1.4286, train_bce_dl_loss: 0.5466, step time: 0.4147\n",
      "batch: 5/17, train_dl_loss: 0.5704, train_bce_loss: 1.4332, train_bce_dl_loss: 0.5704, step time: 0.3786\n",
      "batch: 6/17, train_dl_loss: 0.5924, train_bce_loss: 1.4500, train_bce_dl_loss: 0.5924, step time: 0.4257\n",
      "batch: 7/17, train_dl_loss: 0.5561, train_bce_loss: 1.4268, train_bce_dl_loss: 0.5561, step time: 0.3832\n",
      "batch: 8/17, train_dl_loss: 0.5440, train_bce_loss: 1.4358, train_bce_dl_loss: 0.5440, step time: 0.4411\n",
      "batch: 9/17, train_dl_loss: 0.5399, train_bce_loss: 1.4383, train_bce_dl_loss: 0.5399, step time: 0.3743\n",
      "batch: 10/17, train_dl_loss: 0.6807, train_bce_loss: 1.4443, train_bce_dl_loss: 0.6807, step time: 0.4217\n",
      "batch: 11/17, train_dl_loss: 0.5745, train_bce_loss: 1.4204, train_bce_dl_loss: 0.5745, step time: 0.3807\n",
      "batch: 12/17, train_dl_loss: 0.5742, train_bce_loss: 1.4319, train_bce_dl_loss: 0.5742, step time: 0.4360\n",
      "batch: 13/17, train_dl_loss: 0.7054, train_bce_loss: 1.4596, train_bce_dl_loss: 0.7054, step time: 0.3806\n",
      "batch: 14/17, train_dl_loss: 0.5880, train_bce_loss: 1.4516, train_bce_dl_loss: 0.5880, step time: 0.4279\n",
      "batch: 15/17, train_dl_loss: 0.5235, train_bce_loss: 1.4411, train_bce_dl_loss: 0.5235, step time: 0.3711\n",
      "batch: 16/17, train_dl_loss: 0.5854, train_bce_loss: 1.4493, train_bce_dl_loss: 0.5854, step time: 0.4265\n",
      "batch: 17/17, train_dl_loss: 0.4995, train_bce_loss: 1.4391, train_bce_dl_loss: 0.4995, step time: 0.1120\n",
      "LOSS train DiceLoss: 0.5769, LOSS train BCE: 1.4394, LOSS train BCE-DiceLoss: 0.5769, LOSS val DiceLoss: 0.6253, LOSS val BCE: 1.4407, LOSS val BCE-DiceLoss: 0.6253, METRIC val: 0.3966\n",
      "time consuming of epoch 45 is: 448.4421\n",
      "----------\n",
      "EPOCH 46/80\n",
      "batch: 0/17, train_dl_loss: 0.5599, train_bce_loss: 1.4522, train_bce_dl_loss: 0.5599, step time: 0.4377\n",
      "batch: 1/17, train_dl_loss: 0.5632, train_bce_loss: 1.4523, train_bce_dl_loss: 0.5632, step time: 0.3790\n",
      "batch: 2/17, train_dl_loss: 0.5652, train_bce_loss: 1.4455, train_bce_dl_loss: 0.5652, step time: 0.4224\n",
      "batch: 3/17, train_dl_loss: 0.6199, train_bce_loss: 1.4468, train_bce_dl_loss: 0.6199, step time: 0.3796\n",
      "batch: 4/17, train_dl_loss: 0.5503, train_bce_loss: 1.4491, train_bce_dl_loss: 0.5503, step time: 0.4284\n",
      "batch: 5/17, train_dl_loss: 0.5333, train_bce_loss: 1.4451, train_bce_dl_loss: 0.5333, step time: 0.4259\n",
      "batch: 6/17, train_dl_loss: 0.6094, train_bce_loss: 1.4489, train_bce_dl_loss: 0.6094, step time: 0.4214\n",
      "batch: 7/17, train_dl_loss: 0.5306, train_bce_loss: 1.4327, train_bce_dl_loss: 0.5306, step time: 0.3801\n",
      "batch: 8/17, train_dl_loss: 0.5343, train_bce_loss: 1.4430, train_bce_dl_loss: 0.5343, step time: 0.4370\n",
      "batch: 9/17, train_dl_loss: 0.5489, train_bce_loss: 1.4384, train_bce_dl_loss: 0.5489, step time: 0.3807\n",
      "batch: 10/17, train_dl_loss: 0.6798, train_bce_loss: 1.4480, train_bce_dl_loss: 0.6798, step time: 0.4371\n",
      "batch: 11/17, train_dl_loss: 0.5701, train_bce_loss: 1.4325, train_bce_dl_loss: 0.5701, step time: 0.4437\n",
      "batch: 12/17, train_dl_loss: 0.5597, train_bce_loss: 1.4321, train_bce_dl_loss: 0.5597, step time: 0.4181\n",
      "batch: 13/17, train_dl_loss: 0.6922, train_bce_loss: 1.4477, train_bce_dl_loss: 0.6922, step time: 0.3781\n",
      "batch: 14/17, train_dl_loss: 0.5968, train_bce_loss: 1.4533, train_bce_dl_loss: 0.5968, step time: 0.4380\n",
      "batch: 15/17, train_dl_loss: 0.5432, train_bce_loss: 1.4565, train_bce_dl_loss: 0.5432, step time: 0.3821\n",
      "batch: 16/17, train_dl_loss: 0.5434, train_bce_loss: 1.4455, train_bce_dl_loss: 0.5434, step time: 0.4174\n",
      "batch: 17/17, train_dl_loss: 0.6448, train_bce_loss: 1.4637, train_bce_dl_loss: 0.6448, step time: 0.1114\n",
      "LOSS train DiceLoss: 0.5803, LOSS train BCE: 1.4463, LOSS train BCE-DiceLoss: 0.5803, LOSS val DiceLoss: 0.6290, LOSS val BCE: 1.4423, LOSS val BCE-DiceLoss: 0.6290, METRIC val: 0.3910\n",
      "time consuming of epoch 46 is: 454.2271\n",
      "----------\n",
      "EPOCH 47/80\n",
      "batch: 0/17, train_dl_loss: 0.6368, train_bce_loss: 1.4632, train_bce_dl_loss: 0.6368, step time: 0.4390\n",
      "batch: 1/17, train_dl_loss: 0.5394, train_bce_loss: 1.4395, train_bce_dl_loss: 0.5394, step time: 0.3804\n",
      "batch: 2/17, train_dl_loss: 0.5861, train_bce_loss: 1.4368, train_bce_dl_loss: 0.5861, step time: 0.4203\n",
      "batch: 3/17, train_dl_loss: 0.5975, train_bce_loss: 1.4494, train_bce_dl_loss: 0.5975, step time: 0.3758\n",
      "batch: 4/17, train_dl_loss: 0.5574, train_bce_loss: 1.4533, train_bce_dl_loss: 0.5574, step time: 0.4249\n",
      "batch: 5/17, train_dl_loss: 0.5298, train_bce_loss: 1.4409, train_bce_dl_loss: 0.5298, step time: 0.3782\n",
      "batch: 6/17, train_dl_loss: 0.5857, train_bce_loss: 1.4466, train_bce_dl_loss: 0.5857, step time: 0.4246\n",
      "batch: 7/17, train_dl_loss: 0.5293, train_bce_loss: 1.4450, train_bce_dl_loss: 0.5293, step time: 0.3826\n",
      "batch: 8/17, train_dl_loss: 0.5286, train_bce_loss: 1.4267, train_bce_dl_loss: 0.5286, step time: 0.4224\n",
      "batch: 9/17, train_dl_loss: 0.6089, train_bce_loss: 1.4560, train_bce_dl_loss: 0.6089, step time: 0.3756\n",
      "batch: 10/17, train_dl_loss: 0.6370, train_bce_loss: 1.4528, train_bce_dl_loss: 0.6370, step time: 0.4561\n",
      "batch: 11/17, train_dl_loss: 0.5267, train_bce_loss: 1.4360, train_bce_dl_loss: 0.5267, step time: 0.4266\n",
      "batch: 12/17, train_dl_loss: 0.5283, train_bce_loss: 1.4319, train_bce_dl_loss: 0.5283, step time: 0.4248\n",
      "batch: 13/17, train_dl_loss: 0.6663, train_bce_loss: 1.4466, train_bce_dl_loss: 0.6663, step time: 0.3756\n",
      "batch: 14/17, train_dl_loss: 0.5296, train_bce_loss: 1.4610, train_bce_dl_loss: 0.5296, step time: 0.4112\n",
      "batch: 15/17, train_dl_loss: 0.5705, train_bce_loss: 1.4510, train_bce_dl_loss: 0.5705, step time: 0.3688\n",
      "batch: 16/17, train_dl_loss: 0.5469, train_bce_loss: 1.4493, train_bce_dl_loss: 0.5469, step time: 0.4084\n",
      "batch: 17/17, train_dl_loss: 0.5324, train_bce_loss: 1.4429, train_bce_dl_loss: 0.5324, step time: 0.1135\n",
      "LOSS train DiceLoss: 0.5687, LOSS train BCE: 1.4460, LOSS train BCE-DiceLoss: 0.5687, LOSS val DiceLoss: 0.6284, LOSS val BCE: 1.4441, LOSS val BCE-DiceLoss: 0.6284, METRIC val: 0.3913\n",
      "time consuming of epoch 47 is: 443.4027\n",
      "----------\n",
      "EPOCH 48/80\n",
      "batch: 0/17, train_dl_loss: 0.5154, train_bce_loss: 1.4362, train_bce_dl_loss: 0.5154, step time: 0.4357\n",
      "batch: 1/17, train_dl_loss: 0.5437, train_bce_loss: 1.4439, train_bce_dl_loss: 0.5437, step time: 0.3849\n",
      "batch: 2/17, train_dl_loss: 0.5882, train_bce_loss: 1.4500, train_bce_dl_loss: 0.5882, step time: 0.4284\n",
      "batch: 3/17, train_dl_loss: 0.5972, train_bce_loss: 1.4459, train_bce_dl_loss: 0.5972, step time: 0.3837\n",
      "batch: 4/17, train_dl_loss: 0.5701, train_bce_loss: 1.4657, train_bce_dl_loss: 0.5701, step time: 0.4334\n",
      "batch: 5/17, train_dl_loss: 0.5676, train_bce_loss: 1.4364, train_bce_dl_loss: 0.5676, step time: 0.3838\n",
      "batch: 6/17, train_dl_loss: 0.6199, train_bce_loss: 1.4521, train_bce_dl_loss: 0.6199, step time: 0.4334\n",
      "batch: 7/17, train_dl_loss: 0.5137, train_bce_loss: 1.4319, train_bce_dl_loss: 0.5137, step time: 0.3667\n",
      "batch: 8/17, train_dl_loss: 0.5881, train_bce_loss: 1.4472, train_bce_dl_loss: 0.5881, step time: 0.4344\n",
      "batch: 9/17, train_dl_loss: 0.5344, train_bce_loss: 1.4508, train_bce_dl_loss: 0.5344, step time: 0.3691\n",
      "batch: 10/17, train_dl_loss: 0.6055, train_bce_loss: 1.4374, train_bce_dl_loss: 0.6055, step time: 0.4406\n",
      "batch: 11/17, train_dl_loss: 0.5068, train_bce_loss: 1.4285, train_bce_dl_loss: 0.5068, step time: 0.4212\n",
      "batch: 12/17, train_dl_loss: 0.5381, train_bce_loss: 1.4455, train_bce_dl_loss: 0.5381, step time: 0.4223\n",
      "batch: 13/17, train_dl_loss: 0.6790, train_bce_loss: 1.4622, train_bce_dl_loss: 0.6790, step time: 0.3766\n",
      "batch: 14/17, train_dl_loss: 0.5817, train_bce_loss: 1.4625, train_bce_dl_loss: 0.5817, step time: 0.4370\n",
      "batch: 15/17, train_dl_loss: 0.5609, train_bce_loss: 1.4583, train_bce_dl_loss: 0.5609, step time: 0.3723\n",
      "batch: 16/17, train_dl_loss: 0.5599, train_bce_loss: 1.4523, train_bce_dl_loss: 0.5599, step time: 0.4243\n",
      "batch: 17/17, train_dl_loss: 0.5087, train_bce_loss: 1.4607, train_bce_dl_loss: 0.5087, step time: 0.1101\n",
      "LOSS train DiceLoss: 0.5655, LOSS train BCE: 1.4482, LOSS train BCE-DiceLoss: 0.5655, LOSS val DiceLoss: 0.6327, LOSS val BCE: 1.4488, LOSS val BCE-DiceLoss: 0.6327, METRIC val: 0.3851\n",
      "time consuming of epoch 48 is: 454.8199\n",
      "----------\n",
      "EPOCH 49/80\n",
      "batch: 0/17, train_dl_loss: 0.5304, train_bce_loss: 1.4522, train_bce_dl_loss: 0.5304, step time: 0.4285\n",
      "batch: 1/17, train_dl_loss: 0.5998, train_bce_loss: 1.4549, train_bce_dl_loss: 0.5998, step time: 0.3785\n",
      "batch: 2/17, train_dl_loss: 0.5921, train_bce_loss: 1.4540, train_bce_dl_loss: 0.5921, step time: 0.4398\n",
      "batch: 3/17, train_dl_loss: 0.6541, train_bce_loss: 1.4507, train_bce_dl_loss: 0.6541, step time: 0.3767\n",
      "batch: 4/17, train_dl_loss: 0.5188, train_bce_loss: 1.4547, train_bce_dl_loss: 0.5188, step time: 0.4339\n",
      "batch: 5/17, train_dl_loss: 0.5295, train_bce_loss: 1.4589, train_bce_dl_loss: 0.5295, step time: 0.3840\n",
      "batch: 6/17, train_dl_loss: 0.5900, train_bce_loss: 1.4636, train_bce_dl_loss: 0.5900, step time: 0.4622\n",
      "batch: 7/17, train_dl_loss: 0.5296, train_bce_loss: 1.4338, train_bce_dl_loss: 0.5296, step time: 0.3762\n",
      "batch: 8/17, train_dl_loss: 0.5643, train_bce_loss: 1.4504, train_bce_dl_loss: 0.5643, step time: 0.4584\n",
      "batch: 9/17, train_dl_loss: 0.5563, train_bce_loss: 1.4444, train_bce_dl_loss: 0.5563, step time: 0.3728\n",
      "batch: 10/17, train_dl_loss: 0.7011, train_bce_loss: 1.4620, train_bce_dl_loss: 0.7011, step time: 0.4266\n",
      "batch: 11/17, train_dl_loss: 0.5545, train_bce_loss: 1.4552, train_bce_dl_loss: 0.5545, step time: 0.3812\n",
      "batch: 12/17, train_dl_loss: 0.5451, train_bce_loss: 1.4489, train_bce_dl_loss: 0.5451, step time: 0.4368\n",
      "batch: 13/17, train_dl_loss: 0.6679, train_bce_loss: 1.4642, train_bce_dl_loss: 0.6679, step time: 0.3811\n",
      "batch: 14/17, train_dl_loss: 0.5693, train_bce_loss: 1.4538, train_bce_dl_loss: 0.5693, step time: 0.4365\n",
      "batch: 15/17, train_dl_loss: 0.5916, train_bce_loss: 1.4577, train_bce_dl_loss: 0.5916, step time: 0.3958\n",
      "batch: 16/17, train_dl_loss: 0.5554, train_bce_loss: 1.4585, train_bce_dl_loss: 0.5554, step time: 0.4195\n",
      "batch: 17/17, train_dl_loss: 0.4964, train_bce_loss: 1.4476, train_bce_dl_loss: 0.4964, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5748, LOSS train BCE: 1.4536, LOSS train BCE-DiceLoss: 0.5748, LOSS val DiceLoss: 0.6211, LOSS val BCE: 1.4499, LOSS val BCE-DiceLoss: 0.6211, METRIC val: 0.4011\n",
      "time consuming of epoch 49 is: 459.5328\n",
      "----------\n",
      "EPOCH 50/80\n",
      "batch: 0/17, train_dl_loss: 0.5255, train_bce_loss: 1.4529, train_bce_dl_loss: 0.5255, step time: 0.4591\n",
      "batch: 1/17, train_dl_loss: 0.6206, train_bce_loss: 1.4738, train_bce_dl_loss: 0.6206, step time: 0.3759\n",
      "batch: 2/17, train_dl_loss: 0.5761, train_bce_loss: 1.4658, train_bce_dl_loss: 0.5761, step time: 0.4188\n",
      "batch: 3/17, train_dl_loss: 0.5808, train_bce_loss: 1.4579, train_bce_dl_loss: 0.5808, step time: 0.3765\n",
      "batch: 4/17, train_dl_loss: 0.5343, train_bce_loss: 1.4442, train_bce_dl_loss: 0.5343, step time: 0.4372\n",
      "batch: 5/17, train_dl_loss: 0.5488, train_bce_loss: 1.4534, train_bce_dl_loss: 0.5488, step time: 0.3832\n",
      "batch: 6/17, train_dl_loss: 0.5992, train_bce_loss: 1.4670, train_bce_dl_loss: 0.5992, step time: 0.4312\n",
      "batch: 7/17, train_dl_loss: 0.5743, train_bce_loss: 1.4604, train_bce_dl_loss: 0.5743, step time: 0.3743\n",
      "batch: 8/17, train_dl_loss: 0.5391, train_bce_loss: 1.4305, train_bce_dl_loss: 0.5391, step time: 0.4416\n",
      "batch: 9/17, train_dl_loss: 0.5308, train_bce_loss: 1.4530, train_bce_dl_loss: 0.5308, step time: 0.3821\n",
      "batch: 10/17, train_dl_loss: 0.6028, train_bce_loss: 1.4434, train_bce_dl_loss: 0.6028, step time: 0.4270\n",
      "batch: 11/17, train_dl_loss: 0.5354, train_bce_loss: 1.4299, train_bce_dl_loss: 0.5354, step time: 0.4308\n",
      "batch: 12/17, train_dl_loss: 0.5913, train_bce_loss: 1.4486, train_bce_dl_loss: 0.5913, step time: 0.4355\n",
      "batch: 13/17, train_dl_loss: 0.6968, train_bce_loss: 1.4512, train_bce_dl_loss: 0.6968, step time: 0.3756\n",
      "batch: 14/17, train_dl_loss: 0.5891, train_bce_loss: 1.4654, train_bce_dl_loss: 0.5891, step time: 0.4196\n",
      "batch: 15/17, train_dl_loss: 0.5598, train_bce_loss: 1.4442, train_bce_dl_loss: 0.5598, step time: 0.3725\n",
      "batch: 16/17, train_dl_loss: 0.5692, train_bce_loss: 1.4535, train_bce_dl_loss: 0.5692, step time: 0.4306\n",
      "batch: 17/17, train_dl_loss: 0.4962, train_bce_loss: 1.4588, train_bce_dl_loss: 0.4962, step time: 0.1115\n",
      "LOSS train DiceLoss: 0.5706, LOSS train BCE: 1.4530, LOSS train BCE-DiceLoss: 0.5706, LOSS val DiceLoss: 0.6231, LOSS val BCE: 1.4491, LOSS val BCE-DiceLoss: 0.6231, METRIC val: 0.3987\n",
      "time consuming of epoch 50 is: 541.9578\n",
      "----------\n",
      "EPOCH 51/80\n",
      "batch: 0/17, train_dl_loss: 0.5287, train_bce_loss: 1.4518, train_bce_dl_loss: 0.5287, step time: 0.4252\n",
      "batch: 1/17, train_dl_loss: 0.5364, train_bce_loss: 1.4566, train_bce_dl_loss: 0.5364, step time: 0.3797\n",
      "batch: 2/17, train_dl_loss: 0.5639, train_bce_loss: 1.4494, train_bce_dl_loss: 0.5639, step time: 0.4308\n",
      "batch: 3/17, train_dl_loss: 0.5891, train_bce_loss: 1.4635, train_bce_dl_loss: 0.5891, step time: 0.3730\n",
      "batch: 4/17, train_dl_loss: 0.5505, train_bce_loss: 1.4605, train_bce_dl_loss: 0.5505, step time: 0.4295\n",
      "batch: 5/17, train_dl_loss: 0.5351, train_bce_loss: 1.4588, train_bce_dl_loss: 0.5351, step time: 0.3813\n",
      "batch: 6/17, train_dl_loss: 0.5969, train_bce_loss: 1.4640, train_bce_dl_loss: 0.5969, step time: 0.4148\n",
      "batch: 7/17, train_dl_loss: 0.5356, train_bce_loss: 1.4427, train_bce_dl_loss: 0.5356, step time: 0.3740\n",
      "batch: 8/17, train_dl_loss: 0.5161, train_bce_loss: 1.4415, train_bce_dl_loss: 0.5161, step time: 0.4186\n",
      "batch: 9/17, train_dl_loss: 0.5442, train_bce_loss: 1.4551, train_bce_dl_loss: 0.5442, step time: 0.3716\n",
      "batch: 10/17, train_dl_loss: 0.6539, train_bce_loss: 1.4453, train_bce_dl_loss: 0.6539, step time: 0.4272\n",
      "batch: 11/17, train_dl_loss: 0.5518, train_bce_loss: 1.4568, train_bce_dl_loss: 0.5518, step time: 0.4356\n",
      "batch: 12/17, train_dl_loss: 0.5385, train_bce_loss: 1.4455, train_bce_dl_loss: 0.5385, step time: 0.4253\n",
      "batch: 13/17, train_dl_loss: 0.7226, train_bce_loss: 1.4684, train_bce_dl_loss: 0.7226, step time: 0.3841\n",
      "batch: 14/17, train_dl_loss: 0.6207, train_bce_loss: 1.4761, train_bce_dl_loss: 0.6207, step time: 0.4377\n",
      "batch: 15/17, train_dl_loss: 0.5456, train_bce_loss: 1.4488, train_bce_dl_loss: 0.5456, step time: 0.3746\n",
      "batch: 16/17, train_dl_loss: 0.5780, train_bce_loss: 1.4603, train_bce_dl_loss: 0.5780, step time: 0.4248\n",
      "batch: 17/17, train_dl_loss: 0.5075, train_bce_loss: 1.4569, train_bce_dl_loss: 0.5075, step time: 0.1092\n",
      "LOSS train DiceLoss: 0.5675, LOSS train BCE: 1.4557, LOSS train BCE-DiceLoss: 0.5675, LOSS val DiceLoss: 0.6193, LOSS val BCE: 1.4504, LOSS val BCE-DiceLoss: 0.6193, METRIC val: 0.4036\n",
      "time consuming of epoch 51 is: 494.8039\n",
      "----------\n",
      "EPOCH 52/80\n",
      "batch: 0/17, train_dl_loss: 0.5860, train_bce_loss: 1.4625, train_bce_dl_loss: 0.5860, step time: 0.4863\n",
      "batch: 1/17, train_dl_loss: 0.5458, train_bce_loss: 1.4509, train_bce_dl_loss: 0.5458, step time: 0.3764\n",
      "batch: 2/17, train_dl_loss: 0.6148, train_bce_loss: 1.4554, train_bce_dl_loss: 0.6148, step time: 0.4397\n",
      "batch: 3/17, train_dl_loss: 0.5849, train_bce_loss: 1.4470, train_bce_dl_loss: 0.5849, step time: 0.3817\n",
      "batch: 4/17, train_dl_loss: 0.5155, train_bce_loss: 1.4638, train_bce_dl_loss: 0.5155, step time: 0.4208\n",
      "batch: 5/17, train_dl_loss: 0.5692, train_bce_loss: 1.4591, train_bce_dl_loss: 0.5692, step time: 0.3741\n",
      "batch: 6/17, train_dl_loss: 0.5662, train_bce_loss: 1.4611, train_bce_dl_loss: 0.5662, step time: 0.4189\n",
      "batch: 7/17, train_dl_loss: 0.5201, train_bce_loss: 1.4427, train_bce_dl_loss: 0.5201, step time: 0.3817\n",
      "batch: 8/17, train_dl_loss: 0.5449, train_bce_loss: 1.4362, train_bce_dl_loss: 0.5449, step time: 0.4289\n",
      "batch: 9/17, train_dl_loss: 0.5753, train_bce_loss: 1.4838, train_bce_dl_loss: 0.5753, step time: 0.4395\n",
      "batch: 10/17, train_dl_loss: 0.6302, train_bce_loss: 1.4655, train_bce_dl_loss: 0.6302, step time: 0.4298\n",
      "batch: 11/17, train_dl_loss: 0.5299, train_bce_loss: 1.4636, train_bce_dl_loss: 0.5299, step time: 0.4201\n",
      "batch: 12/17, train_dl_loss: 0.5257, train_bce_loss: 1.4486, train_bce_dl_loss: 0.5257, step time: 0.4289\n",
      "batch: 13/17, train_dl_loss: 0.6849, train_bce_loss: 1.4674, train_bce_dl_loss: 0.6849, step time: 0.4275\n",
      "batch: 14/17, train_dl_loss: 0.5479, train_bce_loss: 1.4722, train_bce_dl_loss: 0.5479, step time: 0.4140\n",
      "batch: 15/17, train_dl_loss: 0.5529, train_bce_loss: 1.4559, train_bce_dl_loss: 0.5529, step time: 0.3760\n",
      "batch: 16/17, train_dl_loss: 0.5542, train_bce_loss: 1.4535, train_bce_dl_loss: 0.5542, step time: 0.4280\n",
      "batch: 17/17, train_dl_loss: 0.6297, train_bce_loss: 1.4694, train_bce_dl_loss: 0.6297, step time: 0.1103\n",
      "LOSS train DiceLoss: 0.5710, LOSS train BCE: 1.4588, LOSS train BCE-DiceLoss: 0.5710, LOSS val DiceLoss: 0.6246, LOSS val BCE: 1.4514, LOSS val BCE-DiceLoss: 0.6246, METRIC val: 0.3960\n",
      "time consuming of epoch 52 is: 440.4810\n",
      "----------\n",
      "EPOCH 53/80\n",
      "batch: 0/17, train_dl_loss: 0.5614, train_bce_loss: 1.4583, train_bce_dl_loss: 0.5614, step time: 0.4341\n",
      "batch: 1/17, train_dl_loss: 0.5417, train_bce_loss: 1.4777, train_bce_dl_loss: 0.5417, step time: 0.3750\n",
      "batch: 2/17, train_dl_loss: 0.6220, train_bce_loss: 1.4674, train_bce_dl_loss: 0.6220, step time: 0.4689\n",
      "batch: 3/17, train_dl_loss: 0.6195, train_bce_loss: 1.4701, train_bce_dl_loss: 0.6195, step time: 0.3708\n",
      "batch: 4/17, train_dl_loss: 0.5547, train_bce_loss: 1.4770, train_bce_dl_loss: 0.5547, step time: 0.4394\n",
      "batch: 5/17, train_dl_loss: 0.5200, train_bce_loss: 1.4588, train_bce_dl_loss: 0.5200, step time: 0.3820\n",
      "batch: 6/17, train_dl_loss: 0.5892, train_bce_loss: 1.4655, train_bce_dl_loss: 0.5892, step time: 0.4451\n",
      "batch: 7/17, train_dl_loss: 0.5374, train_bce_loss: 1.4585, train_bce_dl_loss: 0.5374, step time: 0.4227\n",
      "batch: 8/17, train_dl_loss: 0.5617, train_bce_loss: 1.4477, train_bce_dl_loss: 0.5617, step time: 0.4190\n",
      "batch: 9/17, train_dl_loss: 0.5524, train_bce_loss: 1.4550, train_bce_dl_loss: 0.5524, step time: 0.4401\n",
      "batch: 10/17, train_dl_loss: 0.6222, train_bce_loss: 1.4704, train_bce_dl_loss: 0.6222, step time: 0.4223\n",
      "batch: 11/17, train_dl_loss: 0.5503, train_bce_loss: 1.4411, train_bce_dl_loss: 0.5503, step time: 0.4336\n",
      "batch: 12/17, train_dl_loss: 0.5965, train_bce_loss: 1.4661, train_bce_dl_loss: 0.5965, step time: 0.4396\n",
      "batch: 13/17, train_dl_loss: 0.6654, train_bce_loss: 1.4644, train_bce_dl_loss: 0.6654, step time: 0.3800\n",
      "batch: 14/17, train_dl_loss: 0.5351, train_bce_loss: 1.4663, train_bce_dl_loss: 0.5351, step time: 0.4224\n",
      "batch: 15/17, train_dl_loss: 0.5844, train_bce_loss: 1.4561, train_bce_dl_loss: 0.5844, step time: 0.3705\n",
      "batch: 16/17, train_dl_loss: 0.5438, train_bce_loss: 1.4594, train_bce_dl_loss: 0.5438, step time: 0.4260\n",
      "batch: 17/17, train_dl_loss: 0.6100, train_bce_loss: 1.4699, train_bce_dl_loss: 0.6100, step time: 0.1105\n",
      "LOSS train DiceLoss: 0.5760, LOSS train BCE: 1.4628, LOSS train BCE-DiceLoss: 0.5760, LOSS val DiceLoss: 0.6208, LOSS val BCE: 1.4487, LOSS val BCE-DiceLoss: 0.6208, METRIC val: 0.4008\n",
      "time consuming of epoch 53 is: 435.4376\n",
      "----------\n",
      "EPOCH 54/80\n",
      "batch: 0/17, train_dl_loss: 0.5168, train_bce_loss: 1.4483, train_bce_dl_loss: 0.5168, step time: 0.4313\n",
      "batch: 1/17, train_dl_loss: 0.5880, train_bce_loss: 1.4769, train_bce_dl_loss: 0.5880, step time: 0.3724\n",
      "batch: 2/17, train_dl_loss: 0.5774, train_bce_loss: 1.4494, train_bce_dl_loss: 0.5774, step time: 0.4438\n",
      "batch: 3/17, train_dl_loss: 0.6105, train_bce_loss: 1.4606, train_bce_dl_loss: 0.6105, step time: 0.3790\n",
      "batch: 4/17, train_dl_loss: 0.5190, train_bce_loss: 1.4442, train_bce_dl_loss: 0.5190, step time: 0.4278\n",
      "batch: 5/17, train_dl_loss: 0.5436, train_bce_loss: 1.4464, train_bce_dl_loss: 0.5436, step time: 0.3794\n",
      "batch: 6/17, train_dl_loss: 0.5600, train_bce_loss: 1.4708, train_bce_dl_loss: 0.5600, step time: 0.4180\n",
      "batch: 7/17, train_dl_loss: 0.5563, train_bce_loss: 1.4524, train_bce_dl_loss: 0.5563, step time: 0.3739\n",
      "batch: 8/17, train_dl_loss: 0.5468, train_bce_loss: 1.4586, train_bce_dl_loss: 0.5468, step time: 0.4248\n",
      "batch: 9/17, train_dl_loss: 0.5559, train_bce_loss: 1.4596, train_bce_dl_loss: 0.5559, step time: 0.3818\n",
      "batch: 10/17, train_dl_loss: 0.6282, train_bce_loss: 1.4635, train_bce_dl_loss: 0.6282, step time: 0.4421\n",
      "batch: 11/17, train_dl_loss: 0.5373, train_bce_loss: 1.4336, train_bce_dl_loss: 0.5373, step time: 0.4425\n",
      "batch: 12/17, train_dl_loss: 0.5368, train_bce_loss: 1.4460, train_bce_dl_loss: 0.5368, step time: 0.4348\n",
      "batch: 13/17, train_dl_loss: 0.6734, train_bce_loss: 1.4611, train_bce_dl_loss: 0.6734, step time: 0.3763\n",
      "batch: 14/17, train_dl_loss: 0.5729, train_bce_loss: 1.4730, train_bce_dl_loss: 0.5729, step time: 0.4199\n",
      "batch: 15/17, train_dl_loss: 0.5309, train_bce_loss: 1.4514, train_bce_dl_loss: 0.5309, step time: 0.3842\n",
      "batch: 16/17, train_dl_loss: 0.5327, train_bce_loss: 1.4593, train_bce_dl_loss: 0.5327, step time: 0.4236\n",
      "batch: 17/17, train_dl_loss: 0.5336, train_bce_loss: 1.4510, train_bce_dl_loss: 0.5336, step time: 0.1104\n",
      "LOSS train DiceLoss: 0.5622, LOSS train BCE: 1.4559, LOSS train BCE-DiceLoss: 0.5622, LOSS val DiceLoss: 0.6195, LOSS val BCE: 1.4502, LOSS val BCE-DiceLoss: 0.6195, METRIC val: 0.4034\n",
      "time consuming of epoch 54 is: 449.5522\n",
      "----------\n",
      "EPOCH 55/80\n",
      "batch: 0/17, train_dl_loss: 0.5525, train_bce_loss: 1.4583, train_bce_dl_loss: 0.5525, step time: 0.4377\n",
      "batch: 1/17, train_dl_loss: 0.5721, train_bce_loss: 1.4539, train_bce_dl_loss: 0.5721, step time: 0.3768\n",
      "batch: 2/17, train_dl_loss: 0.6031, train_bce_loss: 1.4596, train_bce_dl_loss: 0.6031, step time: 0.4364\n",
      "batch: 3/17, train_dl_loss: 0.6290, train_bce_loss: 1.4686, train_bce_dl_loss: 0.6290, step time: 0.3799\n",
      "batch: 4/17, train_dl_loss: 0.4892, train_bce_loss: 1.4527, train_bce_dl_loss: 0.4892, step time: 0.4290\n",
      "batch: 5/17, train_dl_loss: 0.5299, train_bce_loss: 1.4461, train_bce_dl_loss: 0.5299, step time: 0.3762\n",
      "batch: 6/17, train_dl_loss: 0.5781, train_bce_loss: 1.4691, train_bce_dl_loss: 0.5781, step time: 0.4328\n",
      "batch: 7/17, train_dl_loss: 0.5818, train_bce_loss: 1.4694, train_bce_dl_loss: 0.5818, step time: 0.3846\n",
      "batch: 8/17, train_dl_loss: 0.5229, train_bce_loss: 1.4633, train_bce_dl_loss: 0.5229, step time: 0.4477\n",
      "batch: 9/17, train_dl_loss: 0.5160, train_bce_loss: 1.4749, train_bce_dl_loss: 0.5160, step time: 0.3774\n",
      "batch: 10/17, train_dl_loss: 0.6639, train_bce_loss: 1.4672, train_bce_dl_loss: 0.6639, step time: 0.4248\n",
      "batch: 11/17, train_dl_loss: 0.5752, train_bce_loss: 1.4549, train_bce_dl_loss: 0.5752, step time: 0.3836\n",
      "batch: 12/17, train_dl_loss: 0.5923, train_bce_loss: 1.4642, train_bce_dl_loss: 0.5923, step time: 0.4400\n",
      "batch: 13/17, train_dl_loss: 0.6963, train_bce_loss: 1.4595, train_bce_dl_loss: 0.6963, step time: 0.3725\n",
      "batch: 14/17, train_dl_loss: 0.5504, train_bce_loss: 1.4626, train_bce_dl_loss: 0.5504, step time: 0.4265\n",
      "batch: 15/17, train_dl_loss: 0.5583, train_bce_loss: 1.4608, train_bce_dl_loss: 0.5583, step time: 0.3757\n",
      "batch: 16/17, train_dl_loss: 0.5683, train_bce_loss: 1.4594, train_bce_dl_loss: 0.5683, step time: 0.4256\n",
      "batch: 17/17, train_dl_loss: 0.4986, train_bce_loss: 1.4555, train_bce_dl_loss: 0.4986, step time: 0.1106\n",
      "LOSS train DiceLoss: 0.5710, LOSS train BCE: 1.4611, LOSS train BCE-DiceLoss: 0.5710, LOSS val DiceLoss: 0.6211, LOSS val BCE: 1.4512, LOSS val BCE-DiceLoss: 0.6211, METRIC val: 0.4013\n",
      "time consuming of epoch 55 is: 441.0809\n",
      "----------\n",
      "EPOCH 56/80\n",
      "batch: 0/17, train_dl_loss: 0.5481, train_bce_loss: 1.4570, train_bce_dl_loss: 0.5481, step time: 0.4421\n",
      "batch: 1/17, train_dl_loss: 0.5746, train_bce_loss: 1.4763, train_bce_dl_loss: 0.5746, step time: 0.3788\n",
      "batch: 2/17, train_dl_loss: 0.5553, train_bce_loss: 1.4635, train_bce_dl_loss: 0.5553, step time: 0.4421\n",
      "batch: 3/17, train_dl_loss: 0.5999, train_bce_loss: 1.4554, train_bce_dl_loss: 0.5999, step time: 0.3804\n",
      "batch: 4/17, train_dl_loss: 0.4950, train_bce_loss: 1.4564, train_bce_dl_loss: 0.4950, step time: 0.4259\n",
      "batch: 5/17, train_dl_loss: 0.5234, train_bce_loss: 1.4623, train_bce_dl_loss: 0.5234, step time: 0.3836\n",
      "batch: 6/17, train_dl_loss: 0.5900, train_bce_loss: 1.4760, train_bce_dl_loss: 0.5900, step time: 0.4303\n",
      "batch: 7/17, train_dl_loss: 0.5175, train_bce_loss: 1.4634, train_bce_dl_loss: 0.5175, step time: 0.3858\n",
      "batch: 8/17, train_dl_loss: 0.5513, train_bce_loss: 1.4391, train_bce_dl_loss: 0.5513, step time: 0.4202\n",
      "batch: 9/17, train_dl_loss: 0.5278, train_bce_loss: 1.4648, train_bce_dl_loss: 0.5278, step time: 0.3782\n",
      "batch: 10/17, train_dl_loss: 0.6105, train_bce_loss: 1.4657, train_bce_dl_loss: 0.6105, step time: 0.4437\n",
      "batch: 11/17, train_dl_loss: 0.5502, train_bce_loss: 1.4441, train_bce_dl_loss: 0.5502, step time: 0.3925\n",
      "batch: 12/17, train_dl_loss: 0.5496, train_bce_loss: 1.4464, train_bce_dl_loss: 0.5496, step time: 0.4210\n",
      "batch: 13/17, train_dl_loss: 0.6539, train_bce_loss: 1.4652, train_bce_dl_loss: 0.6539, step time: 0.3768\n",
      "batch: 14/17, train_dl_loss: 0.6026, train_bce_loss: 1.4759, train_bce_dl_loss: 0.6026, step time: 0.4381\n",
      "batch: 15/17, train_dl_loss: 0.5031, train_bce_loss: 1.4618, train_bce_dl_loss: 0.5031, step time: 0.3797\n",
      "batch: 16/17, train_dl_loss: 0.5419, train_bce_loss: 1.4695, train_bce_dl_loss: 0.5419, step time: 0.4279\n",
      "batch: 17/17, train_dl_loss: 0.4657, train_bce_loss: 1.4707, train_bce_dl_loss: 0.4657, step time: 0.1122\n",
      "LOSS train DiceLoss: 0.5534, LOSS train BCE: 1.4619, LOSS train BCE-DiceLoss: 0.5534, LOSS val DiceLoss: 0.6169, LOSS val BCE: 1.4547, LOSS val BCE-DiceLoss: 0.6169, METRIC val: 0.4068\n",
      "time consuming of epoch 56 is: 426.9798\n",
      "----------\n",
      "EPOCH 57/80\n",
      "batch: 0/17, train_dl_loss: 0.5308, train_bce_loss: 1.4433, train_bce_dl_loss: 0.5308, step time: 0.4410\n",
      "batch: 1/17, train_dl_loss: 0.5180, train_bce_loss: 1.4644, train_bce_dl_loss: 0.5180, step time: 0.3747\n",
      "batch: 2/17, train_dl_loss: 0.5499, train_bce_loss: 1.4599, train_bce_dl_loss: 0.5499, step time: 0.4281\n",
      "batch: 3/17, train_dl_loss: 0.5890, train_bce_loss: 1.4546, train_bce_dl_loss: 0.5890, step time: 0.3758\n",
      "batch: 4/17, train_dl_loss: 0.5288, train_bce_loss: 1.4521, train_bce_dl_loss: 0.5288, step time: 0.4249\n",
      "batch: 5/17, train_dl_loss: 0.5464, train_bce_loss: 1.4547, train_bce_dl_loss: 0.5464, step time: 0.4333\n",
      "batch: 6/17, train_dl_loss: 0.5648, train_bce_loss: 1.4795, train_bce_dl_loss: 0.5648, step time: 0.4240\n",
      "batch: 7/17, train_dl_loss: 0.5309, train_bce_loss: 1.4678, train_bce_dl_loss: 0.5309, step time: 0.4315\n",
      "batch: 8/17, train_dl_loss: 0.5230, train_bce_loss: 1.4592, train_bce_dl_loss: 0.5230, step time: 0.4129\n",
      "batch: 9/17, train_dl_loss: 0.5397, train_bce_loss: 1.4607, train_bce_dl_loss: 0.5397, step time: 0.4289\n",
      "batch: 10/17, train_dl_loss: 0.6105, train_bce_loss: 1.4642, train_bce_dl_loss: 0.6105, step time: 0.4429\n",
      "batch: 11/17, train_dl_loss: 0.5100, train_bce_loss: 1.4363, train_bce_dl_loss: 0.5100, step time: 0.4191\n",
      "batch: 12/17, train_dl_loss: 0.5446, train_bce_loss: 1.4616, train_bce_dl_loss: 0.5446, step time: 0.4196\n",
      "batch: 13/17, train_dl_loss: 0.6222, train_bce_loss: 1.4678, train_bce_dl_loss: 0.6222, step time: 0.4162\n",
      "batch: 14/17, train_dl_loss: 0.5384, train_bce_loss: 1.4720, train_bce_dl_loss: 0.5384, step time: 0.4183\n",
      "batch: 15/17, train_dl_loss: 0.5207, train_bce_loss: 1.4672, train_bce_dl_loss: 0.5207, step time: 0.4279\n",
      "batch: 16/17, train_dl_loss: 0.5462, train_bce_loss: 1.4635, train_bce_dl_loss: 0.5462, step time: 0.4175\n",
      "batch: 17/17, train_dl_loss: 0.4855, train_bce_loss: 1.4678, train_bce_dl_loss: 0.4855, step time: 0.1103\n",
      "LOSS train DiceLoss: 0.5444, LOSS train BCE: 1.4609, LOSS train BCE-DiceLoss: 0.5444, LOSS val DiceLoss: 0.6167, LOSS val BCE: 1.4560, LOSS val BCE-DiceLoss: 0.6167, METRIC val: 0.4070\n",
      "time consuming of epoch 57 is: 481.5517\n",
      "----------\n",
      "EPOCH 58/80\n",
      "batch: 0/17, train_dl_loss: 0.5516, train_bce_loss: 1.4672, train_bce_dl_loss: 0.5516, step time: 0.4241\n",
      "batch: 1/17, train_dl_loss: 0.5673, train_bce_loss: 1.4673, train_bce_dl_loss: 0.5673, step time: 0.3785\n",
      "batch: 2/17, train_dl_loss: 0.5752, train_bce_loss: 1.4425, train_bce_dl_loss: 0.5752, step time: 0.4182\n",
      "batch: 3/17, train_dl_loss: 0.6350, train_bce_loss: 1.4651, train_bce_dl_loss: 0.6350, step time: 0.4010\n",
      "batch: 4/17, train_dl_loss: 0.5050, train_bce_loss: 1.4655, train_bce_dl_loss: 0.5050, step time: 0.4204\n",
      "batch: 5/17, train_dl_loss: 0.5128, train_bce_loss: 1.4581, train_bce_dl_loss: 0.5128, step time: 0.3782\n",
      "batch: 6/17, train_dl_loss: 0.5887, train_bce_loss: 1.4764, train_bce_dl_loss: 0.5887, step time: 0.4269\n",
      "batch: 7/17, train_dl_loss: 0.5205, train_bce_loss: 1.4516, train_bce_dl_loss: 0.5205, step time: 0.3776\n",
      "batch: 8/17, train_dl_loss: 0.5398, train_bce_loss: 1.4570, train_bce_dl_loss: 0.5398, step time: 0.4371\n",
      "batch: 9/17, train_dl_loss: 0.5274, train_bce_loss: 1.4650, train_bce_dl_loss: 0.5274, step time: 0.3796\n",
      "batch: 10/17, train_dl_loss: 0.6201, train_bce_loss: 1.4600, train_bce_dl_loss: 0.6201, step time: 0.4537\n",
      "batch: 11/17, train_dl_loss: 0.5969, train_bce_loss: 1.4538, train_bce_dl_loss: 0.5969, step time: 0.3851\n",
      "batch: 12/17, train_dl_loss: 0.5192, train_bce_loss: 1.4566, train_bce_dl_loss: 0.5192, step time: 0.4238\n",
      "batch: 13/17, train_dl_loss: 0.6146, train_bce_loss: 1.4838, train_bce_dl_loss: 0.6146, step time: 0.3878\n",
      "batch: 14/17, train_dl_loss: 0.5679, train_bce_loss: 1.4809, train_bce_dl_loss: 0.5679, step time: 0.4540\n",
      "batch: 15/17, train_dl_loss: 0.5140, train_bce_loss: 1.4592, train_bce_dl_loss: 0.5140, step time: 0.3823\n",
      "batch: 16/17, train_dl_loss: 0.5410, train_bce_loss: 1.4735, train_bce_dl_loss: 0.5410, step time: 0.4150\n",
      "batch: 17/17, train_dl_loss: 0.4839, train_bce_loss: 1.4607, train_bce_dl_loss: 0.4839, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.5545, LOSS train BCE: 1.4636, LOSS train BCE-DiceLoss: 0.5545, LOSS val DiceLoss: 0.6135, LOSS val BCE: 1.4583, LOSS val BCE-DiceLoss: 0.6135, METRIC val: 0.4104\n",
      "time consuming of epoch 58 is: 407.1600\n",
      "----------\n",
      "EPOCH 59/80\n",
      "batch: 0/17, train_dl_loss: 0.5404, train_bce_loss: 1.4603, train_bce_dl_loss: 0.5404, step time: 0.4225\n",
      "batch: 1/17, train_dl_loss: 0.5457, train_bce_loss: 1.4570, train_bce_dl_loss: 0.5457, step time: 0.3736\n",
      "batch: 2/17, train_dl_loss: 0.5422, train_bce_loss: 1.4567, train_bce_dl_loss: 0.5422, step time: 0.4412\n",
      "batch: 3/17, train_dl_loss: 0.6234, train_bce_loss: 1.4622, train_bce_dl_loss: 0.6234, step time: 0.3982\n",
      "batch: 4/17, train_dl_loss: 0.5025, train_bce_loss: 1.4587, train_bce_dl_loss: 0.5025, step time: 0.4439\n",
      "batch: 5/17, train_dl_loss: 0.5353, train_bce_loss: 1.4716, train_bce_dl_loss: 0.5353, step time: 0.3840\n",
      "batch: 6/17, train_dl_loss: 0.6050, train_bce_loss: 1.4668, train_bce_dl_loss: 0.6050, step time: 0.4318\n",
      "batch: 7/17, train_dl_loss: 0.5590, train_bce_loss: 1.4729, train_bce_dl_loss: 0.5590, step time: 0.4672\n",
      "batch: 8/17, train_dl_loss: 0.5397, train_bce_loss: 1.4625, train_bce_dl_loss: 0.5397, step time: 0.4396\n",
      "batch: 9/17, train_dl_loss: 0.5114, train_bce_loss: 1.4732, train_bce_dl_loss: 0.5114, step time: 0.4395\n",
      "batch: 10/17, train_dl_loss: 0.6286, train_bce_loss: 1.4643, train_bce_dl_loss: 0.6286, step time: 0.4464\n",
      "batch: 11/17, train_dl_loss: 0.5514, train_bce_loss: 1.4628, train_bce_dl_loss: 0.5514, step time: 0.4765\n",
      "batch: 12/17, train_dl_loss: 0.5364, train_bce_loss: 1.4577, train_bce_dl_loss: 0.5364, step time: 0.4215\n",
      "batch: 13/17, train_dl_loss: 0.6876, train_bce_loss: 1.4687, train_bce_dl_loss: 0.6876, step time: 0.4349\n",
      "batch: 14/17, train_dl_loss: 0.5496, train_bce_loss: 1.4849, train_bce_dl_loss: 0.5496, step time: 0.4227\n",
      "batch: 15/17, train_dl_loss: 0.5241, train_bce_loss: 1.4728, train_bce_dl_loss: 0.5241, step time: 0.4379\n",
      "batch: 16/17, train_dl_loss: 0.5766, train_bce_loss: 1.4792, train_bce_dl_loss: 0.5766, step time: 0.4324\n",
      "batch: 17/17, train_dl_loss: 0.4855, train_bce_loss: 1.4741, train_bce_dl_loss: 0.4855, step time: 0.1111\n",
      "LOSS train DiceLoss: 0.5580, LOSS train BCE: 1.4670, LOSS train BCE-DiceLoss: 0.5580, LOSS val DiceLoss: 0.6162, LOSS val BCE: 1.4598, LOSS val BCE-DiceLoss: 0.6162, METRIC val: 0.4062\n",
      "time consuming of epoch 59 is: 433.2844\n",
      "----------\n",
      "EPOCH 60/80\n",
      "batch: 0/17, train_dl_loss: 0.5227, train_bce_loss: 1.4509, train_bce_dl_loss: 0.5227, step time: 0.4188\n",
      "batch: 1/17, train_dl_loss: 0.5308, train_bce_loss: 1.4780, train_bce_dl_loss: 0.5308, step time: 0.3718\n",
      "batch: 2/17, train_dl_loss: 0.5665, train_bce_loss: 1.4667, train_bce_dl_loss: 0.5665, step time: 0.4213\n",
      "batch: 3/17, train_dl_loss: 0.5850, train_bce_loss: 1.4622, train_bce_dl_loss: 0.5850, step time: 0.3766\n",
      "batch: 4/17, train_dl_loss: 0.4996, train_bce_loss: 1.4601, train_bce_dl_loss: 0.4996, step time: 0.4327\n",
      "batch: 5/17, train_dl_loss: 0.5336, train_bce_loss: 1.4762, train_bce_dl_loss: 0.5336, step time: 0.3849\n",
      "batch: 6/17, train_dl_loss: 0.5801, train_bce_loss: 1.4718, train_bce_dl_loss: 0.5801, step time: 0.4305\n",
      "batch: 7/17, train_dl_loss: 0.5219, train_bce_loss: 1.4563, train_bce_dl_loss: 0.5219, step time: 0.3920\n",
      "batch: 8/17, train_dl_loss: 0.5513, train_bce_loss: 1.4534, train_bce_dl_loss: 0.5513, step time: 0.4282\n",
      "batch: 9/17, train_dl_loss: 0.5960, train_bce_loss: 1.4834, train_bce_dl_loss: 0.5960, step time: 0.4404\n",
      "batch: 10/17, train_dl_loss: 0.6085, train_bce_loss: 1.4672, train_bce_dl_loss: 0.6085, step time: 0.4309\n",
      "batch: 11/17, train_dl_loss: 0.5324, train_bce_loss: 1.4409, train_bce_dl_loss: 0.5324, step time: 0.4260\n",
      "batch: 12/17, train_dl_loss: 0.5375, train_bce_loss: 1.4586, train_bce_dl_loss: 0.5375, step time: 0.4367\n",
      "batch: 13/17, train_dl_loss: 0.7002, train_bce_loss: 1.4828, train_bce_dl_loss: 0.7002, step time: 0.4294\n",
      "batch: 14/17, train_dl_loss: 0.5841, train_bce_loss: 1.4938, train_bce_dl_loss: 0.5841, step time: 0.4305\n",
      "batch: 15/17, train_dl_loss: 0.5419, train_bce_loss: 1.4822, train_bce_dl_loss: 0.5419, step time: 0.3846\n",
      "batch: 16/17, train_dl_loss: 0.5335, train_bce_loss: 1.4704, train_bce_dl_loss: 0.5335, step time: 0.4173\n",
      "batch: 17/17, train_dl_loss: 0.5287, train_bce_loss: 1.4641, train_bce_dl_loss: 0.5287, step time: 0.1113\n",
      "LOSS train DiceLoss: 0.5586, LOSS train BCE: 1.4677, LOSS train BCE-DiceLoss: 0.5586, LOSS val DiceLoss: 0.6143, LOSS val BCE: 1.4603, LOSS val BCE-DiceLoss: 0.6143, METRIC val: 0.4084\n",
      "time consuming of epoch 60 is: 446.8952\n",
      "----------\n",
      "EPOCH 61/80\n",
      "batch: 0/17, train_dl_loss: 0.4999, train_bce_loss: 1.4670, train_bce_dl_loss: 0.4999, step time: 0.4344\n",
      "batch: 1/17, train_dl_loss: 0.5341, train_bce_loss: 1.4579, train_bce_dl_loss: 0.5341, step time: 0.3694\n",
      "batch: 2/17, train_dl_loss: 0.5397, train_bce_loss: 1.4578, train_bce_dl_loss: 0.5397, step time: 0.4736\n",
      "batch: 3/17, train_dl_loss: 0.6039, train_bce_loss: 1.4652, train_bce_dl_loss: 0.6039, step time: 0.3735\n",
      "batch: 4/17, train_dl_loss: 0.5655, train_bce_loss: 1.4719, train_bce_dl_loss: 0.5655, step time: 0.4292\n",
      "batch: 5/17, train_dl_loss: 0.5159, train_bce_loss: 1.4649, train_bce_dl_loss: 0.5159, step time: 0.3752\n",
      "batch: 6/17, train_dl_loss: 0.5502, train_bce_loss: 1.4763, train_bce_dl_loss: 0.5502, step time: 0.4249\n",
      "batch: 7/17, train_dl_loss: 0.5504, train_bce_loss: 1.4604, train_bce_dl_loss: 0.5504, step time: 0.3730\n",
      "batch: 8/17, train_dl_loss: 0.5474, train_bce_loss: 1.4647, train_bce_dl_loss: 0.5474, step time: 0.4333\n",
      "batch: 9/17, train_dl_loss: 0.5378, train_bce_loss: 1.4736, train_bce_dl_loss: 0.5378, step time: 0.3904\n",
      "batch: 10/17, train_dl_loss: 0.6143, train_bce_loss: 1.4686, train_bce_dl_loss: 0.6143, step time: 0.4445\n",
      "batch: 11/17, train_dl_loss: 0.5490, train_bce_loss: 1.4691, train_bce_dl_loss: 0.5490, step time: 0.3865\n",
      "batch: 12/17, train_dl_loss: 0.5347, train_bce_loss: 1.4650, train_bce_dl_loss: 0.5347, step time: 0.4409\n",
      "batch: 13/17, train_dl_loss: 0.6989, train_bce_loss: 1.4758, train_bce_dl_loss: 0.6989, step time: 0.3757\n",
      "batch: 14/17, train_dl_loss: 0.5609, train_bce_loss: 1.4830, train_bce_dl_loss: 0.5609, step time: 0.4200\n",
      "batch: 15/17, train_dl_loss: 0.5461, train_bce_loss: 1.4680, train_bce_dl_loss: 0.5461, step time: 0.3784\n",
      "batch: 16/17, train_dl_loss: 0.5377, train_bce_loss: 1.4748, train_bce_dl_loss: 0.5377, step time: 0.4125\n",
      "batch: 17/17, train_dl_loss: 0.5184, train_bce_loss: 1.4657, train_bce_dl_loss: 0.5184, step time: 0.1108\n",
      "LOSS train DiceLoss: 0.5558, LOSS train BCE: 1.4683, LOSS train BCE-DiceLoss: 0.5558, LOSS val DiceLoss: 0.6136, LOSS val BCE: 1.4630, LOSS val BCE-DiceLoss: 0.6136, METRIC val: 0.4107\n",
      "time consuming of epoch 61 is: 435.9767\n",
      "----------\n",
      "EPOCH 62/80\n",
      "batch: 0/17, train_dl_loss: 0.5198, train_bce_loss: 1.4647, train_bce_dl_loss: 0.5198, step time: 0.4451\n",
      "batch: 1/17, train_dl_loss: 0.5344, train_bce_loss: 1.4723, train_bce_dl_loss: 0.5344, step time: 0.3871\n",
      "batch: 2/17, train_dl_loss: 0.5526, train_bce_loss: 1.4538, train_bce_dl_loss: 0.5526, step time: 0.4459\n",
      "batch: 3/17, train_dl_loss: 0.5924, train_bce_loss: 1.4705, train_bce_dl_loss: 0.5924, step time: 0.3805\n",
      "batch: 4/17, train_dl_loss: 0.4996, train_bce_loss: 1.4673, train_bce_dl_loss: 0.4996, step time: 0.4221\n",
      "batch: 5/17, train_dl_loss: 0.5360, train_bce_loss: 1.4568, train_bce_dl_loss: 0.5360, step time: 0.3785\n",
      "batch: 6/17, train_dl_loss: 0.5824, train_bce_loss: 1.4706, train_bce_dl_loss: 0.5824, step time: 0.4365\n",
      "batch: 7/17, train_dl_loss: 0.5256, train_bce_loss: 1.4523, train_bce_dl_loss: 0.5256, step time: 0.3752\n",
      "batch: 8/17, train_dl_loss: 0.5228, train_bce_loss: 1.4587, train_bce_dl_loss: 0.5228, step time: 0.4512\n",
      "batch: 9/17, train_dl_loss: 0.5213, train_bce_loss: 1.4673, train_bce_dl_loss: 0.5213, step time: 0.3732\n",
      "batch: 10/17, train_dl_loss: 0.6168, train_bce_loss: 1.4687, train_bce_dl_loss: 0.6168, step time: 0.4331\n",
      "batch: 11/17, train_dl_loss: 0.6298, train_bce_loss: 1.4773, train_bce_dl_loss: 0.6298, step time: 0.4199\n",
      "batch: 12/17, train_dl_loss: 0.5265, train_bce_loss: 1.4717, train_bce_dl_loss: 0.5265, step time: 0.4386\n",
      "batch: 13/17, train_dl_loss: 0.6281, train_bce_loss: 1.4769, train_bce_dl_loss: 0.6281, step time: 0.3748\n",
      "batch: 14/17, train_dl_loss: 0.5501, train_bce_loss: 1.4848, train_bce_dl_loss: 0.5501, step time: 0.4250\n",
      "batch: 15/17, train_dl_loss: 0.5165, train_bce_loss: 1.4792, train_bce_dl_loss: 0.5165, step time: 0.3819\n",
      "batch: 16/17, train_dl_loss: 0.5292, train_bce_loss: 1.4744, train_bce_dl_loss: 0.5292, step time: 0.4140\n",
      "batch: 17/17, train_dl_loss: 0.4774, train_bce_loss: 1.4752, train_bce_dl_loss: 0.4774, step time: 0.1118\n",
      "LOSS train DiceLoss: 0.5478, LOSS train BCE: 1.4690, LOSS train BCE-DiceLoss: 0.5478, LOSS val DiceLoss: 0.6132, LOSS val BCE: 1.4632, LOSS val BCE-DiceLoss: 0.6132, METRIC val: 0.4112\n",
      "time consuming of epoch 62 is: 405.2193\n",
      "----------\n",
      "EPOCH 63/80\n",
      "batch: 0/17, train_dl_loss: 0.5840, train_bce_loss: 1.4697, train_bce_dl_loss: 0.5840, step time: 0.4310\n",
      "batch: 1/17, train_dl_loss: 0.5473, train_bce_loss: 1.4747, train_bce_dl_loss: 0.5473, step time: 0.3944\n",
      "batch: 2/17, train_dl_loss: 0.5289, train_bce_loss: 1.4756, train_bce_dl_loss: 0.5289, step time: 0.4377\n",
      "batch: 3/17, train_dl_loss: 0.6338, train_bce_loss: 1.4764, train_bce_dl_loss: 0.6338, step time: 0.3808\n",
      "batch: 4/17, train_dl_loss: 0.5398, train_bce_loss: 1.4557, train_bce_dl_loss: 0.5398, step time: 0.4286\n",
      "batch: 5/17, train_dl_loss: 0.5053, train_bce_loss: 1.4652, train_bce_dl_loss: 0.5053, step time: 0.3691\n",
      "batch: 6/17, train_dl_loss: 0.5576, train_bce_loss: 1.4758, train_bce_dl_loss: 0.5576, step time: 0.5137\n",
      "batch: 7/17, train_dl_loss: 0.5144, train_bce_loss: 1.4621, train_bce_dl_loss: 0.5144, step time: 0.3812\n",
      "batch: 8/17, train_dl_loss: 0.5125, train_bce_loss: 1.4523, train_bce_dl_loss: 0.5125, step time: 0.4395\n",
      "batch: 9/17, train_dl_loss: 0.5262, train_bce_loss: 1.4776, train_bce_dl_loss: 0.5262, step time: 0.3763\n",
      "batch: 10/17, train_dl_loss: 0.6023, train_bce_loss: 1.4568, train_bce_dl_loss: 0.6023, step time: 0.4202\n",
      "batch: 11/17, train_dl_loss: 0.5394, train_bce_loss: 1.4493, train_bce_dl_loss: 0.5394, step time: 0.3883\n",
      "batch: 12/17, train_dl_loss: 0.5658, train_bce_loss: 1.4772, train_bce_dl_loss: 0.5658, step time: 0.4240\n",
      "batch: 13/17, train_dl_loss: 0.6398, train_bce_loss: 1.4773, train_bce_dl_loss: 0.6398, step time: 0.3750\n",
      "batch: 14/17, train_dl_loss: 0.5817, train_bce_loss: 1.4936, train_bce_dl_loss: 0.5817, step time: 0.4163\n",
      "batch: 15/17, train_dl_loss: 0.5202, train_bce_loss: 1.4811, train_bce_dl_loss: 0.5202, step time: 0.3783\n",
      "batch: 16/17, train_dl_loss: 0.5094, train_bce_loss: 1.4791, train_bce_dl_loss: 0.5094, step time: 0.4120\n",
      "batch: 17/17, train_dl_loss: 0.4905, train_bce_loss: 1.4759, train_bce_dl_loss: 0.4905, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5499, LOSS train BCE: 1.4709, LOSS train BCE-DiceLoss: 0.5499, LOSS val DiceLoss: 0.6141, LOSS val BCE: 1.4644, LOSS val BCE-DiceLoss: 0.6141, METRIC val: 0.4092\n",
      "time consuming of epoch 63 is: 379.9147\n",
      "----------\n",
      "EPOCH 64/80\n",
      "batch: 0/17, train_dl_loss: 0.5467, train_bce_loss: 1.4644, train_bce_dl_loss: 0.5467, step time: 0.4837\n",
      "batch: 1/17, train_dl_loss: 0.5259, train_bce_loss: 1.4785, train_bce_dl_loss: 0.5259, step time: 0.3762\n",
      "batch: 2/17, train_dl_loss: 0.5499, train_bce_loss: 1.4825, train_bce_dl_loss: 0.5499, step time: 0.4393\n",
      "batch: 3/17, train_dl_loss: 0.5805, train_bce_loss: 1.4699, train_bce_dl_loss: 0.5805, step time: 0.3726\n",
      "batch: 4/17, train_dl_loss: 0.5276, train_bce_loss: 1.4551, train_bce_dl_loss: 0.5276, step time: 0.4310\n",
      "batch: 5/17, train_dl_loss: 0.4970, train_bce_loss: 1.4639, train_bce_dl_loss: 0.4970, step time: 0.3721\n",
      "batch: 6/17, train_dl_loss: 0.5614, train_bce_loss: 1.4773, train_bce_dl_loss: 0.5614, step time: 0.4323\n",
      "batch: 7/17, train_dl_loss: 0.5408, train_bce_loss: 1.4714, train_bce_dl_loss: 0.5408, step time: 0.3758\n",
      "batch: 8/17, train_dl_loss: 0.5288, train_bce_loss: 1.4773, train_bce_dl_loss: 0.5288, step time: 0.4421\n",
      "batch: 9/17, train_dl_loss: 0.5749, train_bce_loss: 1.4739, train_bce_dl_loss: 0.5749, step time: 0.3769\n",
      "batch: 10/17, train_dl_loss: 0.6010, train_bce_loss: 1.4695, train_bce_dl_loss: 0.6010, step time: 0.4264\n",
      "batch: 11/17, train_dl_loss: 0.5350, train_bce_loss: 1.4425, train_bce_dl_loss: 0.5350, step time: 0.3789\n",
      "batch: 12/17, train_dl_loss: 0.5757, train_bce_loss: 1.4624, train_bce_dl_loss: 0.5757, step time: 0.4394\n",
      "batch: 13/17, train_dl_loss: 0.6912, train_bce_loss: 1.4628, train_bce_dl_loss: 0.6912, step time: 0.3791\n",
      "batch: 14/17, train_dl_loss: 0.5455, train_bce_loss: 1.4707, train_bce_dl_loss: 0.5455, step time: 0.4319\n",
      "batch: 15/17, train_dl_loss: 0.5714, train_bce_loss: 1.4738, train_bce_dl_loss: 0.5714, step time: 0.3773\n",
      "batch: 16/17, train_dl_loss: 0.5320, train_bce_loss: 1.4758, train_bce_dl_loss: 0.5320, step time: 0.4180\n",
      "batch: 17/17, train_dl_loss: 0.4725, train_bce_loss: 1.4683, train_bce_dl_loss: 0.4725, step time: 0.1107\n",
      "LOSS train DiceLoss: 0.5532, LOSS train BCE: 1.4689, LOSS train BCE-DiceLoss: 0.5532, LOSS val DiceLoss: 0.6134, LOSS val BCE: 1.4647, LOSS val BCE-DiceLoss: 0.6134, METRIC val: 0.4102\n",
      "time consuming of epoch 64 is: 426.7284\n",
      "----------\n",
      "EPOCH 65/80\n",
      "batch: 0/17, train_dl_loss: 0.5341, train_bce_loss: 1.4590, train_bce_dl_loss: 0.5341, step time: 0.4282\n",
      "batch: 1/17, train_dl_loss: 0.5341, train_bce_loss: 1.4682, train_bce_dl_loss: 0.5341, step time: 0.3809\n",
      "batch: 2/17, train_dl_loss: 0.5505, train_bce_loss: 1.4539, train_bce_dl_loss: 0.5505, step time: 0.4149\n",
      "batch: 3/17, train_dl_loss: 0.5928, train_bce_loss: 1.4677, train_bce_dl_loss: 0.5928, step time: 0.3805\n",
      "batch: 4/17, train_dl_loss: 0.4910, train_bce_loss: 1.4590, train_bce_dl_loss: 0.4910, step time: 0.4461\n",
      "batch: 5/17, train_dl_loss: 0.5066, train_bce_loss: 1.4646, train_bce_dl_loss: 0.5066, step time: 0.4207\n",
      "batch: 6/17, train_dl_loss: 0.6115, train_bce_loss: 1.4772, train_bce_dl_loss: 0.6115, step time: 0.4411\n",
      "batch: 7/17, train_dl_loss: 0.5118, train_bce_loss: 1.4635, train_bce_dl_loss: 0.5118, step time: 0.4298\n",
      "batch: 8/17, train_dl_loss: 0.5228, train_bce_loss: 1.4513, train_bce_dl_loss: 0.5228, step time: 0.4223\n",
      "batch: 9/17, train_dl_loss: 0.5213, train_bce_loss: 1.4715, train_bce_dl_loss: 0.5213, step time: 0.4292\n",
      "batch: 10/17, train_dl_loss: 0.6295, train_bce_loss: 1.4802, train_bce_dl_loss: 0.6295, step time: 0.4236\n",
      "batch: 11/17, train_dl_loss: 0.5266, train_bce_loss: 1.4628, train_bce_dl_loss: 0.5266, step time: 0.4385\n",
      "batch: 12/17, train_dl_loss: 0.5752, train_bce_loss: 1.4708, train_bce_dl_loss: 0.5752, step time: 0.4505\n",
      "batch: 13/17, train_dl_loss: 0.6724, train_bce_loss: 1.4845, train_bce_dl_loss: 0.6724, step time: 0.4393\n",
      "batch: 14/17, train_dl_loss: 0.5671, train_bce_loss: 1.4900, train_bce_dl_loss: 0.5671, step time: 0.4345\n",
      "batch: 15/17, train_dl_loss: 0.5270, train_bce_loss: 1.4655, train_bce_dl_loss: 0.5270, step time: 0.4265\n",
      "batch: 16/17, train_dl_loss: 0.5232, train_bce_loss: 1.4746, train_bce_dl_loss: 0.5232, step time: 0.4288\n",
      "batch: 17/17, train_dl_loss: 0.5168, train_bce_loss: 1.4689, train_bce_dl_loss: 0.5168, step time: 0.1110\n",
      "LOSS train DiceLoss: 0.5508, LOSS train BCE: 1.4685, LOSS train BCE-DiceLoss: 0.5508, LOSS val DiceLoss: 0.6124, LOSS val BCE: 1.4655, LOSS val BCE-DiceLoss: 0.6124, METRIC val: 0.4115\n",
      "time consuming of epoch 65 is: 405.9405\n",
      "----------\n",
      "EPOCH 66/80\n",
      "batch: 0/17, train_dl_loss: 0.5734, train_bce_loss: 1.4621, train_bce_dl_loss: 0.5734, step time: 0.4265\n",
      "batch: 1/17, train_dl_loss: 0.5207, train_bce_loss: 1.4763, train_bce_dl_loss: 0.5207, step time: 0.3746\n",
      "batch: 2/17, train_dl_loss: 0.5588, train_bce_loss: 1.4785, train_bce_dl_loss: 0.5588, step time: 0.4205\n",
      "batch: 3/17, train_dl_loss: 0.6029, train_bce_loss: 1.4740, train_bce_dl_loss: 0.6029, step time: 0.3706\n",
      "batch: 4/17, train_dl_loss: 0.5103, train_bce_loss: 1.4660, train_bce_dl_loss: 0.5103, step time: 0.4412\n",
      "batch: 5/17, train_dl_loss: 0.5121, train_bce_loss: 1.4570, train_bce_dl_loss: 0.5121, step time: 0.3801\n",
      "batch: 6/17, train_dl_loss: 0.5849, train_bce_loss: 1.4744, train_bce_dl_loss: 0.5849, step time: 0.4197\n",
      "batch: 7/17, train_dl_loss: 0.5124, train_bce_loss: 1.4546, train_bce_dl_loss: 0.5124, step time: 0.3758\n",
      "batch: 8/17, train_dl_loss: 0.5158, train_bce_loss: 1.4671, train_bce_dl_loss: 0.5158, step time: 0.4788\n",
      "batch: 9/17, train_dl_loss: 0.5317, train_bce_loss: 1.4827, train_bce_dl_loss: 0.5317, step time: 0.3749\n",
      "batch: 10/17, train_dl_loss: 0.6059, train_bce_loss: 1.4618, train_bce_dl_loss: 0.6059, step time: 0.4261\n",
      "batch: 11/17, train_dl_loss: 0.5871, train_bce_loss: 1.4586, train_bce_dl_loss: 0.5871, step time: 0.4288\n",
      "batch: 12/17, train_dl_loss: 0.5473, train_bce_loss: 1.4709, train_bce_dl_loss: 0.5473, step time: 0.4391\n",
      "batch: 13/17, train_dl_loss: 0.6628, train_bce_loss: 1.4786, train_bce_dl_loss: 0.6628, step time: 0.3782\n",
      "batch: 14/17, train_dl_loss: 0.5634, train_bce_loss: 1.4773, train_bce_dl_loss: 0.5634, step time: 0.4441\n",
      "batch: 15/17, train_dl_loss: 0.5281, train_bce_loss: 1.4792, train_bce_dl_loss: 0.5281, step time: 0.3885\n",
      "batch: 16/17, train_dl_loss: 0.5048, train_bce_loss: 1.4811, train_bce_dl_loss: 0.5048, step time: 0.4323\n",
      "batch: 17/17, train_dl_loss: 0.5099, train_bce_loss: 1.4847, train_bce_dl_loss: 0.5099, step time: 0.1109\n",
      "LOSS train DiceLoss: 0.5518, LOSS train BCE: 1.4714, LOSS train BCE-DiceLoss: 0.5518, LOSS val DiceLoss: 0.6118, LOSS val BCE: 1.4665, LOSS val BCE-DiceLoss: 0.6118, METRIC val: 0.4123\n",
      "time consuming of epoch 66 is: 399.2424\n",
      "----------\n",
      "EPOCH 67/80\n",
      "batch: 0/17, train_dl_loss: 0.5075, train_bce_loss: 1.4517, train_bce_dl_loss: 0.5075, step time: 0.4334\n",
      "batch: 1/17, train_dl_loss: 0.5301, train_bce_loss: 1.4654, train_bce_dl_loss: 0.5301, step time: 0.3752\n",
      "batch: 2/17, train_dl_loss: 0.5464, train_bce_loss: 1.4758, train_bce_dl_loss: 0.5464, step time: 0.4339\n",
      "batch: 3/17, train_dl_loss: 0.6002, train_bce_loss: 1.4837, train_bce_dl_loss: 0.6002, step time: 0.3874\n",
      "batch: 4/17, train_dl_loss: 0.5163, train_bce_loss: 1.4650, train_bce_dl_loss: 0.5163, step time: 0.4248\n",
      "batch: 5/17, train_dl_loss: 0.5224, train_bce_loss: 1.4801, train_bce_dl_loss: 0.5224, step time: 0.3848\n",
      "batch: 6/17, train_dl_loss: 0.5480, train_bce_loss: 1.4875, train_bce_dl_loss: 0.5480, step time: 0.4296\n",
      "batch: 7/17, train_dl_loss: 0.5386, train_bce_loss: 1.4523, train_bce_dl_loss: 0.5386, step time: 0.3822\n",
      "batch: 8/17, train_dl_loss: 0.5180, train_bce_loss: 1.4665, train_bce_dl_loss: 0.5180, step time: 0.4386\n",
      "batch: 9/17, train_dl_loss: 0.5330, train_bce_loss: 1.4734, train_bce_dl_loss: 0.5330, step time: 0.3757\n",
      "batch: 10/17, train_dl_loss: 0.6071, train_bce_loss: 1.4581, train_bce_dl_loss: 0.6071, step time: 0.4313\n",
      "batch: 11/17, train_dl_loss: 0.5135, train_bce_loss: 1.4857, train_bce_dl_loss: 0.5135, step time: 0.4244\n",
      "batch: 12/17, train_dl_loss: 0.5882, train_bce_loss: 1.4849, train_bce_dl_loss: 0.5882, step time: 0.4253\n",
      "batch: 13/17, train_dl_loss: 0.6050, train_bce_loss: 1.4883, train_bce_dl_loss: 0.6050, step time: 0.3748\n",
      "batch: 14/17, train_dl_loss: 0.5526, train_bce_loss: 1.4837, train_bce_dl_loss: 0.5526, step time: 0.4222\n",
      "batch: 15/17, train_dl_loss: 0.5099, train_bce_loss: 1.4713, train_bce_dl_loss: 0.5099, step time: 0.3732\n",
      "batch: 16/17, train_dl_loss: 0.5320, train_bce_loss: 1.4731, train_bce_dl_loss: 0.5320, step time: 0.4327\n",
      "batch: 17/17, train_dl_loss: 0.4670, train_bce_loss: 1.4696, train_bce_dl_loss: 0.4670, step time: 0.1139\n",
      "LOSS train DiceLoss: 0.5409, LOSS train BCE: 1.4731, LOSS train BCE-DiceLoss: 0.5409, LOSS val DiceLoss: 0.6122, LOSS val BCE: 1.4668, LOSS val BCE-DiceLoss: 0.6122, METRIC val: 0.4118\n",
      "time consuming of epoch 67 is: 428.7354\n",
      "----------\n",
      "EPOCH 68/80\n",
      "batch: 0/17, train_dl_loss: 0.5167, train_bce_loss: 1.4670, train_bce_dl_loss: 0.5167, step time: 0.4209\n",
      "batch: 1/17, train_dl_loss: 0.5571, train_bce_loss: 1.4816, train_bce_dl_loss: 0.5571, step time: 0.3800\n",
      "batch: 2/17, train_dl_loss: 0.5459, train_bce_loss: 1.4658, train_bce_dl_loss: 0.5459, step time: 0.4229\n",
      "batch: 3/17, train_dl_loss: 0.6673, train_bce_loss: 1.4939, train_bce_dl_loss: 0.6673, step time: 0.3791\n",
      "batch: 4/17, train_dl_loss: 0.4916, train_bce_loss: 1.4622, train_bce_dl_loss: 0.4916, step time: 0.4478\n",
      "batch: 5/17, train_dl_loss: 0.5903, train_bce_loss: 1.4781, train_bce_dl_loss: 0.5903, step time: 0.3797\n",
      "batch: 6/17, train_dl_loss: 0.5632, train_bce_loss: 1.4754, train_bce_dl_loss: 0.5632, step time: 0.4740\n",
      "batch: 7/17, train_dl_loss: 0.5381, train_bce_loss: 1.4584, train_bce_dl_loss: 0.5381, step time: 0.4356\n",
      "batch: 8/17, train_dl_loss: 0.5883, train_bce_loss: 1.4520, train_bce_dl_loss: 0.5883, step time: 0.4284\n",
      "batch: 9/17, train_dl_loss: 0.5340, train_bce_loss: 1.4800, train_bce_dl_loss: 0.5340, step time: 0.4177\n",
      "batch: 10/17, train_dl_loss: 0.6679, train_bce_loss: 1.4639, train_bce_dl_loss: 0.6679, step time: 0.4191\n",
      "batch: 11/17, train_dl_loss: 0.5328, train_bce_loss: 1.4443, train_bce_dl_loss: 0.5328, step time: 0.4318\n",
      "batch: 12/17, train_dl_loss: 0.5321, train_bce_loss: 1.4692, train_bce_dl_loss: 0.5321, step time: 0.4329\n",
      "batch: 13/17, train_dl_loss: 0.6300, train_bce_loss: 1.4757, train_bce_dl_loss: 0.6300, step time: 0.4264\n",
      "batch: 14/17, train_dl_loss: 0.5332, train_bce_loss: 1.4813, train_bce_dl_loss: 0.5332, step time: 0.4218\n",
      "batch: 15/17, train_dl_loss: 0.5559, train_bce_loss: 1.4778, train_bce_dl_loss: 0.5559, step time: 0.3904\n",
      "batch: 16/17, train_dl_loss: 0.5369, train_bce_loss: 1.4868, train_bce_dl_loss: 0.5369, step time: 0.4241\n",
      "batch: 17/17, train_dl_loss: 0.4784, train_bce_loss: 1.4739, train_bce_dl_loss: 0.4784, step time: 0.1117\n",
      "LOSS train DiceLoss: 0.5589, LOSS train BCE: 1.4715, LOSS train BCE-DiceLoss: 0.5589, LOSS val DiceLoss: 0.6118, LOSS val BCE: 1.4675, LOSS val BCE-DiceLoss: 0.6118, METRIC val: 0.4125\n",
      "time consuming of epoch 68 is: 448.9954\n",
      "----------\n",
      "EPOCH 69/80\n",
      "batch: 0/17, train_dl_loss: 0.5363, train_bce_loss: 1.4616, train_bce_dl_loss: 0.5363, step time: 0.4989\n",
      "batch: 1/17, train_dl_loss: 0.5459, train_bce_loss: 1.4726, train_bce_dl_loss: 0.5459, step time: 0.3807\n",
      "batch: 2/17, train_dl_loss: 0.5572, train_bce_loss: 1.4739, train_bce_dl_loss: 0.5572, step time: 0.4333\n",
      "batch: 3/17, train_dl_loss: 0.5863, train_bce_loss: 1.4650, train_bce_dl_loss: 0.5863, step time: 0.3808\n",
      "batch: 4/17, train_dl_loss: 0.5100, train_bce_loss: 1.4669, train_bce_dl_loss: 0.5100, step time: 0.4333\n",
      "batch: 5/17, train_dl_loss: 0.5431, train_bce_loss: 1.4659, train_bce_dl_loss: 0.5431, step time: 0.3722\n",
      "batch: 6/17, train_dl_loss: 0.5634, train_bce_loss: 1.4776, train_bce_dl_loss: 0.5634, step time: 0.4410\n",
      "batch: 7/17, train_dl_loss: 0.5360, train_bce_loss: 1.4610, train_bce_dl_loss: 0.5360, step time: 0.3779\n",
      "batch: 8/17, train_dl_loss: 0.5195, train_bce_loss: 1.4735, train_bce_dl_loss: 0.5195, step time: 0.4177\n",
      "batch: 9/17, train_dl_loss: 0.5267, train_bce_loss: 1.4787, train_bce_dl_loss: 0.5267, step time: 0.4753\n",
      "batch: 10/17, train_dl_loss: 0.6006, train_bce_loss: 1.4718, train_bce_dl_loss: 0.6006, step time: 0.4417\n",
      "batch: 11/17, train_dl_loss: 0.5764, train_bce_loss: 1.4772, train_bce_dl_loss: 0.5764, step time: 0.4294\n",
      "batch: 12/17, train_dl_loss: 0.5548, train_bce_loss: 1.4693, train_bce_dl_loss: 0.5548, step time: 0.4390\n",
      "batch: 13/17, train_dl_loss: 0.6461, train_bce_loss: 1.4833, train_bce_dl_loss: 0.6461, step time: 0.3868\n",
      "batch: 14/17, train_dl_loss: 0.5394, train_bce_loss: 1.4781, train_bce_dl_loss: 0.5394, step time: 0.4205\n",
      "batch: 15/17, train_dl_loss: 0.5394, train_bce_loss: 1.4802, train_bce_dl_loss: 0.5394, step time: 0.3789\n",
      "batch: 16/17, train_dl_loss: 0.5336, train_bce_loss: 1.4737, train_bce_dl_loss: 0.5336, step time: 0.4307\n",
      "batch: 17/17, train_dl_loss: 0.4718, train_bce_loss: 1.4703, train_bce_dl_loss: 0.4718, step time: 0.1119\n",
      "LOSS train DiceLoss: 0.5493, LOSS train BCE: 1.4723, LOSS train BCE-DiceLoss: 0.5493, LOSS val DiceLoss: 0.6123, LOSS val BCE: 1.4675, LOSS val BCE-DiceLoss: 0.6123, METRIC val: 0.4116\n",
      "time consuming of epoch 69 is: 416.1289\n",
      "----------\n",
      "EPOCH 70/80\n",
      "batch: 0/17, train_dl_loss: 0.5122, train_bce_loss: 1.4755, train_bce_dl_loss: 0.5122, step time: 0.4294\n",
      "batch: 1/17, train_dl_loss: 0.5733, train_bce_loss: 1.4817, train_bce_dl_loss: 0.5733, step time: 0.3788\n",
      "batch: 2/17, train_dl_loss: 0.5548, train_bce_loss: 1.4819, train_bce_dl_loss: 0.5548, step time: 0.4255\n",
      "batch: 3/17, train_dl_loss: 0.5870, train_bce_loss: 1.4741, train_bce_dl_loss: 0.5870, step time: 0.3770\n",
      "batch: 4/17, train_dl_loss: 0.5075, train_bce_loss: 1.4627, train_bce_dl_loss: 0.5075, step time: 0.4369\n",
      "batch: 5/17, train_dl_loss: 0.5447, train_bce_loss: 1.4821, train_bce_dl_loss: 0.5447, step time: 0.3813\n",
      "batch: 6/17, train_dl_loss: 0.5501, train_bce_loss: 1.4762, train_bce_dl_loss: 0.5501, step time: 0.4396\n",
      "batch: 7/17, train_dl_loss: 0.5017, train_bce_loss: 1.4557, train_bce_dl_loss: 0.5017, step time: 0.3892\n",
      "batch: 8/17, train_dl_loss: 0.5253, train_bce_loss: 1.4494, train_bce_dl_loss: 0.5253, step time: 0.4292\n",
      "batch: 9/17, train_dl_loss: 0.5315, train_bce_loss: 1.4869, train_bce_dl_loss: 0.5315, step time: 0.4398\n",
      "batch: 10/17, train_dl_loss: 0.5935, train_bce_loss: 1.4803, train_bce_dl_loss: 0.5935, step time: 0.4352\n",
      "batch: 11/17, train_dl_loss: 0.5314, train_bce_loss: 1.4800, train_bce_dl_loss: 0.5314, step time: 0.4314\n",
      "batch: 12/17, train_dl_loss: 0.5017, train_bce_loss: 1.4621, train_bce_dl_loss: 0.5017, step time: 0.4358\n",
      "batch: 13/17, train_dl_loss: 0.6383, train_bce_loss: 1.4817, train_bce_dl_loss: 0.6383, step time: 0.3778\n",
      "batch: 14/17, train_dl_loss: 0.5464, train_bce_loss: 1.4826, train_bce_dl_loss: 0.5464, step time: 0.4202\n",
      "batch: 15/17, train_dl_loss: 0.5099, train_bce_loss: 1.4860, train_bce_dl_loss: 0.5099, step time: 0.3721\n",
      "batch: 16/17, train_dl_loss: 0.5235, train_bce_loss: 1.4731, train_bce_dl_loss: 0.5235, step time: 0.4335\n",
      "batch: 17/17, train_dl_loss: 0.4708, train_bce_loss: 1.4790, train_bce_dl_loss: 0.4708, step time: 0.1113\n",
      "LOSS train DiceLoss: 0.5391, LOSS train BCE: 1.4751, LOSS train BCE-DiceLoss: 0.5391, LOSS val DiceLoss: 0.6127, LOSS val BCE: 1.4677, LOSS val BCE-DiceLoss: 0.6127, METRIC val: 0.4107\n",
      "time consuming of epoch 70 is: 417.3145\n",
      "----------\n",
      "EPOCH 71/80\n",
      "batch: 0/17, train_dl_loss: 0.5300, train_bce_loss: 1.4605, train_bce_dl_loss: 0.5300, step time: 0.4372\n",
      "batch: 1/17, train_dl_loss: 0.5149, train_bce_loss: 1.4787, train_bce_dl_loss: 0.5149, step time: 0.3760\n",
      "batch: 2/17, train_dl_loss: 0.5195, train_bce_loss: 1.4685, train_bce_dl_loss: 0.5195, step time: 0.4381\n",
      "batch: 3/17, train_dl_loss: 0.6101, train_bce_loss: 1.4816, train_bce_dl_loss: 0.6101, step time: 0.3770\n",
      "batch: 4/17, train_dl_loss: 0.5172, train_bce_loss: 1.4747, train_bce_dl_loss: 0.5172, step time: 0.4380\n",
      "batch: 5/17, train_dl_loss: 0.5340, train_bce_loss: 1.4892, train_bce_dl_loss: 0.5340, step time: 0.3870\n",
      "batch: 6/17, train_dl_loss: 0.6153, train_bce_loss: 1.4921, train_bce_dl_loss: 0.6153, step time: 0.4285\n",
      "batch: 7/17, train_dl_loss: 0.5350, train_bce_loss: 1.4744, train_bce_dl_loss: 0.5350, step time: 0.3742\n",
      "batch: 8/17, train_dl_loss: 0.5682, train_bce_loss: 1.4589, train_bce_dl_loss: 0.5682, step time: 0.4417\n",
      "batch: 9/17, train_dl_loss: 0.5960, train_bce_loss: 1.4932, train_bce_dl_loss: 0.5960, step time: 0.3887\n",
      "batch: 10/17, train_dl_loss: 0.6081, train_bce_loss: 1.4612, train_bce_dl_loss: 0.6081, step time: 0.4417\n",
      "batch: 11/17, train_dl_loss: 0.5238, train_bce_loss: 1.4649, train_bce_dl_loss: 0.5238, step time: 0.4342\n",
      "batch: 12/17, train_dl_loss: 0.5170, train_bce_loss: 1.4612, train_bce_dl_loss: 0.5170, step time: 0.4209\n",
      "batch: 13/17, train_dl_loss: 0.6967, train_bce_loss: 1.4931, train_bce_dl_loss: 0.6967, step time: 0.3836\n",
      "batch: 14/17, train_dl_loss: 0.5333, train_bce_loss: 1.4789, train_bce_dl_loss: 0.5333, step time: 0.4256\n",
      "batch: 15/17, train_dl_loss: 0.5679, train_bce_loss: 1.4784, train_bce_dl_loss: 0.5679, step time: 0.3795\n",
      "batch: 16/17, train_dl_loss: 0.5168, train_bce_loss: 1.4851, train_bce_dl_loss: 0.5168, step time: 0.4174\n",
      "batch: 17/17, train_dl_loss: 0.4688, train_bce_loss: 1.4782, train_bce_dl_loss: 0.4688, step time: 0.1118\n",
      "LOSS train DiceLoss: 0.5540, LOSS train BCE: 1.4763, LOSS train BCE-DiceLoss: 0.5540, LOSS val DiceLoss: 0.6128, LOSS val BCE: 1.4685, LOSS val BCE-DiceLoss: 0.6128, METRIC val: 0.4106\n",
      "time consuming of epoch 71 is: 430.9547\n",
      "----------\n",
      "EPOCH 72/80\n",
      "batch: 0/17, train_dl_loss: 0.5206, train_bce_loss: 1.4792, train_bce_dl_loss: 0.5206, step time: 0.4254\n",
      "batch: 1/17, train_dl_loss: 0.5250, train_bce_loss: 1.4757, train_bce_dl_loss: 0.5250, step time: 0.4339\n",
      "batch: 2/17, train_dl_loss: 0.5519, train_bce_loss: 1.4806, train_bce_dl_loss: 0.5519, step time: 0.4274\n",
      "batch: 3/17, train_dl_loss: 0.5681, train_bce_loss: 1.4745, train_bce_dl_loss: 0.5681, step time: 0.3709\n",
      "batch: 4/17, train_dl_loss: 0.5033, train_bce_loss: 1.4742, train_bce_dl_loss: 0.5033, step time: 0.4291\n",
      "batch: 5/17, train_dl_loss: 0.5254, train_bce_loss: 1.4590, train_bce_dl_loss: 0.5254, step time: 0.3781\n",
      "batch: 6/17, train_dl_loss: 0.5679, train_bce_loss: 1.4843, train_bce_dl_loss: 0.5679, step time: 0.4172\n",
      "batch: 7/17, train_dl_loss: 0.5368, train_bce_loss: 1.4707, train_bce_dl_loss: 0.5368, step time: 0.3793\n",
      "batch: 8/17, train_dl_loss: 0.5184, train_bce_loss: 1.4616, train_bce_dl_loss: 0.5184, step time: 0.4432\n",
      "batch: 9/17, train_dl_loss: 0.5131, train_bce_loss: 1.4841, train_bce_dl_loss: 0.5131, step time: 0.3808\n",
      "batch: 10/17, train_dl_loss: 0.5836, train_bce_loss: 1.4692, train_bce_dl_loss: 0.5836, step time: 0.4514\n",
      "batch: 11/17, train_dl_loss: 0.5757, train_bce_loss: 1.4706, train_bce_dl_loss: 0.5757, step time: 0.4212\n",
      "batch: 12/17, train_dl_loss: 0.6158, train_bce_loss: 1.4714, train_bce_dl_loss: 0.6158, step time: 0.4387\n",
      "batch: 13/17, train_dl_loss: 0.6425, train_bce_loss: 1.4708, train_bce_dl_loss: 0.6425, step time: 0.3784\n",
      "batch: 14/17, train_dl_loss: 0.5751, train_bce_loss: 1.4875, train_bce_dl_loss: 0.5751, step time: 0.4199\n",
      "batch: 15/17, train_dl_loss: 0.5463, train_bce_loss: 1.4764, train_bce_dl_loss: 0.5463, step time: 0.3852\n",
      "batch: 16/17, train_dl_loss: 0.5276, train_bce_loss: 1.4777, train_bce_dl_loss: 0.5276, step time: 0.4344\n",
      "batch: 17/17, train_dl_loss: 0.5197, train_bce_loss: 1.4739, train_bce_dl_loss: 0.5197, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.5509, LOSS train BCE: 1.4745, LOSS train BCE-DiceLoss: 0.5509, LOSS val DiceLoss: 0.6125, LOSS val BCE: 1.4690, LOSS val BCE-DiceLoss: 0.6125, METRIC val: 0.4110\n",
      "time consuming of epoch 72 is: 424.2326\n",
      "----------\n",
      "EPOCH 73/80\n",
      "batch: 0/17, train_dl_loss: 0.5336, train_bce_loss: 1.4620, train_bce_dl_loss: 0.5336, step time: 0.4282\n",
      "batch: 1/17, train_dl_loss: 0.5158, train_bce_loss: 1.4783, train_bce_dl_loss: 0.5158, step time: 0.3740\n",
      "batch: 2/17, train_dl_loss: 0.5521, train_bce_loss: 1.4670, train_bce_dl_loss: 0.5521, step time: 0.4310\n",
      "batch: 3/17, train_dl_loss: 0.5691, train_bce_loss: 1.4788, train_bce_dl_loss: 0.5691, step time: 0.3830\n",
      "batch: 4/17, train_dl_loss: 0.4909, train_bce_loss: 1.4775, train_bce_dl_loss: 0.4909, step time: 0.4415\n",
      "batch: 5/17, train_dl_loss: 0.5374, train_bce_loss: 1.4728, train_bce_dl_loss: 0.5374, step time: 0.3812\n",
      "batch: 6/17, train_dl_loss: 0.5464, train_bce_loss: 1.4798, train_bce_dl_loss: 0.5464, step time: 0.4430\n",
      "batch: 7/17, train_dl_loss: 0.5089, train_bce_loss: 1.4600, train_bce_dl_loss: 0.5089, step time: 0.4313\n",
      "batch: 8/17, train_dl_loss: 0.5151, train_bce_loss: 1.4816, train_bce_dl_loss: 0.5151, step time: 0.4151\n",
      "batch: 9/17, train_dl_loss: 0.5722, train_bce_loss: 1.4911, train_bce_dl_loss: 0.5722, step time: 0.3838\n",
      "batch: 10/17, train_dl_loss: 0.5996, train_bce_loss: 1.4771, train_bce_dl_loss: 0.5996, step time: 0.4244\n",
      "batch: 11/17, train_dl_loss: 0.5371, train_bce_loss: 1.4775, train_bce_dl_loss: 0.5371, step time: 0.4295\n",
      "batch: 12/17, train_dl_loss: 0.5356, train_bce_loss: 1.4601, train_bce_dl_loss: 0.5356, step time: 0.4500\n",
      "batch: 13/17, train_dl_loss: 0.6280, train_bce_loss: 1.4827, train_bce_dl_loss: 0.6280, step time: 0.4494\n",
      "batch: 14/17, train_dl_loss: 0.5374, train_bce_loss: 1.4814, train_bce_dl_loss: 0.5374, step time: 0.4212\n",
      "batch: 15/17, train_dl_loss: 0.5363, train_bce_loss: 1.4816, train_bce_dl_loss: 0.5363, step time: 0.3775\n",
      "batch: 16/17, train_dl_loss: 0.5199, train_bce_loss: 1.4830, train_bce_dl_loss: 0.5199, step time: 0.4357\n",
      "batch: 17/17, train_dl_loss: 0.5193, train_bce_loss: 1.4738, train_bce_dl_loss: 0.5193, step time: 0.1126\n",
      "LOSS train DiceLoss: 0.5419, LOSS train BCE: 1.4759, LOSS train BCE-DiceLoss: 0.5419, LOSS val DiceLoss: 0.6122, LOSS val BCE: 1.4688, LOSS val BCE-DiceLoss: 0.6122, METRIC val: 0.4115\n",
      "time consuming of epoch 73 is: 420.0192\n",
      "----------\n",
      "EPOCH 74/80\n",
      "batch: 0/17, train_dl_loss: 0.5851, train_bce_loss: 1.4701, train_bce_dl_loss: 0.5851, step time: 0.4370\n",
      "batch: 1/17, train_dl_loss: 0.5123, train_bce_loss: 1.4745, train_bce_dl_loss: 0.5123, step time: 0.3756\n",
      "batch: 2/17, train_dl_loss: 0.5913, train_bce_loss: 1.4754, train_bce_dl_loss: 0.5913, step time: 0.4294\n",
      "batch: 3/17, train_dl_loss: 0.6278, train_bce_loss: 1.4830, train_bce_dl_loss: 0.6278, step time: 0.3769\n",
      "batch: 4/17, train_dl_loss: 0.5331, train_bce_loss: 1.4767, train_bce_dl_loss: 0.5331, step time: 0.4145\n",
      "batch: 5/17, train_dl_loss: 0.5858, train_bce_loss: 1.4913, train_bce_dl_loss: 0.5858, step time: 0.4428\n",
      "batch: 6/17, train_dl_loss: 0.5935, train_bce_loss: 1.4895, train_bce_dl_loss: 0.5935, step time: 0.4203\n",
      "batch: 7/17, train_dl_loss: 0.5169, train_bce_loss: 1.4538, train_bce_dl_loss: 0.5169, step time: 0.3767\n",
      "batch: 8/17, train_dl_loss: 0.5389, train_bce_loss: 1.4813, train_bce_dl_loss: 0.5389, step time: 0.4464\n",
      "batch: 9/17, train_dl_loss: 0.5358, train_bce_loss: 1.4879, train_bce_dl_loss: 0.5358, step time: 0.3844\n",
      "batch: 10/17, train_dl_loss: 0.6545, train_bce_loss: 1.4744, train_bce_dl_loss: 0.6545, step time: 0.4400\n",
      "batch: 11/17, train_dl_loss: 0.5254, train_bce_loss: 1.4468, train_bce_dl_loss: 0.5254, step time: 0.4278\n",
      "batch: 12/17, train_dl_loss: 0.5137, train_bce_loss: 1.4605, train_bce_dl_loss: 0.5137, step time: 0.4437\n",
      "batch: 13/17, train_dl_loss: 0.6367, train_bce_loss: 1.4776, train_bce_dl_loss: 0.6367, step time: 0.3851\n",
      "batch: 14/17, train_dl_loss: 0.5763, train_bce_loss: 1.5000, train_bce_dl_loss: 0.5763, step time: 0.4831\n",
      "batch: 15/17, train_dl_loss: 0.5531, train_bce_loss: 1.4856, train_bce_dl_loss: 0.5531, step time: 0.3816\n",
      "batch: 16/17, train_dl_loss: 0.5695, train_bce_loss: 1.4880, train_bce_dl_loss: 0.5695, step time: 0.4278\n",
      "batch: 17/17, train_dl_loss: 0.5152, train_bce_loss: 1.4723, train_bce_dl_loss: 0.5152, step time: 0.1117\n",
      "LOSS train DiceLoss: 0.5647, LOSS train BCE: 1.4772, LOSS train BCE-DiceLoss: 0.5647, LOSS val DiceLoss: 0.6120, LOSS val BCE: 1.4689, LOSS val BCE-DiceLoss: 0.6120, METRIC val: 0.4118\n",
      "time consuming of epoch 74 is: 433.9649\n",
      "----------\n",
      "EPOCH 75/80\n",
      "batch: 0/17, train_dl_loss: 0.5071, train_bce_loss: 1.4613, train_bce_dl_loss: 0.5071, step time: 0.4425\n",
      "batch: 1/17, train_dl_loss: 0.5306, train_bce_loss: 1.4795, train_bce_dl_loss: 0.5306, step time: 0.3825\n",
      "batch: 2/17, train_dl_loss: 0.5579, train_bce_loss: 1.4758, train_bce_dl_loss: 0.5579, step time: 0.4400\n",
      "batch: 3/17, train_dl_loss: 0.6024, train_bce_loss: 1.4659, train_bce_dl_loss: 0.6024, step time: 0.4386\n",
      "batch: 4/17, train_dl_loss: 0.5527, train_bce_loss: 1.4589, train_bce_dl_loss: 0.5527, step time: 0.4318\n",
      "batch: 5/17, train_dl_loss: 0.5419, train_bce_loss: 1.4693, train_bce_dl_loss: 0.5419, step time: 0.3872\n",
      "batch: 6/17, train_dl_loss: 0.5516, train_bce_loss: 1.4764, train_bce_dl_loss: 0.5516, step time: 0.4385\n",
      "batch: 7/17, train_dl_loss: 0.5065, train_bce_loss: 1.4595, train_bce_dl_loss: 0.5065, step time: 0.3874\n",
      "batch: 8/17, train_dl_loss: 0.5432, train_bce_loss: 1.4746, train_bce_dl_loss: 0.5432, step time: 0.4217\n",
      "batch: 9/17, train_dl_loss: 0.5402, train_bce_loss: 1.4821, train_bce_dl_loss: 0.5402, step time: 0.4336\n",
      "batch: 10/17, train_dl_loss: 0.6173, train_bce_loss: 1.4705, train_bce_dl_loss: 0.6173, step time: 0.4445\n",
      "batch: 11/17, train_dl_loss: 0.5107, train_bce_loss: 1.4573, train_bce_dl_loss: 0.5107, step time: 0.4449\n",
      "batch: 12/17, train_dl_loss: 0.5748, train_bce_loss: 1.4653, train_bce_dl_loss: 0.5748, step time: 0.4206\n",
      "batch: 13/17, train_dl_loss: 0.6359, train_bce_loss: 1.4895, train_bce_dl_loss: 0.6359, step time: 0.4281\n",
      "batch: 14/17, train_dl_loss: 0.5303, train_bce_loss: 1.4846, train_bce_dl_loss: 0.5303, step time: 0.4324\n",
      "batch: 15/17, train_dl_loss: 0.5118, train_bce_loss: 1.4801, train_bce_dl_loss: 0.5118, step time: 0.3844\n",
      "batch: 16/17, train_dl_loss: 0.5451, train_bce_loss: 1.4871, train_bce_dl_loss: 0.5451, step time: 0.4171\n",
      "batch: 17/17, train_dl_loss: 0.6789, train_bce_loss: 1.4943, train_bce_dl_loss: 0.6789, step time: 0.1105\n",
      "LOSS train DiceLoss: 0.5577, LOSS train BCE: 1.4740, LOSS train BCE-DiceLoss: 0.5577, LOSS val DiceLoss: 0.6121, LOSS val BCE: 1.4692, LOSS val BCE-DiceLoss: 0.6121, METRIC val: 0.4115\n",
      "time consuming of epoch 75 is: 417.8260\n",
      "----------\n",
      "EPOCH 76/80\n",
      "batch: 0/17, train_dl_loss: 0.5095, train_bce_loss: 1.4587, train_bce_dl_loss: 0.5095, step time: 0.4389\n",
      "batch: 1/17, train_dl_loss: 0.5280, train_bce_loss: 1.4856, train_bce_dl_loss: 0.5280, step time: 0.3776\n",
      "batch: 2/17, train_dl_loss: 0.5740, train_bce_loss: 1.4763, train_bce_dl_loss: 0.5740, step time: 0.4186\n",
      "batch: 3/17, train_dl_loss: 0.6269, train_bce_loss: 1.4637, train_bce_dl_loss: 0.6269, step time: 0.3774\n",
      "batch: 4/17, train_dl_loss: 0.5604, train_bce_loss: 1.4753, train_bce_dl_loss: 0.5604, step time: 0.4275\n",
      "batch: 5/17, train_dl_loss: 0.5299, train_bce_loss: 1.4812, train_bce_dl_loss: 0.5299, step time: 0.3900\n",
      "batch: 6/17, train_dl_loss: 0.5651, train_bce_loss: 1.4780, train_bce_dl_loss: 0.5651, step time: 0.4421\n",
      "batch: 7/17, train_dl_loss: 0.4993, train_bce_loss: 1.4609, train_bce_dl_loss: 0.4993, step time: 0.3842\n",
      "batch: 8/17, train_dl_loss: 0.5080, train_bce_loss: 1.4602, train_bce_dl_loss: 0.5080, step time: 0.4452\n",
      "batch: 9/17, train_dl_loss: 0.5406, train_bce_loss: 1.4746, train_bce_dl_loss: 0.5406, step time: 0.3886\n",
      "batch: 10/17, train_dl_loss: 0.6124, train_bce_loss: 1.4696, train_bce_dl_loss: 0.6124, step time: 0.4439\n",
      "batch: 11/17, train_dl_loss: 0.5441, train_bce_loss: 1.4807, train_bce_dl_loss: 0.5441, step time: 0.3889\n",
      "batch: 12/17, train_dl_loss: 0.5868, train_bce_loss: 1.4665, train_bce_dl_loss: 0.5868, step time: 0.4478\n",
      "batch: 13/17, train_dl_loss: 0.6726, train_bce_loss: 1.4832, train_bce_dl_loss: 0.6726, step time: 0.3877\n",
      "batch: 14/17, train_dl_loss: 0.5208, train_bce_loss: 1.4842, train_bce_dl_loss: 0.5208, step time: 0.4229\n",
      "batch: 15/17, train_dl_loss: 0.5374, train_bce_loss: 1.4837, train_bce_dl_loss: 0.5374, step time: 0.3776\n",
      "batch: 16/17, train_dl_loss: 0.5173, train_bce_loss: 1.4701, train_bce_dl_loss: 0.5173, step time: 0.4252\n",
      "batch: 17/17, train_dl_loss: 0.4637, train_bce_loss: 1.4840, train_bce_dl_loss: 0.4637, step time: 0.1126\n",
      "LOSS train DiceLoss: 0.5498, LOSS train BCE: 1.4743, LOSS train BCE-DiceLoss: 0.5498, LOSS val DiceLoss: 0.6121, LOSS val BCE: 1.4694, LOSS val BCE-DiceLoss: 0.6121, METRIC val: 0.4117\n",
      "time consuming of epoch 76 is: 449.5552\n",
      "----------\n",
      "EPOCH 77/80\n",
      "batch: 0/17, train_dl_loss: 0.5523, train_bce_loss: 1.4624, train_bce_dl_loss: 0.5523, step time: 0.4230\n",
      "batch: 1/17, train_dl_loss: 0.5534, train_bce_loss: 1.4947, train_bce_dl_loss: 0.5534, step time: 0.4390\n",
      "batch: 2/17, train_dl_loss: 0.5751, train_bce_loss: 1.4676, train_bce_dl_loss: 0.5751, step time: 0.4357\n",
      "batch: 3/17, train_dl_loss: 0.6007, train_bce_loss: 1.4733, train_bce_dl_loss: 0.6007, step time: 0.4388\n",
      "batch: 4/17, train_dl_loss: 0.5050, train_bce_loss: 1.4611, train_bce_dl_loss: 0.5050, step time: 0.4343\n",
      "batch: 5/17, train_dl_loss: 0.5630, train_bce_loss: 1.4644, train_bce_dl_loss: 0.5630, step time: 0.4410\n",
      "batch: 6/17, train_dl_loss: 0.5778, train_bce_loss: 1.4864, train_bce_dl_loss: 0.5778, step time: 0.4163\n",
      "batch: 7/17, train_dl_loss: 0.4922, train_bce_loss: 1.4675, train_bce_dl_loss: 0.4922, step time: 0.4307\n",
      "batch: 8/17, train_dl_loss: 0.5258, train_bce_loss: 1.4508, train_bce_dl_loss: 0.5258, step time: 0.4340\n",
      "batch: 9/17, train_dl_loss: 0.6075, train_bce_loss: 1.4832, train_bce_dl_loss: 0.6075, step time: 0.4284\n",
      "batch: 10/17, train_dl_loss: 0.5969, train_bce_loss: 1.4803, train_bce_dl_loss: 0.5969, step time: 0.4273\n",
      "batch: 11/17, train_dl_loss: 0.5224, train_bce_loss: 1.4677, train_bce_dl_loss: 0.5224, step time: 0.4336\n",
      "batch: 12/17, train_dl_loss: 0.5474, train_bce_loss: 1.4688, train_bce_dl_loss: 0.5474, step time: 0.4261\n",
      "batch: 13/17, train_dl_loss: 0.6527, train_bce_loss: 1.4815, train_bce_dl_loss: 0.6527, step time: 0.4373\n",
      "batch: 14/17, train_dl_loss: 0.5506, train_bce_loss: 1.4851, train_bce_dl_loss: 0.5506, step time: 0.4358\n",
      "batch: 15/17, train_dl_loss: 0.5206, train_bce_loss: 1.4792, train_bce_dl_loss: 0.5206, step time: 0.4326\n",
      "batch: 16/17, train_dl_loss: 0.5163, train_bce_loss: 1.4745, train_bce_dl_loss: 0.5163, step time: 0.4257\n",
      "batch: 17/17, train_dl_loss: 0.5152, train_bce_loss: 1.4724, train_bce_dl_loss: 0.5152, step time: 0.1119\n",
      "LOSS train DiceLoss: 0.5542, LOSS train BCE: 1.4734, LOSS train BCE-DiceLoss: 0.5542, LOSS val DiceLoss: 0.6121, LOSS val BCE: 1.4694, LOSS val BCE-DiceLoss: 0.6121, METRIC val: 0.4116\n",
      "time consuming of epoch 77 is: 479.7450\n",
      "----------\n",
      "EPOCH 78/80\n",
      "batch: 0/17, train_dl_loss: 0.5065, train_bce_loss: 1.4602, train_bce_dl_loss: 0.5065, step time: 0.4217\n",
      "batch: 1/17, train_dl_loss: 0.5258, train_bce_loss: 1.4782, train_bce_dl_loss: 0.5258, step time: 0.3759\n",
      "batch: 2/17, train_dl_loss: 0.6186, train_bce_loss: 1.4786, train_bce_dl_loss: 0.6186, step time: 0.4245\n",
      "batch: 3/17, train_dl_loss: 0.5671, train_bce_loss: 1.4836, train_bce_dl_loss: 0.5671, step time: 0.3737\n",
      "batch: 4/17, train_dl_loss: 0.5076, train_bce_loss: 1.4811, train_bce_dl_loss: 0.5076, step time: 0.4170\n",
      "batch: 5/17, train_dl_loss: 0.5279, train_bce_loss: 1.4691, train_bce_dl_loss: 0.5279, step time: 0.3880\n",
      "batch: 6/17, train_dl_loss: 0.5584, train_bce_loss: 1.4866, train_bce_dl_loss: 0.5584, step time: 0.4225\n",
      "batch: 7/17, train_dl_loss: 0.5402, train_bce_loss: 1.4572, train_bce_dl_loss: 0.5402, step time: 0.3809\n",
      "batch: 8/17, train_dl_loss: 0.5605, train_bce_loss: 1.4781, train_bce_dl_loss: 0.5605, step time: 0.4463\n",
      "batch: 9/17, train_dl_loss: 0.5502, train_bce_loss: 1.4762, train_bce_dl_loss: 0.5502, step time: 0.4654\n",
      "batch: 10/17, train_dl_loss: 0.6343, train_bce_loss: 1.4813, train_bce_dl_loss: 0.6343, step time: 0.4423\n",
      "batch: 11/17, train_dl_loss: 0.4918, train_bce_loss: 1.4628, train_bce_dl_loss: 0.4918, step time: 0.3811\n",
      "batch: 12/17, train_dl_loss: 0.5181, train_bce_loss: 1.4639, train_bce_dl_loss: 0.5181, step time: 0.4142\n",
      "batch: 13/17, train_dl_loss: 0.6447, train_bce_loss: 1.4906, train_bce_dl_loss: 0.6447, step time: 0.3703\n",
      "batch: 14/17, train_dl_loss: 0.5172, train_bce_loss: 1.4801, train_bce_dl_loss: 0.5172, step time: 0.4280\n",
      "batch: 15/17, train_dl_loss: 0.5169, train_bce_loss: 1.4839, train_bce_dl_loss: 0.5169, step time: 0.3795\n",
      "batch: 16/17, train_dl_loss: 0.5153, train_bce_loss: 1.4779, train_bce_dl_loss: 0.5153, step time: 0.4161\n",
      "batch: 17/17, train_dl_loss: 0.4971, train_bce_loss: 1.4859, train_bce_dl_loss: 0.4971, step time: 0.1128\n",
      "LOSS train DiceLoss: 0.5444, LOSS train BCE: 1.4764, LOSS train BCE-DiceLoss: 0.5444, LOSS val DiceLoss: 0.6122, LOSS val BCE: 1.4694, LOSS val BCE-DiceLoss: 0.6122, METRIC val: 0.4115\n",
      "time consuming of epoch 78 is: 468.1049\n",
      "----------\n",
      "EPOCH 79/80\n",
      "batch: 0/17, train_dl_loss: 0.5074, train_bce_loss: 1.4675, train_bce_dl_loss: 0.5074, step time: 0.4276\n",
      "batch: 1/17, train_dl_loss: 0.5525, train_bce_loss: 1.4825, train_bce_dl_loss: 0.5525, step time: 0.3793\n",
      "batch: 2/17, train_dl_loss: 0.5607, train_bce_loss: 1.4791, train_bce_dl_loss: 0.5607, step time: 0.4400\n",
      "batch: 3/17, train_dl_loss: 0.6217, train_bce_loss: 1.4745, train_bce_dl_loss: 0.6217, step time: 0.3784\n",
      "batch: 4/17, train_dl_loss: 0.5019, train_bce_loss: 1.4703, train_bce_dl_loss: 0.5019, step time: 0.4265\n",
      "batch: 5/17, train_dl_loss: 0.5026, train_bce_loss: 1.4666, train_bce_dl_loss: 0.5026, step time: 0.3849\n",
      "batch: 6/17, train_dl_loss: 0.5759, train_bce_loss: 1.4750, train_bce_dl_loss: 0.5759, step time: 0.4446\n",
      "batch: 7/17, train_dl_loss: 0.5381, train_bce_loss: 1.4789, train_bce_dl_loss: 0.5381, step time: 0.3816\n",
      "batch: 8/17, train_dl_loss: 0.4999, train_bce_loss: 1.4789, train_bce_dl_loss: 0.4999, step time: 0.4362\n",
      "batch: 9/17, train_dl_loss: 0.5490, train_bce_loss: 1.4857, train_bce_dl_loss: 0.5490, step time: 0.3858\n",
      "batch: 10/17, train_dl_loss: 0.5865, train_bce_loss: 1.4694, train_bce_dl_loss: 0.5865, step time: 0.4325\n",
      "batch: 11/17, train_dl_loss: 0.5920, train_bce_loss: 1.4890, train_bce_dl_loss: 0.5920, step time: 0.4439\n",
      "batch: 12/17, train_dl_loss: 0.5661, train_bce_loss: 1.4682, train_bce_dl_loss: 0.5661, step time: 0.4243\n",
      "batch: 13/17, train_dl_loss: 0.6090, train_bce_loss: 1.4826, train_bce_dl_loss: 0.6090, step time: 0.3861\n",
      "batch: 14/17, train_dl_loss: 0.5552, train_bce_loss: 1.4965, train_bce_dl_loss: 0.5552, step time: 0.4438\n",
      "batch: 15/17, train_dl_loss: 0.5152, train_bce_loss: 1.4742, train_bce_dl_loss: 0.5152, step time: 0.4254\n",
      "batch: 16/17, train_dl_loss: 0.5166, train_bce_loss: 1.4856, train_bce_dl_loss: 0.5166, step time: 0.4143\n",
      "batch: 17/17, train_dl_loss: 0.5190, train_bce_loss: 1.4744, train_bce_dl_loss: 0.5190, step time: 0.1114\n",
      "LOSS train DiceLoss: 0.5483, LOSS train BCE: 1.4777, LOSS train BCE-DiceLoss: 0.5483, LOSS val DiceLoss: 0.6122, LOSS val BCE: 1.4694, LOSS val BCE-DiceLoss: 0.6122, METRIC val: 0.4115\n",
      "time consuming of epoch 79 is: 444.2817\n",
      "----------\n",
      "EPOCH 80/80\n",
      "batch: 0/17, train_dl_loss: 0.5394, train_bce_loss: 1.4726, train_bce_dl_loss: 0.5394, step time: 0.4430\n",
      "batch: 1/17, train_dl_loss: 0.5817, train_bce_loss: 1.4939, train_bce_dl_loss: 0.5817, step time: 0.3793\n",
      "batch: 2/17, train_dl_loss: 0.5435, train_bce_loss: 1.4702, train_bce_dl_loss: 0.5435, step time: 0.4380\n",
      "batch: 3/17, train_dl_loss: 0.6366, train_bce_loss: 1.4830, train_bce_dl_loss: 0.6366, step time: 0.3826\n",
      "batch: 4/17, train_dl_loss: 0.4972, train_bce_loss: 1.4676, train_bce_dl_loss: 0.4972, step time: 0.4378\n",
      "batch: 5/17, train_dl_loss: 0.5020, train_bce_loss: 1.4837, train_bce_dl_loss: 0.5020, step time: 0.4041\n",
      "batch: 6/17, train_dl_loss: 0.5740, train_bce_loss: 1.4876, train_bce_dl_loss: 0.5740, step time: 0.4349\n",
      "batch: 7/17, train_dl_loss: 0.5185, train_bce_loss: 1.4621, train_bce_dl_loss: 0.5185, step time: 0.3790\n",
      "batch: 8/17, train_dl_loss: 0.5283, train_bce_loss: 1.4656, train_bce_dl_loss: 0.5283, step time: 0.4270\n",
      "batch: 9/17, train_dl_loss: 0.5039, train_bce_loss: 1.4767, train_bce_dl_loss: 0.5039, step time: 0.4401\n",
      "batch: 10/17, train_dl_loss: 0.6055, train_bce_loss: 1.4757, train_bce_dl_loss: 0.6055, step time: 0.4260\n",
      "batch: 11/17, train_dl_loss: 0.5216, train_bce_loss: 1.4662, train_bce_dl_loss: 0.5216, step time: 0.4424\n",
      "batch: 12/17, train_dl_loss: 0.6311, train_bce_loss: 1.4928, train_bce_dl_loss: 0.6311, step time: 0.4350\n",
      "batch: 13/17, train_dl_loss: 0.6236, train_bce_loss: 1.4877, train_bce_dl_loss: 0.6236, step time: 0.3881\n",
      "batch: 14/17, train_dl_loss: 0.5400, train_bce_loss: 1.4824, train_bce_dl_loss: 0.5400, step time: 0.4351\n",
      "batch: 15/17, train_dl_loss: 0.5185, train_bce_loss: 1.4734, train_bce_dl_loss: 0.5185, step time: 0.3820\n",
      "batch: 16/17, train_dl_loss: 0.5451, train_bce_loss: 1.4820, train_bce_dl_loss: 0.5451, step time: 0.4228\n",
      "batch: 17/17, train_dl_loss: 0.5151, train_bce_loss: 1.4729, train_bce_dl_loss: 0.5151, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.5514, LOSS train BCE: 1.4776, LOSS train BCE-DiceLoss: 0.5514, LOSS val DiceLoss: 0.6122, LOSS val BCE: 1.4694, LOSS val BCE-DiceLoss: 0.6122, METRIC val: 0.4115\n",
      "time consuming of epoch 80 is: 446.1662\n"
     ]
    }
   ],
   "source": [
    "train_loop(model=unet_model,\n",
    "           train_loader=train_loader,\n",
    "           val_loader=val_loader,\n",
    "           diceloss_function=dice_loss_fn,\n",
    "           bce_function=bce_loss_fn,\n",
    "           bce_diceloss_function=criterion,\n",
    "           metric=dice_metric,\n",
    "           optimizer=optimizer,\n",
    "           lr_scheduler=lr_scheduler,\n",
    "           config=config,\n",
    "           output_dir=OUTPUT_DIR,\n",
    "           output_file=OUTPUT_FILE,\n",
    "           device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc13cc",
   "metadata": {
    "papermill": {
     "duration": 0.12257,
     "end_time": "2024-08-31T00:04:09.429057",
     "exception": false,
     "start_time": "2024-08-31T00:04:09.306487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plot Training/Validation Losses & Validation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37bc2068",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-31T00:04:09.676989Z",
     "iopub.status.busy": "2024-08-31T00:04:09.676209Z",
     "iopub.status.idle": "2024-08-31T00:04:10.506358Z",
     "shell.execute_reply": "2024-08-31T00:04:10.505380Z"
    },
    "papermill": {
     "duration": 0.957927,
     "end_time": "2024-08-31T00:04:10.508505",
     "exception": false,
     "start_time": "2024-08-31T00:04:09.550578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load txt file\n",
    "path = f\"/kaggle/working/{config['ID']}_train_val_losses.csv\"\n",
    "train_val_losses = pd.read_csv(path)\n",
    "\n",
    "# Plot and Save Train & Val Losses as png in output dir\n",
    "training_plot(train_val_losses, OUTPUT_DIR, config)\n",
    "\n",
    "# Plot and Save Val Metric as png in output dir\n",
    "validation_metric_plot(train_val_losses, OUTPUT_DIR, config)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 4050810,
     "sourceId": 36363,
     "sourceType": "competition"
    },
    {
     "datasetId": 5021316,
     "sourceId": 8604320,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5115113,
     "sourceId": 8620534,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35921.023554,
   "end_time": "2024-08-31T00:04:14.322908",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-30T14:05:33.299354",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
