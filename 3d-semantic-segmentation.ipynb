{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b337b51",
   "metadata": {
    "papermill": {
     "duration": 0.009268,
     "end_time": "2024-08-27T12:27:27.057617",
     "exception": false,
     "start_time": "2024-08-27T12:27:27.048349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3D Cervical Vertebrae Segmentation (RSNA 2022) with MONAI\n",
    "\n",
    "---\n",
    "\n",
    "The aim of this notebook is to perform 3D semantic segmentation on CT scan provided by Radiological Society of North America during the past kaggle's competition RSNA 2022 targeting cervical vertebrae.\n",
    "\n",
    "We will explit [MONAI](https://monai.io/) library to import 3D UNet Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e031ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:27:27.076895Z",
     "iopub.status.busy": "2024-08-27T12:27:27.076211Z",
     "iopub.status.idle": "2024-08-27T12:28:20.407069Z",
     "shell.execute_reply": "2024-08-27T12:28:20.405893Z"
    },
    "papermill": {
     "duration": 53.343155,
     "end_time": "2024-08-27T12:28:20.409500",
     "exception": false,
     "start_time": "2024-08-27T12:27:27.066345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-gdcm\r\n",
      "  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\r\n",
      "Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: python-gdcm\r\n",
      "Successfully installed python-gdcm-3.0.24.1\r\n",
      "Collecting pylibjpeg\r\n",
      "  Downloading pylibjpeg-2.0.1-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting pylibjpeg-libjpeg\r\n",
      "  Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\r\n",
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.10/site-packages (2.4.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pylibjpeg) (1.26.4)\r\n",
      "Downloading pylibjpeg-2.0.1-py3-none-any.whl (24 kB)\r\n",
      "Downloading pylibjpeg_libjpeg-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pylibjpeg-libjpeg, pylibjpeg\r\n",
      "Successfully installed pylibjpeg-2.0.1 pylibjpeg-libjpeg-2.2.0\r\n",
      "Collecting pyjpegls\r\n",
      "  Downloading pyjpegls-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\r\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.10/site-packages (from pyjpegls) (1.26.4)\r\n",
      "Downloading pyjpegls-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: pyjpegls\r\n",
      "Successfully installed pyjpegls-1.4.0\r\n",
      "Collecting monai\r\n",
      "  Downloading monai-1.3.2-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.1.2)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\r\n",
      "Downloading monai-1.3.2-py3-none-any.whl (1.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\r\n",
      "\u001b[0mInstalling collected packages: monai\r\n",
      "Successfully installed monai-1.3.2\r\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "! pip install python-gdcm\n",
    "! pip install pylibjpeg pylibjpeg-libjpeg pydicom\n",
    "! pip install pyjpegls\n",
    "! pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5633dea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:28:20.435113Z",
     "iopub.status.busy": "2024-08-27T12:28:20.434784Z",
     "iopub.status.idle": "2024-08-27T12:29:02.021092Z",
     "shell.execute_reply": "2024-08-27T12:29:02.020081Z"
    },
    "papermill": {
     "duration": 41.601833,
     "end_time": "2024-08-27T12:29:02.023624",
     "exception": false,
     "start_time": "2024-08-27T12:28:20.421791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-27 12:28:53.048156: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-27 12:28:53.048294: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-27 12:28:53.171401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import warnings\n",
    "from glob import glob\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "# DICOM image files (.dcm)\n",
    "import pydicom\n",
    "from pydicom import dcmread\n",
    "\n",
    "# NIfTI image files (.nii)\n",
    "import nibabel as nib\n",
    "\n",
    "# Required dependencies\n",
    "import gdcm\n",
    "import pylibjpeg\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "# Monai\n",
    "import monai\n",
    "from monai.data import ArrayDataset, DataLoader, decollate_batch\n",
    "from monai.networks.layers import Norm\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    Resize,\n",
    "    ScaleIntensity,\n",
    "    RandFlip,\n",
    "    RandAffine,\n",
    "    RandGridDistortion\n",
    ")\n",
    "from monai.utils import set_determinism, first\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc9ed7",
   "metadata": {
    "papermill": {
     "duration": 0.011575,
     "end_time": "2024-08-27T12:29:02.048794",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.037219",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Set Up & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4a5df9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.073796Z",
     "iopub.status.busy": "2024-08-27T12:29:02.073110Z",
     "iopub.status.idle": "2024-08-27T12:29:02.080478Z",
     "shell.execute_reply": "2024-08-27T12:29:02.079629Z"
    },
    "papermill": {
     "duration": 0.022349,
     "end_time": "2024-08-27T12:29:02.082800",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.060451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KY9504FK\n"
     ]
    }
   ],
   "source": [
    "def generate_id():\n",
    "    '''\n",
    "    Generate Notebook ID\n",
    "    '''\n",
    "    letters = string.ascii_uppercase  # Uppercase letters A-Z\n",
    "    digits = string.digits  # Digits 0-9\n",
    "    start_letters = ''.join(random.choice(letters) for _ in range(2))\n",
    "    middle_digits = ''.join(random.choice(digits) for _ in range(4))\n",
    "    end_letters = ''.join(random.choice(letters) for _ in range(2))\n",
    "    id_number = start_letters + middle_digits + end_letters\n",
    "    return id_number\n",
    "\n",
    "# Generate Notebook ID\n",
    "ID = generate_id()\n",
    "print(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9812f87d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.107454Z",
     "iopub.status.busy": "2024-08-27T12:29:02.107205Z",
     "iopub.status.idle": "2024-08-27T12:29:02.112969Z",
     "shell.execute_reply": "2024-08-27T12:29:02.112319Z"
    },
    "papermill": {
     "duration": 0.020408,
     "end_time": "2024-08-27T12:29:02.115161",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.094753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set deterministic training for reproducibility\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2356fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.140050Z",
     "iopub.status.busy": "2024-08-27T12:29:02.139787Z",
     "iopub.status.idle": "2024-08-27T12:29:02.147261Z",
     "shell.execute_reply": "2024-08-27T12:29:02.146411Z"
    },
    "papermill": {
     "duration": 0.02211,
     "end_time": "2024-08-27T12:29:02.149128",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.127018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Paths\n",
    "base_path = \"../input/rsna-2022-cervical-spine-fracture-detection\"\n",
    "TRAIN_IMAGES_PATH = f'{base_path}/train_images'\n",
    "SEGMENTATIONS_PATH = f'{base_path}/segmentations'\n",
    "OUTPUT_DIR = '.'\n",
    "OUTPUT_FILE = OUTPUT_DIR + f'/{ID}_train_val_losses.csv'\n",
    "CONFIG_FILE = OUTPUT_DIR + f'/{ID}_config.pkl'\n",
    "\n",
    "# Masks to be reverted \n",
    "revert_mask = [\n",
    "    '1.2.826.0.1.3680043.1363',\n",
    "    '1.2.826.0.1.3680043.20120',\n",
    "    '1.2.826.0.1.3680043.2243',\n",
    "    '1.2.826.0.1.3680043.24606',\n",
    "    '1.2.826.0.1.3680043.32071'\n",
    "    ]\n",
    "\n",
    "\n",
    "# Dictionary to store configuration of training and model architecture\n",
    "config = {\n",
    "    'ID' : ID,\n",
    "    # Data Preprocessing params\n",
    "    'spatial_size' : (128, 128, 128), # Target spatial size of the volume (CT scan & segmentation masks)\n",
    "    'prob' : 0.5, # Probability of applying the augmentation technique\n",
    "    'k' : 5, # Number of folders for K-fold\n",
    "     # Training Params\n",
    "    'batch_size' : 4, \n",
    "    'epochs' : 80, \n",
    "    'lr' : 1e-4,\n",
    "    'loss_weights' : (0.0, 1.0),\n",
    "    # Model Architecture Params\n",
    "    'channels' : (16, 32, 64, 128, 256), # Channels per layer\n",
    "    'strides' : (2, 2, 2, 2), # Stride per layers\n",
    "    'kernel_size' : 3, # Size of the kernel for each layer\n",
    "    'up_kernel_size' : 3,\n",
    "    'num_res_units' : 2, # Number of residual units\n",
    "    'act' : 'PRELU', # Activation function\n",
    "    'dropout' : 0.0, # Dropout rate #0.2\n",
    "    'bias' : True,\n",
    "    # K-Fold\n",
    "    'val_fold_idx' : 1 # Validation index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b886e2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.174136Z",
     "iopub.status.busy": "2024-08-27T12:29:02.173359Z",
     "iopub.status.idle": "2024-08-27T12:29:02.279129Z",
     "shell.execute_reply": "2024-08-27T12:29:02.278080Z"
    },
    "papermill": {
     "duration": 0.120298,
     "end_time": "2024-08-27T12:29:02.281188",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.160890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla T4 is available.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Enabling GPU\n",
    "# https://www.kaggle.com/dansbecker/running-kaggle-kernels-with-a-gpu\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "    \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# Enable cuDNN benchmark. Set to True whenever the input model does not change over training, False if, eg, some layers are deactivated\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6611f9eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.306517Z",
     "iopub.status.busy": "2024-08-27T12:29:02.306212Z",
     "iopub.status.idle": "2024-08-27T12:29:02.310815Z",
     "shell.execute_reply": "2024-08-27T12:29:02.309937Z"
    },
    "papermill": {
     "duration": 0.019497,
     "end_time": "2024-08-27T12:29:02.312807",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.293310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save config to pickle file\n",
    "with open(CONFIG_FILE, 'wb') as f:\n",
    "    pickle.dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc56652",
   "metadata": {
    "papermill": {
     "duration": 0.011715,
     "end_time": "2024-08-27T12:29:02.336325",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.324610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "638be5f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.361246Z",
     "iopub.status.busy": "2024-08-27T12:29:02.361003Z",
     "iopub.status.idle": "2024-08-27T12:29:02.698375Z",
     "shell.execute_reply": "2024-08-27T12:29:02.697430Z"
    },
    "papermill": {
     "duration": 0.352217,
     "end_time": "2024-08-27T12:29:02.700381",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.348164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dicom_scan(folder_path):\n",
    "    \"\"\" Read CT scan (dicom files) and stack the slices\"\"\"\n",
    "    slices = []\n",
    "    for filename in sorted(os.listdir(folder_path), key=lambda x: int(x.split(\".\")[0])):\n",
    "        if filename.endswith('.dcm'):\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "            ds = pydicom.dcmread(filepath)\n",
    "            slices.append(ds.pixel_array)\n",
    "    scan = np.stack(slices, -1).astype('float64')\n",
    "    return scan\n",
    "\n",
    "\n",
    "def read_nifti_file(file_path, revert_mask=revert_mask):\n",
    "    \"\"\" Read nifit file segmentation\"\"\"    \n",
    "    data = nib.load(file_path).get_fdata()\n",
    "    shape = data.shape\n",
    "    # Reorient because segmentations are done over the sagittal plane\n",
    "    data = data.transpose(1, 0, 2)[::-1, :, ::-1]\n",
    "    # Revert the files that have inverted sequence (from bottom to top)\n",
    "    if file_path in revert_mask:\n",
    "        data[:, :, ::-1]\n",
    "    return data\n",
    "\n",
    "\n",
    "def zoom_volume(vol, spatial_size):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    \"\"\" NON UTILIZZATA SOSTITUITA DA RESIZE\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_width, desired_height, desired_depth = spatial_size\n",
    "    # Get current depth\n",
    "    current_depth = vol.shape[-1]\n",
    "    current_width = vol.shape[0]\n",
    "    current_height = vol.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Resize across z-axis\n",
    "    #vol = ndi.zoom(vol, (width_factor, height_factor, depth_factor), order=0, mode='constant')\n",
    "    zoom_transform = Zoom(zoom=(width_factor, height_factor, depth_factor), keep_size=False)\n",
    "    zoom_vol = zoom_transform(vol)\n",
    "    return zoom_vol\n",
    "\n",
    "def one_hot_encoding_multiclass_mask(mask):\n",
    "    \"\"\" Binary OneHot Encoding of Multi-class masks\"\"\"\n",
    "    labels = list(range(8))\n",
    "    num_labels = len(labels)\n",
    "    c, h, w, d = mask.shape\n",
    "    enc_mask = np.zeros((num_labels, h, w, d))\n",
    "    for c in range(1, num_labels):  # this loop starts from label 1 to ignore background 0\n",
    "        enc_mask[c, :, :, :] = (mask == labels[c]) # 1 for the pixel belonging to that class, 0 for the rest of the pixel\n",
    "        \n",
    "    return enc_mask\n",
    "\n",
    "def expand_dims(arr):\n",
    "    return np.expand_dims(arr, axis=0)\n",
    "\n",
    "\n",
    "def training_plot(file, output_path, config):\n",
    "    train_bce_dl_loss = file['Train_bce_dl_loss']\n",
    "    val_bce_dl_loss = file['Val_bce_dl_loss']\n",
    "    epochs = range(1, len(train_bce_dl_loss) + 1)\n",
    "    plt.plot(epochs, train_bce_dl_loss, label='Training BCE-DiceLoss', color='darkblue')\n",
    "    plt.plot(epochs, val_bce_dl_loss, label='Val BCE-DiceLoss', color='darkorange')\n",
    "    plt.title('Training & Val Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_path, f'{config[\"ID\"]}_Training_Losses_plot.png'))\n",
    "    plt.show()\n",
    "    \n",
    "def validation_metric_plot(file, output_path, config):\n",
    "    val_metric = file['Val_metric']\n",
    "    epochs = range(1, len(val_metric)+1)\n",
    "    plt.plot(epochs, val_metric, label='Validation DiceMetric', color='red')\n",
    "    plt.title('Validation Metric')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(False)\n",
    "    plt.savefig(os.path.join(output_path, f'{config[\"ID\"]}_Validation_Metric_plot.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72b25d",
   "metadata": {
    "papermill": {
     "duration": 0.011712,
     "end_time": "2024-08-27T12:29:02.724337",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.712625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "In this section we will build the dataset (pandas dataframe) starting from the input data. The df has 4 columns:\n",
    "\n",
    "* **ID** : identification number of the patient\n",
    "* **label_path**: complete path of the segmentation mask\n",
    "* **image_path**: complete path of the CT scan\n",
    "* **fold**: index of the folder for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c15282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.749351Z",
     "iopub.status.busy": "2024-08-27T12:29:02.749050Z",
     "iopub.status.idle": "2024-08-27T12:29:02.807341Z",
     "shell.execute_reply": "2024-08-27T12:29:02.806445Z"
    },
    "papermill": {
     "duration": 0.0731,
     "end_time": "2024-08-27T12:29:02.809394",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.736294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label_path</th>\n",
       "      <th>image_path</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.780</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.21321</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.6125</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.30067</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.12833</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ID  \\\n",
       "0    1.2.826.0.1.3680043.780   \n",
       "1  1.2.826.0.1.3680043.21321   \n",
       "2   1.2.826.0.1.3680043.6125   \n",
       "3  1.2.826.0.1.3680043.30067   \n",
       "4  1.2.826.0.1.3680043.12833   \n",
       "\n",
       "                                          label_path  \\\n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "3  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "4  ../input/rsna-2022-cervical-spine-fracture-det...   \n",
       "\n",
       "                                          image_path  fold  \n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...     0  \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...     4  \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...     4  \n",
       "3  ../input/rsna-2022-cervical-spine-fracture-det...     2  \n",
       "4  ../input/rsna-2022-cervical-spine-fracture-det...     0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataset\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Store all the nifti files in the segmentation folder\n",
    "df['ID'] = os.listdir(SEGMENTATIONS_PATH)\n",
    "\n",
    "# Remove the extension '.nii'\n",
    "df['ID'] = df['ID'].apply(lambda x: x[:-4])\n",
    "\n",
    "# Add complete path to reach segmentation file (nifti)\n",
    "df['label_path'] = df['ID'].apply(lambda x: os.path.join(SEGMENTATIONS_PATH, x + '.nii'))\n",
    "\n",
    "# Add complete path to reach CT scan folder in train_images\n",
    "df['image_path'] = df['ID'].apply(lambda x: os.path.join(TRAIN_IMAGES_PATH, x))\n",
    "\n",
    "# Initialize KFold\n",
    "kf = KFold(n_splits=config['k'], shuffle=True, random_state=42)\n",
    "\n",
    "# Create a new column for fold indices\n",
    "df['fold'] = -1\n",
    "\n",
    "# Assign fold indices\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(df)):\n",
    "    df.loc[val_index, 'fold'] = fold\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(df.shape)\n",
    "\n",
    "# Show the head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2268a376",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.835163Z",
     "iopub.status.busy": "2024-08-27T12:29:02.834902Z",
     "iopub.status.idle": "2024-08-27T12:29:02.848012Z",
     "shell.execute_reply": "2024-08-27T12:29:02.846940Z"
    },
    "papermill": {
     "duration": 0.028141,
     "end_time": "2024-08-27T12:29:02.849959",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.821818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 5)\n",
      "(18, 5)\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation dataset\n",
    "\n",
    "val_fold_idx = config['val_fold_idx']\n",
    "\n",
    "df_train = df[df.fold != val_fold_idx].reset_index()\n",
    "print(df_train.shape)\n",
    "\n",
    "df_val = df[df.fold == val_fold_idx].reset_index()\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a7960",
   "metadata": {
    "papermill": {
     "duration": 0.012068,
     "end_time": "2024-08-27T12:29:02.874115",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.862047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transforms\n",
    "\n",
    "In this section we will define the transformation (MONAI) to be applied to both images (CT scan) and segmentation masks. The transforms pipeline are constituted by:\n",
    "\n",
    "**Load Data**. The image and label loading, `read_dicom_scan` and `read_nifti_file` respectively, load and preprocess volumetric data from DICOM and NIfTI formats, ensuring proper orientation and stacking for 3D analysis.\n",
    "\n",
    "**Data Preparation**. It includes expanding dimensions (`expand_dims`), resizing the volumes (`Resize`) to a target spatial size (128, 128, 128) ensuring that all inputs to the model have the same dimensions, scaling intensity (`ScaleIntensity`) for images, and applying one-hot encoding for multi-class masks (`one_hot_encoding_multiclass_mask`) for labels, standardizing the data for model input.\n",
    "\n",
    "**Data Augmentation**. To increase the model's generalization we introduce variability in the training data by using image augmentation techniques such as:\n",
    "* `RandFlip`: Randomly flips the input images and masks along specified axes (width and height) with a probability of 0.5, helping the model become invariant to orientation changes\n",
    "* `RandGridDistortion`: Applies random grid distortion with 5 cells and a distortion limit of (-0.03, 0.03), warping the image grid to simulate deformations and enhance robustness to spatial variations\n",
    "* `RandAffine`: Applies random affine transformations with a probability of 0.5, allowing translations up to 30% of the image size in each dimension, simulating patient movement or slight positioning changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0efd37cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.899673Z",
     "iopub.status.busy": "2024-08-27T12:29:02.899364Z",
     "iopub.status.idle": "2024-08-27T12:29:02.926089Z",
     "shell.execute_reply": "2024-08-27T12:29:02.925172Z"
    },
    "papermill": {
     "duration": 0.041991,
     "end_time": "2024-08-27T12:29:02.928147",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.886156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training transforms for image and label\n",
    "train_image_trans = Compose(\n",
    "    [   \n",
    "        # Load Data\n",
    "        read_dicom_scan,\n",
    "        # Data Preparation\n",
    "        expand_dims, \n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"), # Resize the volume to target spatial_size\n",
    "        ScaleIntensity(), # scale between (0,1)\n",
    "        # Data Augmentation \n",
    "        RandFlip(prob=config['prob'], spatial_axis=0), # width\n",
    "        RandFlip(prob=config['prob'], spatial_axis=1), # height\n",
    "        RandGridDistortion(num_cells=5, distort_limit=(-0.03, 0.03), prob=config['prob']),\n",
    "        RandAffine(prob=config['prob'], \n",
    "                   translate_range=[int(x*y) for x, y in zip(config['spatial_size'], [0.3, 0.3, 0.3])], padding_mode='zeros')\n",
    "    ]\n",
    ")\n",
    "train_label_trans = Compose(\n",
    "    [   \n",
    "        # Load data\n",
    "        read_nifti_file,\n",
    "        # Data Preparation\n",
    "        expand_dims,\n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"),\n",
    "        one_hot_encoding_multiclass_mask, \n",
    "        # Data Augmentation\n",
    "        RandFlip(prob=config['prob'], spatial_axis=0), # width\n",
    "        RandFlip(prob=config['prob'], spatial_axis=1), # height\n",
    "        RandGridDistortion(num_cells=5, distort_limit=(-0.03, 0.03), prob=config['prob']),\n",
    "        RandAffine(prob=config['prob'], \n",
    "                   translate_range=[int(x*y) for x, y in zip(config['spatial_size'], [0.3, 0.3, 0.3])], padding_mode='zeros')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define validation transforms for image and label (no augmentation)\n",
    "val_image_trans = Compose(\n",
    "    [\n",
    "        # Load data\n",
    "        read_dicom_scan,\n",
    "        # Data Preparation\n",
    "        expand_dims,\n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"), \n",
    "        ScaleIntensity()\n",
    "    ]\n",
    ")\n",
    "val_label_trans = Compose(\n",
    "    [\n",
    "        # Load data\n",
    "        read_nifti_file,\n",
    "        # Data preparation\n",
    "        expand_dims,\n",
    "        Resize(spatial_size=config['spatial_size'], mode=\"area\"),\n",
    "        one_hot_encoding_multiclass_mask\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492599f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.953393Z",
     "iopub.status.busy": "2024-08-27T12:29:02.953129Z",
     "iopub.status.idle": "2024-08-27T12:29:02.959674Z",
     "shell.execute_reply": "2024-08-27T12:29:02.958846Z"
    },
    "papermill": {
     "duration": 0.021346,
     "end_time": "2024-08-27T12:29:02.961543",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.940197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define train dataset and dataloader\n",
    "train_ds = ArrayDataset(df_train.image_path, train_image_trans, df_train.label_path, train_label_trans)\n",
    "train_loader = DataLoader(train_ds, batch_size=config['batch_size'], num_workers=2)\n",
    "\n",
    "# Define validation dataset and dataloader\n",
    "val_ds = ArrayDataset(df_val.image_path, val_image_trans, df_val.label_path, val_label_trans)\n",
    "val_loader = DataLoader(val_ds, batch_size=config['batch_size'], num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e474bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:02.987283Z",
     "iopub.status.busy": "2024-08-27T12:29:02.987014Z",
     "iopub.status.idle": "2024-08-27T12:29:45.716985Z",
     "shell.execute_reply": "2024-08-27T12:29:45.715559Z"
    },
    "papermill": {
     "duration": 42.757249,
     "end_time": "2024-08-27T12:29:45.731077",
     "exception": false,
     "start_time": "2024-08-27T12:29:02.973828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 128, 128, 128]) torch.Size([4, 8, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Take the first processed train batch and print the shape\n",
    "first_train_image, first_train_label = first(train_loader)\n",
    "print(first_train_image.shape, first_train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "009f5bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:45.758663Z",
     "iopub.status.busy": "2024-08-27T12:29:45.758056Z",
     "iopub.status.idle": "2024-08-27T12:29:45.986515Z",
     "shell.execute_reply": "2024-08-27T12:29:45.985096Z"
    },
    "papermill": {
     "duration": 0.247316,
     "end_time": "2024-08-27T12:29:45.991303",
     "exception": false,
     "start_time": "2024-08-27T12:29:45.743987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot example image and label (training dataset)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "s = 29\n",
    "vertebrae = 1\n",
    "\n",
    "ax1.imshow(first_train_image[1, 0, :, :, s])\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(first_train_label[1,vertebrae, :, :, s])\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()  # Optional: improve spacing between plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d7535",
   "metadata": {
    "papermill": {
     "duration": 0.013166,
     "end_time": "2024-08-27T12:29:46.027206",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.014040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3D Unet model, DiceLoss and Optimizer\n",
    "\n",
    "In this section we will define the model used for 3D segmentation, the loss and the optimization algorithm used during training.\n",
    "\n",
    "- `Model`: has UNet architecture which is *state-of-the-art* for 3D segmentation of medical images. We exploit the [MONAI](https://docs.monai.io/en/stable/networks.html#unet) implementation.\n",
    "- `Loss`: the default loss used in segmentation problem is **Dice Loss**. We exploit the MONAI implementation. Because we are dealing with a mulit-class semantic segmantation problem the **softmax** activation function is applied to the prediction of the model. \n",
    "- `Optimizer`: the optimization algorithm employed for training the 3Dsegmentation model is **Adam**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7000cd31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.055106Z",
     "iopub.status.busy": "2024-08-27T12:29:46.054801Z",
     "iopub.status.idle": "2024-08-27T12:29:46.287338Z",
     "shell.execute_reply": "2024-08-27T12:29:46.286539Z"
    },
    "papermill": {
     "duration": 0.249085,
     "end_time": "2024-08-27T12:29:46.289623",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.040538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the 3D Unet model\n",
    "unet_model = UNet(\n",
    "    spatial_dims = 3, # (Height, Width, Depth)\n",
    "    in_channels = 1,\n",
    "    out_channels = 8, # 8 Binary mask 7 as the vertebrae(C1->C7) + background\n",
    "    channels = config['channels'], # Channels per layer\n",
    "    strides = config['strides'], # Stride per layers\n",
    "    kernel_size = config['kernel_size'], # Size of the kernel for each layer\n",
    "    up_kernel_size = config['up_kernel_size'], # Upsampling convolution kernel size\n",
    "    num_res_units = config['num_res_units'], # Number of residual units\n",
    "    act = config['act'], # Activation function\n",
    "    dropout = config['dropout'], # Dropout rate\n",
    "    bias = config['bias'] # Presence of bias term in convolution blocks\n",
    ")\n",
    "unet_model = unet_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092856f",
   "metadata": {
    "papermill": {
     "duration": 0.013309,
     "end_time": "2024-08-27T12:29:46.316675",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.303366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Losses & Metrics\n",
    "---\n",
    "\n",
    "The loss function used during training is the weighted sum of **Dice Loss** and **BCE Loss** because combining these two losses yields the best result in terms of segmentation, pixel-wise accuracy, generalization and adversarial attacks as shown in [Robustness of different loss functions and their impact on networks learning capability](https://arxiv.org/abs/2110.08322).\n",
    "\n",
    "The weights allow us to balance the effects of the two losses. The best combination after model selection is $\\alpha=0.05$ and $\\beta=0.95$\n",
    "\n",
    "$$\\alpha \\cdot \\text{BCE} + \\beta \\cdot \\text{Dice loss}$$\n",
    "\n",
    "Below is a brief explanation of the two losses.\n",
    "\n",
    "#### Dice Loss\n",
    "\n",
    " **Dice Loss** is a popular loss function for image segmentation and **measures the overlap between the predicted segmentation and the ground truth**.\n",
    "The advantage of using dice loss is that it can very well **handle the class imbalance** in terms of pixel count for foreground and background. Class imbalances is a common scenario in medical images where the background vastly outnumbers the foreground as in the current case.\n",
    "The dice loss formula is reported below.\n",
    "\n",
    "$$ \\text{Dice Loss} = 1 - \\frac{2\\sum_{i=1}^{n}p_i y_i}{\\sum_{i=1}^{n}p_{i}^{2}+\\sum_{i=1}^{n}y_{i}^{2}}$$\n",
    "\n",
    "Where $y_{i}$ is the real pixel value and $p_{i}$ is the predicted pixel value.\n",
    "\n",
    "We exploit MONAI implementation of Dice Loss, in what follows we will explain the chosen parameters setting:\n",
    "- `softmax=True`. In **multi-class semantic segmentation problem** each voxel of the input volume can belong to at most one class. In the current problem we have 8 classes (background and C1, ..., C7 vertebrae). **Softmax activation** function is applied to the raw output of the segmentation model to ensure that the sum of the predicted probabilities over the 8 binary channels sum up to 1.\n",
    "- `include_background=False`. We decide to exclude the first channel (background) from the loss to focus the attention of the model in the prediction of the C1, ..., C7 vertebrae.\n",
    "- `squared_pred=False`. At the denominator we do NOT use the squared prediction of the real pixel value and predicted pixel value.\n",
    "- `reduction='mean'` The reduction applied to the output, i.e. the mean over the sample in the processed batch.\n",
    "\n",
    "\n",
    "#### BCE - Binary Crossentropy\n",
    "\n",
    "**BCE Loss** (Binary Crossentropy) is commonly used in binary classification problems where the target can only assume value 0 or 1, this is the case of image segmentation if we consider the pixels of the binary encoded masks.\n",
    "\n",
    "$$\\text{BCE Loss} = - \\frac{1}{N}\\sum_{i=1}^{n}[y_i log(p_i) + (1-y_i)log(1-p_i)]$$\n",
    "\n",
    "We exploit Pytorch implementation of BCE, in particular withLogitsLoss version because the output of the model is between $[-inf, +inf]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac849d69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.344668Z",
     "iopub.status.busy": "2024-08-27T12:29:46.344327Z",
     "iopub.status.idle": "2024-08-27T12:29:46.351761Z",
     "shell.execute_reply": "2024-08-27T12:29:46.350885Z"
    },
    "papermill": {
     "duration": 0.023691,
     "end_time": "2024-08-27T12:29:46.353669",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.329978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Loss function\n",
    "\n",
    "# DiceLoss function\n",
    "#loss_function = DiceLoss(\n",
    "#    include_background = True,  # If False, channel index 0 (background) is excluded from the calculation\n",
    "#    squared_pred = False, # Use squared versions of targets and predictions in the denominator or not\n",
    "#    reduction = 'mean' # Reduction to apply to the output\n",
    "#)\n",
    "\n",
    "# BCE-DiceLoss function\n",
    "# Define DiceLoss (MONAI)\n",
    "dice_loss_fn = DiceLoss(\n",
    "    include_background=False,  # Include background class in the Dice computation\n",
    "    to_onehot_y=False,  # Assuming the labels are not one-hot encoded\n",
    "    sigmoid=False,  # Apply sigmoid to the input tensor\n",
    "    softmax=True,  # Do not apply softmax to the input tensor\n",
    "    squared_pred=True,  # Do not use squared predictions\n",
    "    reduction='mean', # Reduction to apply to the output\n",
    "    smooth_nr=1.0, # constant added to the numerator to avoid zero\n",
    "    smooth_dr=1.0 # constant added to the denominator to avoid nan\n",
    ")\n",
    "# Define BCEWithLogitsLoss (PyTorch)\n",
    "bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "# Combine BCE and Dice losses\n",
    "def bce_diceloss(input, target, loss_weights=config['loss_weights']):    # Compute the BCE loss\n",
    "    bce_loss = loss_weights[0] * bce_loss_fn(input, target)\n",
    "    # Compute the Dice loss\n",
    "    dice_loss = loss_weights[1] * dice_loss_fn(input, target)\n",
    "    # Combine the losses\n",
    "    total_loss = (bce_loss + dice_loss) / sum(loss_weights)\n",
    "    return total_loss\n",
    "# Set the combined loss function\n",
    "criterion = bce_diceloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30114956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.381505Z",
     "iopub.status.busy": "2024-08-27T12:29:46.381238Z",
     "iopub.status.idle": "2024-08-27T12:29:46.385258Z",
     "shell.execute_reply": "2024-08-27T12:29:46.384489Z"
    },
    "papermill": {
     "duration": 0.020067,
     "end_time": "2024-08-27T12:29:46.387140",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.367073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define metric\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07fc93c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.414651Z",
     "iopub.status.busy": "2024-08-27T12:29:46.414356Z",
     "iopub.status.idle": "2024-08-27T12:29:46.419991Z",
     "shell.execute_reply": "2024-08-27T12:29:46.419151Z"
    },
    "papermill": {
     "duration": 0.021556,
     "end_time": "2024-08-27T12:29:46.421866",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.400310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Optimizer\n",
    "\n",
    "# Adam optimzier\n",
    "#optimizer = torch.optim.Adam(\n",
    "#    unet_model.parameters(), # Model's params\n",
    "#    lr = 1e-3 # Learning rate\n",
    "#)\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    unet_model.parameters(), \n",
    "    lr = config['lr'] # weight_decay = config['weight_decay'] \n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0cccd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.449304Z",
     "iopub.status.busy": "2024-08-27T12:29:46.449043Z",
     "iopub.status.idle": "2024-08-27T12:29:46.454181Z",
     "shell.execute_reply": "2024-08-27T12:29:46.453346Z"
    },
    "papermill": {
     "duration": 0.021002,
     "end_time": "2024-08-27T12:29:46.456025",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.435023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use amp to accelerate training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Define the transforms to apply to model prediction \n",
    "post_trans = Compose([Activations(sigmoid=False, softmax=True, dim=0), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a25de21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.483511Z",
     "iopub.status.busy": "2024-08-27T12:29:46.483249Z",
     "iopub.status.idle": "2024-08-27T12:29:46.486799Z",
     "shell.execute_reply": "2024-08-27T12:29:46.485979Z"
    },
    "papermill": {
     "duration": 0.01944,
     "end_time": "2024-08-27T12:29:46.488666",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.469226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(unet_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba8cce",
   "metadata": {
    "papermill": {
     "duration": 0.013255,
     "end_time": "2024-08-27T12:29:46.515201",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.501946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82789380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.543951Z",
     "iopub.status.busy": "2024-08-27T12:29:46.543652Z",
     "iopub.status.idle": "2024-08-27T12:29:46.568995Z",
     "shell.execute_reply": "2024-08-27T12:29:46.568099Z"
    },
    "papermill": {
     "duration": 0.042322,
     "end_time": "2024-08-27T12:29:46.570930",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.528608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(model,\n",
    "               train_loader,\n",
    "               val_loader,\n",
    "               diceloss_function,\n",
    "               bce_function,\n",
    "               bce_diceloss_function,\n",
    "               metric,\n",
    "               optimizer,\n",
    "               lr_scheduler,\n",
    "               config,\n",
    "               output_dir,\n",
    "               output_file,\n",
    "               device):\n",
    "    \n",
    "    # Container to store train losses values per epoch\n",
    "    train_dl_values = []\n",
    "    train_bce_values = []\n",
    "    train_bce_dl_values = []\n",
    "    \n",
    "    # Container to store val losses values per epoch\n",
    "    val_dl_values = []\n",
    "    val_bce_values = []\n",
    "    val_bce_dl_values = []\n",
    "\n",
    "    # Container to store val metric values per epoch\n",
    "    val_metric_values = []\n",
    "\n",
    "    # Store best val metric\n",
    "    best_val_metric = -1\n",
    "\n",
    "    total_start = time.time()\n",
    "    # Iterate over the epochs\n",
    "    for epoch in range(1, config['epochs']+1):\n",
    "        epoch_start = time.time()\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"EPOCH {epoch}/{config['epochs']}\")\n",
    "        model.train() # Set the model in training mode\n",
    "        epoch_train_dl_loss, epoch_train_bce_loss, epoch_train_bce_dl_loss = 0, 0, 0\n",
    "        epoch_val_dl_loss, epoch_val_bce_loss, epoch_val_bce_dl_loss = 0, 0, 0\n",
    "        # Iterate over the batches\n",
    "        for step, batch_data in enumerate(train_loader):\n",
    "            step_start = time.time()\n",
    "            inputs, labels = batch_data\n",
    "            inputs, labels = (inputs.to(device), labels.to(device))\n",
    "            optimizer.zero_grad() # Clear the old gradients before computing new ones\n",
    "            # Enable automatic mixed precision (amp)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs) # Make predictions for current batch\n",
    "                train_dl_loss = diceloss_function(outputs, labels) # Compute DiceLoss (train)\n",
    "                train_bce_loss = bce_function(outputs, labels) # Compute BCE loss (train)\n",
    "                train_bce_dl_loss = bce_diceloss_function(outputs, labels) # Compute BCE-DiceLoss (train)\n",
    "            scaler.scale(train_bce_dl_loss).backward() # Compute the gradients\n",
    "            scaler.step(optimizer) # Update model weights\n",
    "            scaler.update()\n",
    "            epoch_train_dl_loss += train_dl_loss.item()\n",
    "            epoch_train_bce_loss += train_bce_loss.item()\n",
    "            epoch_train_bce_dl_loss += train_bce_dl_loss.item()\n",
    "            # REPORT PER BATCH \n",
    "            print(\n",
    "                f\"batch: {step}/{len(train_ds) // train_loader.batch_size}\"\n",
    "                f\", train_dl_loss: {train_dl_loss.item():.4f}\"\n",
    "                f\", train_bce_loss: {train_bce_loss.item():.4f}\"\n",
    "                f\", train_bce_dl_loss: {train_bce_dl_loss.item():.4f}\"\n",
    "                f\", step time: {(time.time() - step_start):.4f}\"\n",
    "            )\n",
    "        lr_scheduler.step()\n",
    "        # Compute mean losses over the batches\n",
    "        avg_train_dl_loss = epoch_train_dl_loss / (step+1)\n",
    "        avg_train_bce_loss = epoch_train_bce_loss / (step+1)\n",
    "        avg_train_bce_dl_loss = epoch_train_bce_dl_loss / (step+1)\n",
    "\n",
    "        # EVALUATE MODEL ON VALIDATION SET\n",
    "        model.eval() # Set the model to evaluation mode\n",
    "        with torch.no_grad(): # Disable gradient computation and reduce memory consumption\n",
    "            for step, val_data in enumerate(val_loader):\n",
    "                val_inputs, val_labels = val_data\n",
    "                val_inputs, val_labels = (val_inputs.to(device), val_labels.to(device))\n",
    "                val_outputs = model(val_inputs)\n",
    "                # Compute losses\n",
    "                val_dl_loss = diceloss_function(val_outputs, val_labels) # Compute DiceLoss (val)\n",
    "                val_bce_loss = bce_function(val_outputs, val_labels) # Compute BCE (val)\n",
    "                val_bce_dl_loss = bce_diceloss_function(val_outputs, val_labels) # Compute BCE-DiceLoss (val)\n",
    "                # Apply post transforms\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                # Compute metric\n",
    "                metric(y_pred=val_outputs, y=val_labels)\n",
    "                \n",
    "                epoch_val_dl_loss += val_dl_loss.item()\n",
    "                epoch_val_bce_loss += val_bce_loss.item()\n",
    "                epoch_val_bce_dl_loss += val_bce_dl_loss.item()\n",
    "                \n",
    "            # Aggregate the final mean dice result\n",
    "            avg_val_metric = metric.aggregate().item()\n",
    "            \n",
    "        # Compute mean val losses over the batches\n",
    "        avg_val_dl_loss = epoch_val_dl_loss / (step + 1)\n",
    "        avg_val_bce_loss = epoch_val_bce_loss / (step + 1)\n",
    "        avg_val_bce_dl_loss = epoch_val_bce_dl_loss / (step + 1)\n",
    "\n",
    "        # REPORT PER EPOCH\n",
    "        print(f'LOSS train DiceLoss: {avg_train_dl_loss:.4f}, LOSS train BCE: {avg_train_bce_loss:.4f}, LOSS train BCE-DiceLoss: {avg_train_bce_dl_loss:.4f}, LOSS val DiceLoss: {avg_val_dl_loss:.4f}, LOSS val BCE: {avg_val_bce_loss:.4f}, LOSS val BCE-DiceLoss: {avg_val_bce_dl_loss:.4f}, METRIC val: {avg_val_metric:.4f}')\n",
    "\n",
    "        # Store train/val losses and val metric per epoch\n",
    "        train_dl_values.append(avg_train_dl_loss)\n",
    "        train_bce_values.append(avg_train_bce_loss)\n",
    "        train_bce_dl_values.append(avg_train_bce_dl_loss)\n",
    "        val_dl_values.append(avg_val_dl_loss)\n",
    "        val_bce_values.append(avg_val_bce_loss)\n",
    "        val_bce_dl_values.append(avg_val_bce_dl_loss)\n",
    "        val_metric_values.append(avg_val_metric)\n",
    "        \n",
    "        # Reset the metric status\n",
    "        metric.reset()\n",
    "\n",
    "        # Log the running loss averaged per batch for train and the running metric averaged per batch for val\n",
    "        with open(output_file, \"a\") as file:\n",
    "            file.write(f\"{epoch}, {avg_train_dl_loss}, {avg_train_bce_loss}, {avg_train_bce_dl_loss}, {avg_val_dl_loss}, {avg_val_bce_loss}, {avg_val_bce_dl_loss}, {avg_val_metric}\\n\")\n",
    "        \n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_val_metric > best_val_metric:\n",
    "            best_val_metric = avg_val_metric\n",
    "            best_model = {'epoch': epoch,\n",
    "                          'model_state_dict': model.state_dict(),\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                          'train DiceLoss loss': avg_train_dl_loss,\n",
    "                          'train BCE loss': avg_train_bce_loss,\n",
    "                          'train BCE-DiceLoss loss': avg_train_bce_dl_loss,\n",
    "                          'val DiceLoss loss': avg_val_dl_loss,\n",
    "                          'val BCE loss': avg_val_bce_loss,\n",
    "                          'val BCE-DiceLoss loss': avg_val_bce_dl_loss\n",
    "                         }\n",
    "        print(f\"time consuming of epoch {epoch} is: {(time.time() - epoch_start):.4f}\")\n",
    "        \n",
    "        # Save last model's state\n",
    "        if epoch == config['epochs']:\n",
    "            last_model = {'epoch': epoch,\n",
    "                          'model_state_dict': model.state_dict(),\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "                          'train DiceLoss loss': avg_train_dl_loss,\n",
    "                          'train BCE loss': avg_train_bce_loss,\n",
    "                          'train BCE-DiceLoss loss': avg_train_bce_dl_loss,\n",
    "                          'val DiceLoss loss': avg_val_dl_loss,\n",
    "                          'val BCE loss': avg_val_bce_loss,\n",
    "                          'val BCE-DiceLoss loss': avg_val_bce_dl_loss\n",
    "                          }\n",
    "            \n",
    "    total_time = time.time() - total_start\n",
    "\n",
    "    # Save Train Losses and Val Metric\n",
    "    with open(OUTPUT_FILE, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Train_dl_loss', 'Train_bce_loss', 'Train_bce_dl_loss', 'Val_dl_loss', 'Val_bce_loss', 'Val_bce_dl_loss', 'Val_metric'])\n",
    "        csvwriter.writerows(zip(train_dl_values, train_bce_values, train_bce_dl_values, val_dl_values, val_bce_values, val_bce_dl_values, val_metric_values))    \n",
    "        \n",
    "    # Save Best Model's State\n",
    "    best_model_path = os.path.join(OUTPUT_DIR, f\"{config['ID']}_best_model\")\n",
    "    torch.save(best_model, best_model_path)\n",
    "\n",
    "    # Save Last Model's State\n",
    "    last_model_path = os.path.join(OUTPUT_DIR, f\"{config['ID']}_last_model\")\n",
    "    torch.save(last_model, last_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b181cb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T12:29:46.600122Z",
     "iopub.status.busy": "2024-08-27T12:29:46.599822Z",
     "iopub.status.idle": "2024-08-27T22:29:46.403760Z",
     "shell.execute_reply": "2024-08-27T22:29:46.402422Z"
    },
    "papermill": {
     "duration": 35999.879393,
     "end_time": "2024-08-27T22:29:46.464248",
     "exception": false,
     "start_time": "2024-08-27T12:29:46.584855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "EPOCH 1/80\n",
      "batch: 0/17, train_dl_loss: 0.9817, train_bce_loss: 0.8861, train_bce_dl_loss: 0.9817, step time: 4.8857\n",
      "batch: 1/17, train_dl_loss: 0.9828, train_bce_loss: 0.8833, train_bce_dl_loss: 0.9828, step time: 0.3630\n",
      "batch: 2/17, train_dl_loss: 0.9840, train_bce_loss: 0.8848, train_bce_dl_loss: 0.9840, step time: 0.4289\n",
      "batch: 3/17, train_dl_loss: 0.9886, train_bce_loss: 0.8817, train_bce_dl_loss: 0.9886, step time: 0.3641\n",
      "batch: 4/17, train_dl_loss: 0.9750, train_bce_loss: 0.8849, train_bce_dl_loss: 0.9750, step time: 0.4197\n",
      "batch: 5/17, train_dl_loss: 0.9741, train_bce_loss: 0.8836, train_bce_dl_loss: 0.9741, step time: 0.4293\n",
      "batch: 6/17, train_dl_loss: 0.9866, train_bce_loss: 0.8822, train_bce_dl_loss: 0.9866, step time: 0.4143\n",
      "batch: 7/17, train_dl_loss: 0.9762, train_bce_loss: 0.8806, train_bce_dl_loss: 0.9762, step time: 0.3663\n",
      "batch: 8/17, train_dl_loss: 0.9790, train_bce_loss: 0.8790, train_bce_dl_loss: 0.9790, step time: 0.4339\n",
      "batch: 9/17, train_dl_loss: 0.9806, train_bce_loss: 0.8778, train_bce_dl_loss: 0.9806, step time: 0.4279\n",
      "batch: 10/17, train_dl_loss: 0.9749, train_bce_loss: 0.8759, train_bce_dl_loss: 0.9749, step time: 0.4222\n",
      "batch: 11/17, train_dl_loss: 0.9685, train_bce_loss: 0.8606, train_bce_dl_loss: 0.9685, step time: 0.4085\n",
      "batch: 12/17, train_dl_loss: 0.9760, train_bce_loss: 0.8726, train_bce_dl_loss: 0.9760, step time: 0.4288\n",
      "batch: 13/17, train_dl_loss: 0.9879, train_bce_loss: 0.8649, train_bce_dl_loss: 0.9879, step time: 0.4290\n",
      "batch: 14/17, train_dl_loss: 0.9822, train_bce_loss: 0.8642, train_bce_dl_loss: 0.9822, step time: 0.4167\n",
      "batch: 15/17, train_dl_loss: 0.9796, train_bce_loss: 0.8707, train_bce_dl_loss: 0.9796, step time: 0.3758\n",
      "batch: 16/17, train_dl_loss: 0.9851, train_bce_loss: 0.8687, train_bce_dl_loss: 0.9851, step time: 0.4243\n",
      "batch: 17/17, train_dl_loss: 0.9811, train_bce_loss: 0.8698, train_bce_dl_loss: 0.9811, step time: 1.1868\n",
      "LOSS train DiceLoss: 0.9802, LOSS train BCE: 0.8762, LOSS train BCE-DiceLoss: 0.9802, LOSS val DiceLoss: 0.9765, LOSS val BCE: 0.8597, LOSS val BCE-DiceLoss: 0.9765, METRIC val: 0.0002\n",
      "time consuming of epoch 1 is: 441.7913\n",
      "----------\n",
      "EPOCH 2/80\n",
      "batch: 0/17, train_dl_loss: 0.9761, train_bce_loss: 0.8670, train_bce_dl_loss: 0.9761, step time: 0.4322\n",
      "batch: 1/17, train_dl_loss: 0.9773, train_bce_loss: 0.8658, train_bce_dl_loss: 0.9773, step time: 0.3778\n",
      "batch: 2/17, train_dl_loss: 0.9786, train_bce_loss: 0.8665, train_bce_dl_loss: 0.9786, step time: 0.4301\n",
      "batch: 3/17, train_dl_loss: 0.9824, train_bce_loss: 0.8624, train_bce_dl_loss: 0.9824, step time: 0.3738\n",
      "batch: 4/17, train_dl_loss: 0.9672, train_bce_loss: 0.8602, train_bce_dl_loss: 0.9672, step time: 0.4743\n",
      "batch: 5/17, train_dl_loss: 0.9663, train_bce_loss: 0.8577, train_bce_dl_loss: 0.9663, step time: 0.3755\n",
      "batch: 6/17, train_dl_loss: 0.9825, train_bce_loss: 0.8646, train_bce_dl_loss: 0.9825, step time: 0.4323\n",
      "batch: 7/17, train_dl_loss: 0.9704, train_bce_loss: 0.8600, train_bce_dl_loss: 0.9704, step time: 0.3813\n",
      "batch: 8/17, train_dl_loss: 0.9725, train_bce_loss: 0.8561, train_bce_dl_loss: 0.9725, step time: 0.4219\n",
      "batch: 9/17, train_dl_loss: 0.9750, train_bce_loss: 0.8598, train_bce_dl_loss: 0.9750, step time: 0.3868\n",
      "batch: 10/17, train_dl_loss: 0.9689, train_bce_loss: 0.8638, train_bce_dl_loss: 0.9689, step time: 0.4452\n",
      "batch: 11/17, train_dl_loss: 0.9613, train_bce_loss: 0.8522, train_bce_dl_loss: 0.9613, step time: 0.4431\n",
      "batch: 12/17, train_dl_loss: 0.9708, train_bce_loss: 0.8570, train_bce_dl_loss: 0.9708, step time: 0.4280\n",
      "batch: 13/17, train_dl_loss: 0.9853, train_bce_loss: 0.8601, train_bce_dl_loss: 0.9853, step time: 0.4209\n",
      "batch: 14/17, train_dl_loss: 0.9781, train_bce_loss: 0.8586, train_bce_dl_loss: 0.9781, step time: 0.4461\n",
      "batch: 15/17, train_dl_loss: 0.9759, train_bce_loss: 0.8663, train_bce_dl_loss: 0.9759, step time: 0.3762\n",
      "batch: 16/17, train_dl_loss: 0.9820, train_bce_loss: 0.8607, train_bce_dl_loss: 0.9820, step time: 0.4319\n",
      "batch: 17/17, train_dl_loss: 0.9756, train_bce_loss: 0.8617, train_bce_dl_loss: 0.9756, step time: 0.1117\n",
      "LOSS train DiceLoss: 0.9748, LOSS train BCE: 0.8611, LOSS train BCE-DiceLoss: 0.9748, LOSS val DiceLoss: 0.9724, LOSS val BCE: 0.8512, LOSS val BCE-DiceLoss: 0.9724, METRIC val: 0.0000\n",
      "time consuming of epoch 2 is: 426.6096\n",
      "----------\n",
      "EPOCH 3/80\n",
      "batch: 0/17, train_dl_loss: 0.9725, train_bce_loss: 0.8596, train_bce_dl_loss: 0.9725, step time: 0.4282\n",
      "batch: 1/17, train_dl_loss: 0.9723, train_bce_loss: 0.8527, train_bce_dl_loss: 0.9723, step time: 0.3793\n",
      "batch: 2/17, train_dl_loss: 0.9744, train_bce_loss: 0.8531, train_bce_dl_loss: 0.9744, step time: 0.4430\n",
      "batch: 3/17, train_dl_loss: 0.9791, train_bce_loss: 0.8549, train_bce_dl_loss: 0.9791, step time: 0.3734\n",
      "batch: 4/17, train_dl_loss: 0.9600, train_bce_loss: 0.8582, train_bce_dl_loss: 0.9600, step time: 0.4270\n",
      "batch: 5/17, train_dl_loss: 0.9595, train_bce_loss: 0.8587, train_bce_dl_loss: 0.9595, step time: 0.3845\n",
      "batch: 6/17, train_dl_loss: 0.9777, train_bce_loss: 0.8616, train_bce_dl_loss: 0.9777, step time: 0.4240\n",
      "batch: 7/17, train_dl_loss: 0.9681, train_bce_loss: 0.8607, train_bce_dl_loss: 0.9681, step time: 0.3816\n",
      "batch: 8/17, train_dl_loss: 0.9664, train_bce_loss: 0.8528, train_bce_dl_loss: 0.9664, step time: 0.4393\n",
      "batch: 9/17, train_dl_loss: 0.9693, train_bce_loss: 0.8537, train_bce_dl_loss: 0.9693, step time: 0.3783\n",
      "batch: 10/17, train_dl_loss: 0.9581, train_bce_loss: 0.8630, train_bce_dl_loss: 0.9581, step time: 0.4447\n",
      "batch: 11/17, train_dl_loss: 0.9570, train_bce_loss: 0.8569, train_bce_dl_loss: 0.9570, step time: 0.3873\n",
      "batch: 12/17, train_dl_loss: 0.9613, train_bce_loss: 0.8612, train_bce_dl_loss: 0.9613, step time: 0.4309\n",
      "batch: 13/17, train_dl_loss: 0.9807, train_bce_loss: 0.8588, train_bce_dl_loss: 0.9807, step time: 0.3749\n",
      "batch: 14/17, train_dl_loss: 0.9732, train_bce_loss: 0.8611, train_bce_dl_loss: 0.9732, step time: 0.4268\n",
      "batch: 15/17, train_dl_loss: 0.9687, train_bce_loss: 0.8599, train_bce_dl_loss: 0.9687, step time: 0.4087\n",
      "batch: 16/17, train_dl_loss: 0.9752, train_bce_loss: 0.8620, train_bce_dl_loss: 0.9752, step time: 0.4192\n",
      "batch: 17/17, train_dl_loss: 0.9822, train_bce_loss: 0.8695, train_bce_dl_loss: 0.9822, step time: 0.1122\n",
      "LOSS train DiceLoss: 0.9698, LOSS train BCE: 0.8588, LOSS train BCE-DiceLoss: 0.9698, LOSS val DiceLoss: 0.9654, LOSS val BCE: 0.8602, LOSS val BCE-DiceLoss: 0.9654, METRIC val: 0.0115\n",
      "time consuming of epoch 3 is: 431.4127\n",
      "----------\n",
      "EPOCH 4/80\n",
      "batch: 0/17, train_dl_loss: 0.9664, train_bce_loss: 0.8624, train_bce_dl_loss: 0.9664, step time: 0.4253\n",
      "batch: 1/17, train_dl_loss: 0.9694, train_bce_loss: 0.8714, train_bce_dl_loss: 0.9694, step time: 0.3852\n",
      "batch: 2/17, train_dl_loss: 0.9703, train_bce_loss: 0.8701, train_bce_dl_loss: 0.9703, step time: 0.4610\n",
      "batch: 3/17, train_dl_loss: 0.9711, train_bce_loss: 0.8663, train_bce_dl_loss: 0.9711, step time: 0.3773\n",
      "batch: 4/17, train_dl_loss: 0.9475, train_bce_loss: 0.8723, train_bce_dl_loss: 0.9475, step time: 0.4197\n",
      "batch: 5/17, train_dl_loss: 0.9512, train_bce_loss: 0.8674, train_bce_dl_loss: 0.9512, step time: 0.3821\n",
      "batch: 6/17, train_dl_loss: 0.9711, train_bce_loss: 0.8687, train_bce_dl_loss: 0.9711, step time: 0.4218\n",
      "batch: 7/17, train_dl_loss: 0.9490, train_bce_loss: 0.8700, train_bce_dl_loss: 0.9490, step time: 0.3786\n",
      "batch: 8/17, train_dl_loss: 0.9515, train_bce_loss: 0.8711, train_bce_dl_loss: 0.9515, step time: 0.4242\n",
      "batch: 9/17, train_dl_loss: 0.9559, train_bce_loss: 0.8728, train_bce_dl_loss: 0.9559, step time: 0.3835\n",
      "batch: 10/17, train_dl_loss: 0.9522, train_bce_loss: 0.8752, train_bce_dl_loss: 0.9522, step time: 0.4420\n",
      "batch: 11/17, train_dl_loss: 0.9378, train_bce_loss: 0.8664, train_bce_dl_loss: 0.9378, step time: 0.4352\n",
      "batch: 12/17, train_dl_loss: 0.9564, train_bce_loss: 0.8745, train_bce_dl_loss: 0.9564, step time: 0.4360\n",
      "batch: 13/17, train_dl_loss: 0.9732, train_bce_loss: 0.8727, train_bce_dl_loss: 0.9732, step time: 0.3820\n",
      "batch: 14/17, train_dl_loss: 0.9613, train_bce_loss: 0.8804, train_bce_dl_loss: 0.9613, step time: 0.4182\n",
      "batch: 15/17, train_dl_loss: 0.9514, train_bce_loss: 0.8809, train_bce_dl_loss: 0.9514, step time: 0.3812\n",
      "batch: 16/17, train_dl_loss: 0.9607, train_bce_loss: 0.8804, train_bce_dl_loss: 0.9607, step time: 0.4163\n",
      "batch: 17/17, train_dl_loss: 0.9519, train_bce_loss: 0.8840, train_bce_dl_loss: 0.9519, step time: 0.1120\n",
      "LOSS train DiceLoss: 0.9582, LOSS train BCE: 0.8726, LOSS train BCE-DiceLoss: 0.9582, LOSS val DiceLoss: 0.9479, LOSS val BCE: 0.8783, LOSS val BCE-DiceLoss: 0.9479, METRIC val: 0.0331\n",
      "time consuming of epoch 4 is: 349.7273\n",
      "----------\n",
      "EPOCH 5/80\n",
      "batch: 0/17, train_dl_loss: 0.9484, train_bce_loss: 0.8826, train_bce_dl_loss: 0.9484, step time: 0.4380\n",
      "batch: 1/17, train_dl_loss: 0.9533, train_bce_loss: 0.8912, train_bce_dl_loss: 0.9533, step time: 0.3795\n",
      "batch: 2/17, train_dl_loss: 0.9556, train_bce_loss: 0.8826, train_bce_dl_loss: 0.9556, step time: 0.4284\n",
      "batch: 3/17, train_dl_loss: 0.9580, train_bce_loss: 0.8854, train_bce_dl_loss: 0.9580, step time: 0.3833\n",
      "batch: 4/17, train_dl_loss: 0.9293, train_bce_loss: 0.8833, train_bce_dl_loss: 0.9293, step time: 0.4315\n",
      "batch: 5/17, train_dl_loss: 0.9266, train_bce_loss: 0.8894, train_bce_dl_loss: 0.9266, step time: 0.4439\n",
      "batch: 6/17, train_dl_loss: 0.9520, train_bce_loss: 0.8946, train_bce_dl_loss: 0.9520, step time: 0.4350\n",
      "batch: 7/17, train_dl_loss: 0.9253, train_bce_loss: 0.8895, train_bce_dl_loss: 0.9253, step time: 0.4328\n",
      "batch: 8/17, train_dl_loss: 0.9346, train_bce_loss: 0.8917, train_bce_dl_loss: 0.9346, step time: 0.4415\n",
      "batch: 9/17, train_dl_loss: 0.9345, train_bce_loss: 0.8999, train_bce_dl_loss: 0.9345, step time: 0.4374\n",
      "batch: 10/17, train_dl_loss: 0.9357, train_bce_loss: 0.8992, train_bce_dl_loss: 0.9357, step time: 0.4419\n",
      "batch: 11/17, train_dl_loss: 0.9077, train_bce_loss: 0.8941, train_bce_dl_loss: 0.9077, step time: 0.4285\n",
      "batch: 12/17, train_dl_loss: 0.9305, train_bce_loss: 0.9007, train_bce_dl_loss: 0.9305, step time: 0.4450\n",
      "batch: 13/17, train_dl_loss: 0.9617, train_bce_loss: 0.9051, train_bce_dl_loss: 0.9617, step time: 0.4376\n",
      "batch: 14/17, train_dl_loss: 0.9487, train_bce_loss: 0.9055, train_bce_dl_loss: 0.9487, step time: 0.4268\n",
      "batch: 15/17, train_dl_loss: 0.9317, train_bce_loss: 0.9035, train_bce_dl_loss: 0.9317, step time: 0.4377\n",
      "batch: 16/17, train_dl_loss: 0.9347, train_bce_loss: 0.9128, train_bce_dl_loss: 0.9347, step time: 0.4292\n",
      "batch: 17/17, train_dl_loss: 0.9606, train_bce_loss: 0.9127, train_bce_dl_loss: 0.9606, step time: 0.1135\n",
      "LOSS train DiceLoss: 0.9405, LOSS train BCE: 0.8958, LOSS train BCE-DiceLoss: 0.9405, LOSS val DiceLoss: 0.9269, LOSS val BCE: 0.9076, LOSS val BCE-DiceLoss: 0.9269, METRIC val: 0.0476\n",
      "time consuming of epoch 5 is: 423.0351\n",
      "----------\n",
      "EPOCH 6/80\n",
      "batch: 0/17, train_dl_loss: 0.9229, train_bce_loss: 0.9158, train_bce_dl_loss: 0.9229, step time: 0.4366\n",
      "batch: 1/17, train_dl_loss: 0.9188, train_bce_loss: 0.9119, train_bce_dl_loss: 0.9188, step time: 0.3884\n",
      "batch: 2/17, train_dl_loss: 0.9347, train_bce_loss: 0.9170, train_bce_dl_loss: 0.9347, step time: 0.4355\n",
      "batch: 3/17, train_dl_loss: 0.9435, train_bce_loss: 0.9180, train_bce_dl_loss: 0.9435, step time: 0.3759\n",
      "batch: 4/17, train_dl_loss: 0.9012, train_bce_loss: 0.9203, train_bce_dl_loss: 0.9012, step time: 0.4359\n",
      "batch: 5/17, train_dl_loss: 0.9028, train_bce_loss: 0.9215, train_bce_dl_loss: 0.9028, step time: 0.3872\n",
      "batch: 6/17, train_dl_loss: 0.9381, train_bce_loss: 0.9264, train_bce_dl_loss: 0.9381, step time: 0.4395\n",
      "batch: 7/17, train_dl_loss: 0.9039, train_bce_loss: 0.9180, train_bce_dl_loss: 0.9039, step time: 0.3818\n",
      "batch: 8/17, train_dl_loss: 0.9213, train_bce_loss: 0.9297, train_bce_dl_loss: 0.9213, step time: 0.4264\n",
      "batch: 9/17, train_dl_loss: 0.9202, train_bce_loss: 0.9289, train_bce_dl_loss: 0.9202, step time: 0.3804\n",
      "batch: 10/17, train_dl_loss: 0.9134, train_bce_loss: 0.9335, train_bce_dl_loss: 0.9134, step time: 0.4223\n",
      "batch: 11/17, train_dl_loss: 0.8923, train_bce_loss: 0.9235, train_bce_dl_loss: 0.8923, step time: 0.3838\n",
      "batch: 12/17, train_dl_loss: 0.9149, train_bce_loss: 0.9367, train_bce_dl_loss: 0.9149, step time: 0.4279\n",
      "batch: 13/17, train_dl_loss: 0.9424, train_bce_loss: 0.9349, train_bce_dl_loss: 0.9424, step time: 0.3736\n",
      "batch: 14/17, train_dl_loss: 0.9186, train_bce_loss: 0.9334, train_bce_dl_loss: 0.9186, step time: 0.4268\n",
      "batch: 15/17, train_dl_loss: 0.9137, train_bce_loss: 0.9359, train_bce_dl_loss: 0.9137, step time: 0.3831\n",
      "batch: 16/17, train_dl_loss: 0.9115, train_bce_loss: 0.9493, train_bce_dl_loss: 0.9115, step time: 0.4289\n",
      "batch: 17/17, train_dl_loss: 0.8974, train_bce_loss: 0.9517, train_bce_dl_loss: 0.8974, step time: 0.1122\n",
      "LOSS train DiceLoss: 0.9173, LOSS train BCE: 0.9281, LOSS train BCE-DiceLoss: 0.9173, LOSS val DiceLoss: 0.9202, LOSS val BCE: 0.9398, LOSS val BCE-DiceLoss: 0.9202, METRIC val: 0.0365\n",
      "time consuming of epoch 6 is: 366.1075\n",
      "----------\n",
      "EPOCH 7/80\n",
      "batch: 0/17, train_dl_loss: 0.9257, train_bce_loss: 0.9562, train_bce_dl_loss: 0.9257, step time: 0.4481\n",
      "batch: 1/17, train_dl_loss: 0.9005, train_bce_loss: 0.9473, train_bce_dl_loss: 0.9005, step time: 0.3787\n",
      "batch: 2/17, train_dl_loss: 0.9251, train_bce_loss: 0.9535, train_bce_dl_loss: 0.9251, step time: 0.4281\n",
      "batch: 3/17, train_dl_loss: 0.9225, train_bce_loss: 0.9555, train_bce_dl_loss: 0.9225, step time: 0.3834\n",
      "batch: 4/17, train_dl_loss: 0.8720, train_bce_loss: 0.9446, train_bce_dl_loss: 0.8720, step time: 0.4393\n",
      "batch: 5/17, train_dl_loss: 0.8804, train_bce_loss: 0.9577, train_bce_dl_loss: 0.8804, step time: 0.3835\n",
      "batch: 6/17, train_dl_loss: 0.9057, train_bce_loss: 0.9561, train_bce_dl_loss: 0.9057, step time: 0.4393\n",
      "batch: 7/17, train_dl_loss: 0.8695, train_bce_loss: 0.9506, train_bce_dl_loss: 0.8695, step time: 0.3771\n",
      "batch: 8/17, train_dl_loss: 0.8860, train_bce_loss: 0.9543, train_bce_dl_loss: 0.8860, step time: 0.4481\n",
      "batch: 9/17, train_dl_loss: 0.8878, train_bce_loss: 0.9694, train_bce_dl_loss: 0.8878, step time: 0.3817\n",
      "batch: 10/17, train_dl_loss: 0.8717, train_bce_loss: 0.9725, train_bce_dl_loss: 0.8717, step time: 0.4188\n",
      "batch: 11/17, train_dl_loss: 0.8516, train_bce_loss: 0.9513, train_bce_dl_loss: 0.8516, step time: 0.4434\n",
      "batch: 12/17, train_dl_loss: 0.8836, train_bce_loss: 0.9678, train_bce_dl_loss: 0.8836, step time: 0.4279\n",
      "batch: 13/17, train_dl_loss: 0.9218, train_bce_loss: 0.9756, train_bce_dl_loss: 0.9218, step time: 0.3761\n",
      "batch: 14/17, train_dl_loss: 0.8874, train_bce_loss: 0.9803, train_bce_dl_loss: 0.8874, step time: 0.4317\n",
      "batch: 15/17, train_dl_loss: 0.8642, train_bce_loss: 0.9830, train_bce_dl_loss: 0.8642, step time: 0.3854\n",
      "batch: 16/17, train_dl_loss: 0.8836, train_bce_loss: 0.9740, train_bce_dl_loss: 0.8836, step time: 0.4296\n",
      "batch: 17/17, train_dl_loss: 0.8647, train_bce_loss: 0.9762, train_bce_dl_loss: 0.8647, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.8891, LOSS train BCE: 0.9626, LOSS train BCE-DiceLoss: 0.8891, LOSS val DiceLoss: 0.8849, LOSS val BCE: 0.9748, LOSS val BCE-DiceLoss: 0.8849, METRIC val: 0.0564\n",
      "time consuming of epoch 7 is: 416.9680\n",
      "----------\n",
      "EPOCH 8/80\n",
      "batch: 0/17, train_dl_loss: 0.8838, train_bce_loss: 0.9813, train_bce_dl_loss: 0.8838, step time: 0.4420\n",
      "batch: 1/17, train_dl_loss: 0.8748, train_bce_loss: 0.9822, train_bce_dl_loss: 0.8748, step time: 0.3809\n",
      "batch: 2/17, train_dl_loss: 0.8902, train_bce_loss: 0.9901, train_bce_dl_loss: 0.8902, step time: 0.4249\n",
      "batch: 3/17, train_dl_loss: 0.8877, train_bce_loss: 0.9861, train_bce_dl_loss: 0.8877, step time: 0.3754\n",
      "batch: 4/17, train_dl_loss: 0.8366, train_bce_loss: 0.9905, train_bce_dl_loss: 0.8366, step time: 0.4420\n",
      "batch: 5/17, train_dl_loss: 0.8567, train_bce_loss: 0.9951, train_bce_dl_loss: 0.8567, step time: 0.3856\n",
      "batch: 6/17, train_dl_loss: 0.8783, train_bce_loss: 0.9985, train_bce_dl_loss: 0.8783, step time: 0.4321\n",
      "batch: 7/17, train_dl_loss: 0.8276, train_bce_loss: 0.9996, train_bce_dl_loss: 0.8276, step time: 0.3764\n",
      "batch: 8/17, train_dl_loss: 0.8619, train_bce_loss: 0.9885, train_bce_dl_loss: 0.8619, step time: 0.5097\n",
      "batch: 9/17, train_dl_loss: 0.8416, train_bce_loss: 0.9995, train_bce_dl_loss: 0.8416, step time: 0.3848\n",
      "batch: 10/17, train_dl_loss: 0.8388, train_bce_loss: 1.0068, train_bce_dl_loss: 0.8388, step time: 0.4289\n",
      "batch: 11/17, train_dl_loss: 0.8157, train_bce_loss: 1.0072, train_bce_dl_loss: 0.8157, step time: 0.3803\n",
      "batch: 12/17, train_dl_loss: 0.8483, train_bce_loss: 1.0021, train_bce_dl_loss: 0.8483, step time: 0.4242\n",
      "batch: 13/17, train_dl_loss: 0.9166, train_bce_loss: 1.0117, train_bce_dl_loss: 0.9166, step time: 0.3788\n",
      "batch: 14/17, train_dl_loss: 0.8628, train_bce_loss: 1.0130, train_bce_dl_loss: 0.8628, step time: 0.4334\n",
      "batch: 15/17, train_dl_loss: 0.8481, train_bce_loss: 1.0085, train_bce_dl_loss: 0.8481, step time: 0.3809\n",
      "batch: 16/17, train_dl_loss: 0.8559, train_bce_loss: 1.0146, train_bce_dl_loss: 0.8559, step time: 0.4163\n",
      "batch: 17/17, train_dl_loss: 0.8778, train_bce_loss: 1.0257, train_bce_dl_loss: 0.8778, step time: 0.1130\n",
      "LOSS train DiceLoss: 0.8613, LOSS train BCE: 1.0001, LOSS train BCE-DiceLoss: 0.8613, LOSS val DiceLoss: 0.8526, LOSS val BCE: 1.0145, LOSS val BCE-DiceLoss: 0.8526, METRIC val: 0.0725\n",
      "time consuming of epoch 8 is: 417.9383\n",
      "----------\n",
      "EPOCH 9/80\n",
      "batch: 0/17, train_dl_loss: 0.8375, train_bce_loss: 1.0205, train_bce_dl_loss: 0.8375, step time: 0.4211\n",
      "batch: 1/17, train_dl_loss: 0.8267, train_bce_loss: 1.0229, train_bce_dl_loss: 0.8267, step time: 0.3759\n",
      "batch: 2/17, train_dl_loss: 0.8559, train_bce_loss: 1.0262, train_bce_dl_loss: 0.8559, step time: 0.4290\n",
      "batch: 3/17, train_dl_loss: 0.8696, train_bce_loss: 1.0283, train_bce_dl_loss: 0.8696, step time: 0.3800\n",
      "batch: 4/17, train_dl_loss: 0.8253, train_bce_loss: 1.0406, train_bce_dl_loss: 0.8253, step time: 0.4272\n",
      "batch: 5/17, train_dl_loss: 0.8149, train_bce_loss: 1.0303, train_bce_dl_loss: 0.8149, step time: 0.4288\n",
      "batch: 6/17, train_dl_loss: 0.8417, train_bce_loss: 1.0416, train_bce_dl_loss: 0.8417, step time: 0.4406\n",
      "batch: 7/17, train_dl_loss: 0.8111, train_bce_loss: 1.0463, train_bce_dl_loss: 0.8111, step time: 0.4266\n",
      "batch: 8/17, train_dl_loss: 0.8307, train_bce_loss: 1.0466, train_bce_dl_loss: 0.8307, step time: 0.4213\n",
      "batch: 9/17, train_dl_loss: 0.8413, train_bce_loss: 1.0494, train_bce_dl_loss: 0.8413, step time: 0.4236\n",
      "batch: 10/17, train_dl_loss: 0.8129, train_bce_loss: 1.0434, train_bce_dl_loss: 0.8129, step time: 0.4563\n",
      "batch: 11/17, train_dl_loss: 0.8001, train_bce_loss: 1.0392, train_bce_dl_loss: 0.8001, step time: 0.4388\n",
      "batch: 12/17, train_dl_loss: 0.8183, train_bce_loss: 1.0416, train_bce_dl_loss: 0.8183, step time: 0.4239\n",
      "batch: 13/17, train_dl_loss: 0.8765, train_bce_loss: 1.0502, train_bce_dl_loss: 0.8765, step time: 0.4384\n",
      "batch: 14/17, train_dl_loss: 0.8444, train_bce_loss: 1.0613, train_bce_dl_loss: 0.8444, step time: 0.4418\n",
      "batch: 15/17, train_dl_loss: 0.8147, train_bce_loss: 1.0460, train_bce_dl_loss: 0.8147, step time: 0.4246\n",
      "batch: 16/17, train_dl_loss: 0.8129, train_bce_loss: 1.0547, train_bce_dl_loss: 0.8129, step time: 0.4265\n",
      "batch: 17/17, train_dl_loss: 0.8063, train_bce_loss: 1.0689, train_bce_dl_loss: 0.8063, step time: 0.1123\n",
      "LOSS train DiceLoss: 0.8300, LOSS train BCE: 1.0421, LOSS train BCE-DiceLoss: 0.8300, LOSS val DiceLoss: 0.8274, LOSS val BCE: 1.0552, LOSS val BCE-DiceLoss: 0.8274, METRIC val: 0.0786\n",
      "time consuming of epoch 9 is: 489.0808\n",
      "----------\n",
      "EPOCH 10/80\n",
      "batch: 0/17, train_dl_loss: 0.7901, train_bce_loss: 1.0556, train_bce_dl_loss: 0.7901, step time: 0.4397\n",
      "batch: 1/17, train_dl_loss: 0.7984, train_bce_loss: 1.0663, train_bce_dl_loss: 0.7984, step time: 0.3771\n",
      "batch: 2/17, train_dl_loss: 0.8397, train_bce_loss: 1.0595, train_bce_dl_loss: 0.8397, step time: 0.4317\n",
      "batch: 3/17, train_dl_loss: 0.8428, train_bce_loss: 1.0663, train_bce_dl_loss: 0.8428, step time: 0.3789\n",
      "batch: 4/17, train_dl_loss: 0.8129, train_bce_loss: 1.0716, train_bce_dl_loss: 0.8129, step time: 0.4334\n",
      "batch: 5/17, train_dl_loss: 0.8076, train_bce_loss: 1.0721, train_bce_dl_loss: 0.8076, step time: 0.3867\n",
      "batch: 6/17, train_dl_loss: 0.8292, train_bce_loss: 1.0763, train_bce_dl_loss: 0.8292, step time: 0.4249\n",
      "batch: 7/17, train_dl_loss: 0.7928, train_bce_loss: 1.0673, train_bce_dl_loss: 0.7928, step time: 0.3874\n",
      "batch: 8/17, train_dl_loss: 0.8024, train_bce_loss: 1.0829, train_bce_dl_loss: 0.8024, step time: 0.4179\n",
      "batch: 9/17, train_dl_loss: 0.8091, train_bce_loss: 1.0874, train_bce_dl_loss: 0.8091, step time: 0.3774\n",
      "batch: 10/17, train_dl_loss: 0.8071, train_bce_loss: 1.0802, train_bce_dl_loss: 0.8071, step time: 0.4291\n",
      "batch: 11/17, train_dl_loss: 0.7896, train_bce_loss: 1.0737, train_bce_dl_loss: 0.7896, step time: 0.3846\n",
      "batch: 12/17, train_dl_loss: 0.7969, train_bce_loss: 1.0815, train_bce_dl_loss: 0.7969, step time: 0.4400\n",
      "batch: 13/17, train_dl_loss: 0.8594, train_bce_loss: 1.0888, train_bce_dl_loss: 0.8594, step time: 0.3808\n",
      "batch: 14/17, train_dl_loss: 0.8084, train_bce_loss: 1.0899, train_bce_dl_loss: 0.8084, step time: 0.4561\n",
      "batch: 15/17, train_dl_loss: 0.7913, train_bce_loss: 1.0936, train_bce_dl_loss: 0.7913, step time: 0.4410\n",
      "batch: 16/17, train_dl_loss: 0.7820, train_bce_loss: 1.0952, train_bce_dl_loss: 0.7820, step time: 0.4121\n",
      "batch: 17/17, train_dl_loss: 0.7818, train_bce_loss: 1.0877, train_bce_dl_loss: 0.7818, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.8079, LOSS train BCE: 1.0775, LOSS train BCE-DiceLoss: 0.8079, LOSS val DiceLoss: 0.8210, LOSS val BCE: 1.0900, LOSS val BCE-DiceLoss: 0.8210, METRIC val: 0.0733\n",
      "time consuming of epoch 10 is: 403.0627\n",
      "----------\n",
      "EPOCH 11/80\n",
      "batch: 0/17, train_dl_loss: 0.7668, train_bce_loss: 1.0987, train_bce_dl_loss: 0.7668, step time: 0.4511\n",
      "batch: 1/17, train_dl_loss: 0.7756, train_bce_loss: 1.1004, train_bce_dl_loss: 0.7756, step time: 0.3710\n",
      "batch: 2/17, train_dl_loss: 0.8321, train_bce_loss: 1.1026, train_bce_dl_loss: 0.8321, step time: 0.4392\n",
      "batch: 3/17, train_dl_loss: 0.8037, train_bce_loss: 1.1019, train_bce_dl_loss: 0.8037, step time: 0.3786\n",
      "batch: 4/17, train_dl_loss: 0.7764, train_bce_loss: 1.1027, train_bce_dl_loss: 0.7764, step time: 0.4349\n",
      "batch: 5/17, train_dl_loss: 0.7551, train_bce_loss: 1.1139, train_bce_dl_loss: 0.7551, step time: 0.3768\n",
      "batch: 6/17, train_dl_loss: 0.7977, train_bce_loss: 1.1059, train_bce_dl_loss: 0.7977, step time: 0.4362\n",
      "batch: 7/17, train_dl_loss: 0.7579, train_bce_loss: 1.1110, train_bce_dl_loss: 0.7579, step time: 0.3819\n",
      "batch: 8/17, train_dl_loss: 0.7834, train_bce_loss: 1.1039, train_bce_dl_loss: 0.7834, step time: 0.4402\n",
      "batch: 9/17, train_dl_loss: 0.7834, train_bce_loss: 1.1154, train_bce_dl_loss: 0.7834, step time: 0.4485\n",
      "batch: 10/17, train_dl_loss: 0.7913, train_bce_loss: 1.1065, train_bce_dl_loss: 0.7913, step time: 0.4402\n",
      "batch: 11/17, train_dl_loss: 0.7470, train_bce_loss: 1.0895, train_bce_dl_loss: 0.7470, step time: 0.4288\n",
      "batch: 12/17, train_dl_loss: 0.8022, train_bce_loss: 1.1159, train_bce_dl_loss: 0.8022, step time: 0.4466\n",
      "batch: 13/17, train_dl_loss: 0.8490, train_bce_loss: 1.1180, train_bce_dl_loss: 0.8490, step time: 0.3865\n",
      "batch: 14/17, train_dl_loss: 0.8071, train_bce_loss: 1.1210, train_bce_dl_loss: 0.8071, step time: 0.4356\n",
      "batch: 15/17, train_dl_loss: 0.7656, train_bce_loss: 1.1090, train_bce_dl_loss: 0.7656, step time: 0.3826\n",
      "batch: 16/17, train_dl_loss: 0.7593, train_bce_loss: 1.1140, train_bce_dl_loss: 0.7593, step time: 0.4268\n",
      "batch: 17/17, train_dl_loss: 0.7543, train_bce_loss: 1.1177, train_bce_dl_loss: 0.7543, step time: 0.1119\n",
      "LOSS train DiceLoss: 0.7838, LOSS train BCE: 1.1082, LOSS train BCE-DiceLoss: 0.7838, LOSS val DiceLoss: 0.7964, LOSS val BCE: 1.1153, LOSS val BCE-DiceLoss: 0.7964, METRIC val: 0.1119\n",
      "time consuming of epoch 11 is: 428.9269\n",
      "----------\n",
      "EPOCH 12/80\n",
      "batch: 0/17, train_dl_loss: 0.7705, train_bce_loss: 1.1190, train_bce_dl_loss: 0.7705, step time: 0.4309\n",
      "batch: 1/17, train_dl_loss: 0.7587, train_bce_loss: 1.1356, train_bce_dl_loss: 0.7587, step time: 0.3804\n",
      "batch: 2/17, train_dl_loss: 0.7999, train_bce_loss: 1.1191, train_bce_dl_loss: 0.7999, step time: 0.4215\n",
      "batch: 3/17, train_dl_loss: 0.7913, train_bce_loss: 1.1200, train_bce_dl_loss: 0.7913, step time: 0.3717\n",
      "batch: 4/17, train_dl_loss: 0.7537, train_bce_loss: 1.1220, train_bce_dl_loss: 0.7537, step time: 0.4233\n",
      "batch: 5/17, train_dl_loss: 0.7469, train_bce_loss: 1.1274, train_bce_dl_loss: 0.7469, step time: 0.3830\n",
      "batch: 6/17, train_dl_loss: 0.7691, train_bce_loss: 1.1367, train_bce_dl_loss: 0.7691, step time: 0.4301\n",
      "batch: 7/17, train_dl_loss: 0.7247, train_bce_loss: 1.1281, train_bce_dl_loss: 0.7247, step time: 0.3813\n",
      "batch: 8/17, train_dl_loss: 0.7586, train_bce_loss: 1.1322, train_bce_dl_loss: 0.7586, step time: 0.4194\n",
      "batch: 9/17, train_dl_loss: 0.7503, train_bce_loss: 1.1402, train_bce_dl_loss: 0.7503, step time: 0.3728\n",
      "batch: 10/17, train_dl_loss: 0.7539, train_bce_loss: 1.1397, train_bce_dl_loss: 0.7539, step time: 0.4269\n",
      "batch: 11/17, train_dl_loss: 0.7197, train_bce_loss: 1.1203, train_bce_dl_loss: 0.7197, step time: 0.3835\n",
      "batch: 12/17, train_dl_loss: 0.7428, train_bce_loss: 1.1258, train_bce_dl_loss: 0.7428, step time: 0.4370\n",
      "batch: 13/17, train_dl_loss: 0.8392, train_bce_loss: 1.1375, train_bce_dl_loss: 0.8392, step time: 0.3841\n",
      "batch: 14/17, train_dl_loss: 0.7886, train_bce_loss: 1.1512, train_bce_dl_loss: 0.7886, step time: 0.4339\n",
      "batch: 15/17, train_dl_loss: 0.7366, train_bce_loss: 1.1458, train_bce_dl_loss: 0.7366, step time: 0.3758\n",
      "batch: 16/17, train_dl_loss: 0.7279, train_bce_loss: 1.1390, train_bce_dl_loss: 0.7279, step time: 0.4270\n",
      "batch: 17/17, train_dl_loss: 0.7178, train_bce_loss: 1.1368, train_bce_dl_loss: 0.7178, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.7583, LOSS train BCE: 1.1320, LOSS train BCE-DiceLoss: 0.7583, LOSS val DiceLoss: 0.7837, LOSS val BCE: 1.1380, LOSS val BCE-DiceLoss: 0.7837, METRIC val: 0.1371\n",
      "time consuming of epoch 12 is: 416.3828\n",
      "----------\n",
      "EPOCH 13/80\n",
      "batch: 0/17, train_dl_loss: 0.7050, train_bce_loss: 1.1331, train_bce_dl_loss: 0.7050, step time: 0.4424\n",
      "batch: 1/17, train_dl_loss: 0.7259, train_bce_loss: 1.1432, train_bce_dl_loss: 0.7259, step time: 0.3771\n",
      "batch: 2/17, train_dl_loss: 0.7926, train_bce_loss: 1.1337, train_bce_dl_loss: 0.7926, step time: 0.4187\n",
      "batch: 3/17, train_dl_loss: 0.8019, train_bce_loss: 1.1449, train_bce_dl_loss: 0.8019, step time: 0.3767\n",
      "batch: 4/17, train_dl_loss: 0.7087, train_bce_loss: 1.1468, train_bce_dl_loss: 0.7087, step time: 0.4338\n",
      "batch: 5/17, train_dl_loss: 0.7573, train_bce_loss: 1.1389, train_bce_dl_loss: 0.7573, step time: 0.4304\n",
      "batch: 6/17, train_dl_loss: 0.7750, train_bce_loss: 1.1550, train_bce_dl_loss: 0.7750, step time: 0.4260\n",
      "batch: 7/17, train_dl_loss: 0.7049, train_bce_loss: 1.1431, train_bce_dl_loss: 0.7049, step time: 0.4440\n",
      "batch: 8/17, train_dl_loss: 0.7223, train_bce_loss: 1.1534, train_bce_dl_loss: 0.7223, step time: 0.4225\n",
      "batch: 9/17, train_dl_loss: 0.7045, train_bce_loss: 1.1648, train_bce_dl_loss: 0.7045, step time: 0.4290\n",
      "batch: 10/17, train_dl_loss: 0.7386, train_bce_loss: 1.1609, train_bce_dl_loss: 0.7386, step time: 0.4180\n",
      "batch: 11/17, train_dl_loss: 0.6873, train_bce_loss: 1.1343, train_bce_dl_loss: 0.6873, step time: 0.4371\n",
      "batch: 12/17, train_dl_loss: 0.7681, train_bce_loss: 1.1634, train_bce_dl_loss: 0.7681, step time: 0.4324\n",
      "batch: 13/17, train_dl_loss: 0.7986, train_bce_loss: 1.1579, train_bce_dl_loss: 0.7986, step time: 0.4270\n",
      "batch: 14/17, train_dl_loss: 0.7769, train_bce_loss: 1.1625, train_bce_dl_loss: 0.7769, step time: 0.4330\n",
      "batch: 15/17, train_dl_loss: 0.7034, train_bce_loss: 1.1578, train_bce_dl_loss: 0.7034, step time: 0.4263\n",
      "batch: 16/17, train_dl_loss: 0.7189, train_bce_loss: 1.1600, train_bce_dl_loss: 0.7189, step time: 0.4197\n",
      "batch: 17/17, train_dl_loss: 0.8158, train_bce_loss: 1.1791, train_bce_dl_loss: 0.8158, step time: 0.1114\n",
      "LOSS train DiceLoss: 0.7448, LOSS train BCE: 1.1518, LOSS train BCE-DiceLoss: 0.7448, LOSS val DiceLoss: 0.7492, LOSS val BCE: 1.1569, LOSS val BCE-DiceLoss: 0.7492, METRIC val: 0.1780\n",
      "time consuming of epoch 13 is: 407.9996\n",
      "----------\n",
      "EPOCH 14/80\n",
      "batch: 0/17, train_dl_loss: 0.6784, train_bce_loss: 1.1527, train_bce_dl_loss: 0.6784, step time: 0.4631\n",
      "batch: 1/17, train_dl_loss: 0.7286, train_bce_loss: 1.1667, train_bce_dl_loss: 0.7286, step time: 0.3735\n",
      "batch: 2/17, train_dl_loss: 0.7801, train_bce_loss: 1.1604, train_bce_dl_loss: 0.7801, step time: 0.4402\n",
      "batch: 3/17, train_dl_loss: 0.8033, train_bce_loss: 1.1639, train_bce_dl_loss: 0.8033, step time: 0.3778\n",
      "batch: 4/17, train_dl_loss: 0.6781, train_bce_loss: 1.1668, train_bce_dl_loss: 0.6781, step time: 0.4546\n",
      "batch: 5/17, train_dl_loss: 0.6895, train_bce_loss: 1.1666, train_bce_dl_loss: 0.6895, step time: 0.3798\n",
      "batch: 6/17, train_dl_loss: 0.7028, train_bce_loss: 1.1757, train_bce_dl_loss: 0.7028, step time: 0.4360\n",
      "batch: 7/17, train_dl_loss: 0.6859, train_bce_loss: 1.1639, train_bce_dl_loss: 0.6859, step time: 0.3789\n",
      "batch: 8/17, train_dl_loss: 0.6899, train_bce_loss: 1.1734, train_bce_dl_loss: 0.6899, step time: 0.4251\n",
      "batch: 9/17, train_dl_loss: 0.7190, train_bce_loss: 1.1801, train_bce_dl_loss: 0.7190, step time: 0.3759\n",
      "batch: 10/17, train_dl_loss: 0.7281, train_bce_loss: 1.1785, train_bce_dl_loss: 0.7281, step time: 0.4519\n",
      "batch: 11/17, train_dl_loss: 0.6835, train_bce_loss: 1.1728, train_bce_dl_loss: 0.6835, step time: 0.3911\n",
      "batch: 12/17, train_dl_loss: 0.7306, train_bce_loss: 1.1638, train_bce_dl_loss: 0.7306, step time: 0.4274\n",
      "batch: 13/17, train_dl_loss: 0.8025, train_bce_loss: 1.1736, train_bce_dl_loss: 0.8025, step time: 0.3711\n",
      "batch: 14/17, train_dl_loss: 0.7273, train_bce_loss: 1.1873, train_bce_dl_loss: 0.7273, step time: 0.4311\n",
      "batch: 15/17, train_dl_loss: 0.6742, train_bce_loss: 1.1761, train_bce_dl_loss: 0.6742, step time: 0.3777\n",
      "batch: 16/17, train_dl_loss: 0.6847, train_bce_loss: 1.1799, train_bce_dl_loss: 0.6847, step time: 0.4092\n",
      "batch: 17/17, train_dl_loss: 0.6295, train_bce_loss: 1.1826, train_bce_dl_loss: 0.6295, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.7120, LOSS train BCE: 1.1714, LOSS train BCE-DiceLoss: 0.7120, LOSS val DiceLoss: 0.7250, LOSS val BCE: 1.1765, LOSS val BCE-DiceLoss: 0.7250, METRIC val: 0.2118\n",
      "time consuming of epoch 14 is: 419.4641\n",
      "----------\n",
      "EPOCH 15/80\n",
      "batch: 0/17, train_dl_loss: 0.6746, train_bce_loss: 1.1749, train_bce_dl_loss: 0.6746, step time: 0.4285\n",
      "batch: 1/17, train_dl_loss: 0.6993, train_bce_loss: 1.1860, train_bce_dl_loss: 0.6993, step time: 0.3763\n",
      "batch: 2/17, train_dl_loss: 0.7687, train_bce_loss: 1.1817, train_bce_dl_loss: 0.7687, step time: 0.4189\n",
      "batch: 3/17, train_dl_loss: 0.7761, train_bce_loss: 1.1915, train_bce_dl_loss: 0.7761, step time: 0.3789\n",
      "batch: 4/17, train_dl_loss: 0.6779, train_bce_loss: 1.1835, train_bce_dl_loss: 0.6779, step time: 0.4318\n",
      "batch: 5/17, train_dl_loss: 0.6678, train_bce_loss: 1.1952, train_bce_dl_loss: 0.6678, step time: 0.3736\n",
      "batch: 6/17, train_dl_loss: 0.6974, train_bce_loss: 1.2052, train_bce_dl_loss: 0.6974, step time: 0.4390\n",
      "batch: 7/17, train_dl_loss: 0.6750, train_bce_loss: 1.1902, train_bce_dl_loss: 0.6750, step time: 0.3842\n",
      "batch: 8/17, train_dl_loss: 0.6751, train_bce_loss: 1.1812, train_bce_dl_loss: 0.6751, step time: 0.4316\n",
      "batch: 9/17, train_dl_loss: 0.7426, train_bce_loss: 1.2126, train_bce_dl_loss: 0.7426, step time: 0.3753\n",
      "batch: 10/17, train_dl_loss: 0.7512, train_bce_loss: 1.1938, train_bce_dl_loss: 0.7512, step time: 0.4234\n",
      "batch: 11/17, train_dl_loss: 0.6454, train_bce_loss: 1.1840, train_bce_dl_loss: 0.6454, step time: 0.3804\n",
      "batch: 12/17, train_dl_loss: 0.6774, train_bce_loss: 1.1927, train_bce_dl_loss: 0.6774, step time: 0.4209\n",
      "batch: 13/17, train_dl_loss: 0.8086, train_bce_loss: 1.2001, train_bce_dl_loss: 0.8086, step time: 0.3834\n",
      "batch: 14/17, train_dl_loss: 0.7160, train_bce_loss: 1.2071, train_bce_dl_loss: 0.7160, step time: 0.4409\n",
      "batch: 15/17, train_dl_loss: 0.7036, train_bce_loss: 1.2068, train_bce_dl_loss: 0.7036, step time: 0.3762\n",
      "batch: 16/17, train_dl_loss: 0.6697, train_bce_loss: 1.2022, train_bce_dl_loss: 0.6697, step time: 0.4158\n",
      "batch: 17/17, train_dl_loss: 0.6197, train_bce_loss: 1.1997, train_bce_dl_loss: 0.6197, step time: 0.1123\n",
      "LOSS train DiceLoss: 0.7026, LOSS train BCE: 1.1938, LOSS train BCE-DiceLoss: 0.7026, LOSS val DiceLoss: 0.7549, LOSS val BCE: 1.2018, LOSS val BCE-DiceLoss: 0.7549, METRIC val: 0.1581\n",
      "time consuming of epoch 15 is: 437.1361\n",
      "----------\n",
      "EPOCH 16/80\n",
      "batch: 0/17, train_dl_loss: 0.6593, train_bce_loss: 1.1939, train_bce_dl_loss: 0.6593, step time: 0.4546\n",
      "batch: 1/17, train_dl_loss: 0.7325, train_bce_loss: 1.2101, train_bce_dl_loss: 0.7325, step time: 0.4385\n",
      "batch: 2/17, train_dl_loss: 0.7656, train_bce_loss: 1.1991, train_bce_dl_loss: 0.7656, step time: 0.4368\n",
      "batch: 3/17, train_dl_loss: 0.7234, train_bce_loss: 1.2029, train_bce_dl_loss: 0.7234, step time: 0.3755\n",
      "batch: 4/17, train_dl_loss: 0.6436, train_bce_loss: 1.2027, train_bce_dl_loss: 0.6436, step time: 0.4221\n",
      "batch: 5/17, train_dl_loss: 0.6648, train_bce_loss: 1.2076, train_bce_dl_loss: 0.6648, step time: 0.4248\n",
      "batch: 6/17, train_dl_loss: 0.7322, train_bce_loss: 1.2118, train_bce_dl_loss: 0.7322, step time: 0.4345\n",
      "batch: 7/17, train_dl_loss: 0.6417, train_bce_loss: 1.2123, train_bce_dl_loss: 0.6417, step time: 0.4334\n",
      "batch: 8/17, train_dl_loss: 0.6735, train_bce_loss: 1.2216, train_bce_dl_loss: 0.6735, step time: 0.4411\n",
      "batch: 9/17, train_dl_loss: 0.6927, train_bce_loss: 1.2340, train_bce_dl_loss: 0.6927, step time: 0.4302\n",
      "batch: 10/17, train_dl_loss: 0.6991, train_bce_loss: 1.2234, train_bce_dl_loss: 0.6991, step time: 0.4364\n",
      "batch: 11/17, train_dl_loss: 0.6807, train_bce_loss: 1.2190, train_bce_dl_loss: 0.6807, step time: 0.4470\n",
      "batch: 12/17, train_dl_loss: 0.6716, train_bce_loss: 1.2200, train_bce_dl_loss: 0.6716, step time: 0.4241\n",
      "batch: 13/17, train_dl_loss: 0.7790, train_bce_loss: 1.2204, train_bce_dl_loss: 0.7790, step time: 0.4334\n",
      "batch: 14/17, train_dl_loss: 0.6693, train_bce_loss: 1.2323, train_bce_dl_loss: 0.6693, step time: 0.4315\n",
      "batch: 15/17, train_dl_loss: 0.6300, train_bce_loss: 1.2241, train_bce_dl_loss: 0.6300, step time: 0.4255\n",
      "batch: 16/17, train_dl_loss: 0.6380, train_bce_loss: 1.2255, train_bce_dl_loss: 0.6380, step time: 0.4209\n",
      "batch: 17/17, train_dl_loss: 0.5960, train_bce_loss: 1.2332, train_bce_dl_loss: 0.5960, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.6829, LOSS train BCE: 1.2163, LOSS train BCE-DiceLoss: 0.6829, LOSS val DiceLoss: 0.7034, LOSS val BCE: 1.2189, LOSS val BCE-DiceLoss: 0.7034, METRIC val: 0.2344\n",
      "time consuming of epoch 16 is: 429.5589\n",
      "----------\n",
      "EPOCH 17/80\n",
      "batch: 0/17, train_dl_loss: 0.6082, train_bce_loss: 1.2155, train_bce_dl_loss: 0.6082, step time: 0.4433\n",
      "batch: 1/17, train_dl_loss: 0.6660, train_bce_loss: 1.2237, train_bce_dl_loss: 0.6660, step time: 0.4526\n",
      "batch: 2/17, train_dl_loss: 0.6843, train_bce_loss: 1.2291, train_bce_dl_loss: 0.6843, step time: 0.4222\n",
      "batch: 3/17, train_dl_loss: 0.6581, train_bce_loss: 1.2277, train_bce_dl_loss: 0.6581, step time: 0.3751\n",
      "batch: 4/17, train_dl_loss: 0.6532, train_bce_loss: 1.2327, train_bce_dl_loss: 0.6532, step time: 0.4417\n",
      "batch: 5/17, train_dl_loss: 0.6067, train_bce_loss: 1.2237, train_bce_dl_loss: 0.6067, step time: 0.3956\n",
      "batch: 6/17, train_dl_loss: 0.6996, train_bce_loss: 1.2383, train_bce_dl_loss: 0.6996, step time: 0.4194\n",
      "batch: 7/17, train_dl_loss: 0.6529, train_bce_loss: 1.2270, train_bce_dl_loss: 0.6529, step time: 0.3749\n",
      "batch: 8/17, train_dl_loss: 0.6565, train_bce_loss: 1.2198, train_bce_dl_loss: 0.6565, step time: 0.4186\n",
      "batch: 9/17, train_dl_loss: 0.6673, train_bce_loss: 1.2310, train_bce_dl_loss: 0.6673, step time: 0.3685\n",
      "batch: 10/17, train_dl_loss: 0.6768, train_bce_loss: 1.2364, train_bce_dl_loss: 0.6768, step time: 0.4372\n",
      "batch: 11/17, train_dl_loss: 0.5995, train_bce_loss: 1.2216, train_bce_dl_loss: 0.5995, step time: 0.3787\n",
      "batch: 12/17, train_dl_loss: 0.6435, train_bce_loss: 1.2324, train_bce_dl_loss: 0.6435, step time: 0.4242\n",
      "batch: 13/17, train_dl_loss: 0.7466, train_bce_loss: 1.2386, train_bce_dl_loss: 0.7466, step time: 0.3793\n",
      "batch: 14/17, train_dl_loss: 0.6807, train_bce_loss: 1.2491, train_bce_dl_loss: 0.6807, step time: 0.4177\n",
      "batch: 15/17, train_dl_loss: 0.6312, train_bce_loss: 1.2474, train_bce_dl_loss: 0.6312, step time: 0.3773\n",
      "batch: 16/17, train_dl_loss: 0.6786, train_bce_loss: 1.2373, train_bce_dl_loss: 0.6786, step time: 0.4239\n",
      "batch: 17/17, train_dl_loss: 0.5590, train_bce_loss: 1.2500, train_bce_dl_loss: 0.5590, step time: 0.1118\n",
      "LOSS train DiceLoss: 0.6538, LOSS train BCE: 1.2323, LOSS train BCE-DiceLoss: 0.6538, LOSS val DiceLoss: 0.6924, LOSS val BCE: 1.2395, LOSS val BCE-DiceLoss: 0.6924, METRIC val: 0.2701\n",
      "time consuming of epoch 17 is: 462.9510\n",
      "----------\n",
      "EPOCH 18/80\n",
      "batch: 0/17, train_dl_loss: 0.6187, train_bce_loss: 1.2324, train_bce_dl_loss: 0.6187, step time: 0.4312\n",
      "batch: 1/17, train_dl_loss: 0.6343, train_bce_loss: 1.2559, train_bce_dl_loss: 0.6343, step time: 0.3754\n",
      "batch: 2/17, train_dl_loss: 0.7024, train_bce_loss: 1.2449, train_bce_dl_loss: 0.7024, step time: 0.4319\n",
      "batch: 3/17, train_dl_loss: 0.6961, train_bce_loss: 1.2495, train_bce_dl_loss: 0.6961, step time: 0.3847\n",
      "batch: 4/17, train_dl_loss: 0.5942, train_bce_loss: 1.2584, train_bce_dl_loss: 0.5942, step time: 0.4309\n",
      "batch: 5/17, train_dl_loss: 0.6593, train_bce_loss: 1.2381, train_bce_dl_loss: 0.6593, step time: 0.4279\n",
      "batch: 6/17, train_dl_loss: 0.6458, train_bce_loss: 1.2549, train_bce_dl_loss: 0.6458, step time: 0.4318\n",
      "batch: 7/17, train_dl_loss: 0.5876, train_bce_loss: 1.2450, train_bce_dl_loss: 0.5876, step time: 0.4297\n",
      "batch: 8/17, train_dl_loss: 0.6808, train_bce_loss: 1.2434, train_bce_dl_loss: 0.6808, step time: 0.4155\n",
      "batch: 9/17, train_dl_loss: 0.6294, train_bce_loss: 1.2573, train_bce_dl_loss: 0.6294, step time: 0.4416\n",
      "batch: 10/17, train_dl_loss: 0.6594, train_bce_loss: 1.2493, train_bce_dl_loss: 0.6594, step time: 0.4211\n",
      "batch: 11/17, train_dl_loss: 0.6477, train_bce_loss: 1.2447, train_bce_dl_loss: 0.6477, step time: 0.4232\n",
      "batch: 12/17, train_dl_loss: 0.6316, train_bce_loss: 1.2455, train_bce_dl_loss: 0.6316, step time: 0.4354\n",
      "batch: 13/17, train_dl_loss: 0.7711, train_bce_loss: 1.2574, train_bce_dl_loss: 0.7711, step time: 0.3816\n",
      "batch: 14/17, train_dl_loss: 0.6906, train_bce_loss: 1.2639, train_bce_dl_loss: 0.6906, step time: 0.4308\n",
      "batch: 15/17, train_dl_loss: 0.6621, train_bce_loss: 1.2576, train_bce_dl_loss: 0.6621, step time: 0.3787\n",
      "batch: 16/17, train_dl_loss: 0.5937, train_bce_loss: 1.2587, train_bce_dl_loss: 0.5937, step time: 0.4172\n",
      "batch: 17/17, train_dl_loss: 0.5938, train_bce_loss: 1.2563, train_bce_dl_loss: 0.5938, step time: 0.1123\n",
      "LOSS train DiceLoss: 0.6499, LOSS train BCE: 1.2507, LOSS train BCE-DiceLoss: 0.6499, LOSS val DiceLoss: 0.6734, LOSS val BCE: 1.2581, LOSS val BCE-DiceLoss: 0.6734, METRIC val: 0.2858\n",
      "time consuming of epoch 18 is: 455.2051\n",
      "----------\n",
      "EPOCH 19/80\n",
      "batch: 0/17, train_dl_loss: 0.6139, train_bce_loss: 1.2713, train_bce_dl_loss: 0.6139, step time: 0.4343\n",
      "batch: 1/17, train_dl_loss: 0.6356, train_bce_loss: 1.2761, train_bce_dl_loss: 0.6356, step time: 0.4031\n",
      "batch: 2/17, train_dl_loss: 0.7041, train_bce_loss: 1.2593, train_bce_dl_loss: 0.7041, step time: 0.4148\n",
      "batch: 3/17, train_dl_loss: 0.6737, train_bce_loss: 1.2553, train_bce_dl_loss: 0.6737, step time: 0.3731\n",
      "batch: 4/17, train_dl_loss: 0.6529, train_bce_loss: 1.2669, train_bce_dl_loss: 0.6529, step time: 0.4434\n",
      "batch: 5/17, train_dl_loss: 0.6345, train_bce_loss: 1.2598, train_bce_dl_loss: 0.6345, step time: 0.3936\n",
      "batch: 6/17, train_dl_loss: 0.6987, train_bce_loss: 1.2702, train_bce_dl_loss: 0.6987, step time: 0.4195\n",
      "batch: 7/17, train_dl_loss: 0.6073, train_bce_loss: 1.2598, train_bce_dl_loss: 0.6073, step time: 0.3849\n",
      "batch: 8/17, train_dl_loss: 0.6485, train_bce_loss: 1.2550, train_bce_dl_loss: 0.6485, step time: 0.4479\n",
      "batch: 9/17, train_dl_loss: 0.6036, train_bce_loss: 1.2634, train_bce_dl_loss: 0.6036, step time: 0.3833\n",
      "batch: 10/17, train_dl_loss: 0.6475, train_bce_loss: 1.2686, train_bce_dl_loss: 0.6475, step time: 0.4354\n",
      "batch: 11/17, train_dl_loss: 0.5642, train_bce_loss: 1.2541, train_bce_dl_loss: 0.5642, step time: 0.3824\n",
      "batch: 12/17, train_dl_loss: 0.6676, train_bce_loss: 1.2656, train_bce_dl_loss: 0.6676, step time: 0.4229\n",
      "batch: 13/17, train_dl_loss: 0.7590, train_bce_loss: 1.2791, train_bce_dl_loss: 0.7590, step time: 0.3777\n",
      "batch: 14/17, train_dl_loss: 0.6557, train_bce_loss: 1.2810, train_bce_dl_loss: 0.6557, step time: 0.4248\n",
      "batch: 15/17, train_dl_loss: 0.6350, train_bce_loss: 1.2848, train_bce_dl_loss: 0.6350, step time: 0.3787\n",
      "batch: 16/17, train_dl_loss: 0.6078, train_bce_loss: 1.2775, train_bce_dl_loss: 0.6078, step time: 0.4231\n",
      "batch: 17/17, train_dl_loss: 0.5424, train_bce_loss: 1.2716, train_bce_dl_loss: 0.5424, step time: 0.1126\n",
      "LOSS train DiceLoss: 0.6418, LOSS train BCE: 1.2678, LOSS train BCE-DiceLoss: 0.6418, LOSS val DiceLoss: 0.6778, LOSS val BCE: 1.2728, LOSS val BCE-DiceLoss: 0.6778, METRIC val: 0.2825\n",
      "time consuming of epoch 19 is: 449.4034\n",
      "----------\n",
      "EPOCH 20/80\n",
      "batch: 0/17, train_dl_loss: 0.6890, train_bce_loss: 1.2818, train_bce_dl_loss: 0.6890, step time: 0.4249\n",
      "batch: 1/17, train_dl_loss: 0.5992, train_bce_loss: 1.2796, train_bce_dl_loss: 0.5992, step time: 0.3807\n",
      "batch: 2/17, train_dl_loss: 0.6658, train_bce_loss: 1.2813, train_bce_dl_loss: 0.6658, step time: 0.4381\n",
      "batch: 3/17, train_dl_loss: 0.6530, train_bce_loss: 1.2868, train_bce_dl_loss: 0.6530, step time: 0.3782\n",
      "batch: 4/17, train_dl_loss: 0.6107, train_bce_loss: 1.2799, train_bce_dl_loss: 0.6107, step time: 0.4355\n",
      "batch: 5/17, train_dl_loss: 0.5959, train_bce_loss: 1.2723, train_bce_dl_loss: 0.5959, step time: 0.3782\n",
      "batch: 6/17, train_dl_loss: 0.6446, train_bce_loss: 1.2855, train_bce_dl_loss: 0.6446, step time: 0.4555\n",
      "batch: 7/17, train_dl_loss: 0.5720, train_bce_loss: 1.2650, train_bce_dl_loss: 0.5720, step time: 0.3810\n",
      "batch: 8/17, train_dl_loss: 0.6100, train_bce_loss: 1.2797, train_bce_dl_loss: 0.6100, step time: 0.4298\n",
      "batch: 9/17, train_dl_loss: 0.6956, train_bce_loss: 1.2866, train_bce_dl_loss: 0.6956, step time: 0.3815\n",
      "batch: 10/17, train_dl_loss: 0.6918, train_bce_loss: 1.2784, train_bce_dl_loss: 0.6918, step time: 0.4454\n",
      "batch: 11/17, train_dl_loss: 0.5836, train_bce_loss: 1.2643, train_bce_dl_loss: 0.5836, step time: 0.3787\n",
      "batch: 12/17, train_dl_loss: 0.6193, train_bce_loss: 1.2729, train_bce_dl_loss: 0.6193, step time: 0.4408\n",
      "batch: 13/17, train_dl_loss: 0.7714, train_bce_loss: 1.2881, train_bce_dl_loss: 0.7714, step time: 0.3828\n",
      "batch: 14/17, train_dl_loss: 0.6509, train_bce_loss: 1.2855, train_bce_dl_loss: 0.6509, step time: 0.4279\n",
      "batch: 15/17, train_dl_loss: 0.5829, train_bce_loss: 1.2874, train_bce_dl_loss: 0.5829, step time: 0.3756\n",
      "batch: 16/17, train_dl_loss: 0.6012, train_bce_loss: 1.2912, train_bce_dl_loss: 0.6012, step time: 0.4210\n",
      "batch: 17/17, train_dl_loss: 0.5550, train_bce_loss: 1.2964, train_bce_dl_loss: 0.5550, step time: 0.1123\n",
      "LOSS train DiceLoss: 0.6329, LOSS train BCE: 1.2813, LOSS train BCE-DiceLoss: 0.6329, LOSS val DiceLoss: 0.6656, LOSS val BCE: 1.2848, LOSS val BCE-DiceLoss: 0.6656, METRIC val: 0.2915\n",
      "time consuming of epoch 20 is: 414.6649\n",
      "----------\n",
      "EPOCH 21/80\n",
      "batch: 0/17, train_dl_loss: 0.5945, train_bce_loss: 1.2792, train_bce_dl_loss: 0.5945, step time: 0.4674\n",
      "batch: 1/17, train_dl_loss: 0.5847, train_bce_loss: 1.3031, train_bce_dl_loss: 0.5847, step time: 0.3753\n",
      "batch: 2/17, train_dl_loss: 0.6381, train_bce_loss: 1.2871, train_bce_dl_loss: 0.6381, step time: 0.4287\n",
      "batch: 3/17, train_dl_loss: 0.6666, train_bce_loss: 1.2909, train_bce_dl_loss: 0.6666, step time: 0.3757\n",
      "batch: 4/17, train_dl_loss: 0.5599, train_bce_loss: 1.2825, train_bce_dl_loss: 0.5599, step time: 0.4219\n",
      "batch: 5/17, train_dl_loss: 0.5818, train_bce_loss: 1.2884, train_bce_dl_loss: 0.5818, step time: 0.4363\n",
      "batch: 6/17, train_dl_loss: 0.6483, train_bce_loss: 1.3064, train_bce_dl_loss: 0.6483, step time: 0.4298\n",
      "batch: 7/17, train_dl_loss: 0.5466, train_bce_loss: 1.2858, train_bce_dl_loss: 0.5466, step time: 0.4373\n",
      "batch: 8/17, train_dl_loss: 0.6259, train_bce_loss: 1.2989, train_bce_dl_loss: 0.6259, step time: 0.4244\n",
      "batch: 9/17, train_dl_loss: 0.5808, train_bce_loss: 1.2897, train_bce_dl_loss: 0.5808, step time: 0.4297\n",
      "batch: 10/17, train_dl_loss: 0.6367, train_bce_loss: 1.3016, train_bce_dl_loss: 0.6367, step time: 0.4333\n",
      "batch: 11/17, train_dl_loss: 0.5697, train_bce_loss: 1.2876, train_bce_dl_loss: 0.5697, step time: 0.4274\n",
      "batch: 12/17, train_dl_loss: 0.5934, train_bce_loss: 1.2858, train_bce_dl_loss: 0.5934, step time: 0.4368\n",
      "batch: 13/17, train_dl_loss: 0.7728, train_bce_loss: 1.3061, train_bce_dl_loss: 0.7728, step time: 0.4358\n",
      "batch: 14/17, train_dl_loss: 0.5711, train_bce_loss: 1.3108, train_bce_dl_loss: 0.5711, step time: 0.4208\n",
      "batch: 15/17, train_dl_loss: 0.6211, train_bce_loss: 1.3050, train_bce_dl_loss: 0.6211, step time: 0.4350\n",
      "batch: 16/17, train_dl_loss: 0.5567, train_bce_loss: 1.2984, train_bce_dl_loss: 0.5567, step time: 0.4330\n",
      "batch: 17/17, train_dl_loss: 0.5694, train_bce_loss: 1.3022, train_bce_dl_loss: 0.5694, step time: 0.1112\n",
      "LOSS train DiceLoss: 0.6066, LOSS train BCE: 1.2950, LOSS train BCE-DiceLoss: 0.6066, LOSS val DiceLoss: 0.6426, LOSS val BCE: 1.2999, LOSS val BCE-DiceLoss: 0.6426, METRIC val: 0.3181\n",
      "time consuming of epoch 21 is: 410.3143\n",
      "----------\n",
      "EPOCH 22/80\n",
      "batch: 0/17, train_dl_loss: 0.5467, train_bce_loss: 1.2902, train_bce_dl_loss: 0.5467, step time: 0.4422\n",
      "batch: 1/17, train_dl_loss: 0.5960, train_bce_loss: 1.3066, train_bce_dl_loss: 0.5960, step time: 0.3789\n",
      "batch: 2/17, train_dl_loss: 0.6477, train_bce_loss: 1.3040, train_bce_dl_loss: 0.6477, step time: 0.4390\n",
      "batch: 3/17, train_dl_loss: 0.6535, train_bce_loss: 1.3027, train_bce_dl_loss: 0.6535, step time: 0.3797\n",
      "batch: 4/17, train_dl_loss: 0.5819, train_bce_loss: 1.2958, train_bce_dl_loss: 0.5819, step time: 0.4440\n",
      "batch: 5/17, train_dl_loss: 0.5452, train_bce_loss: 1.2986, train_bce_dl_loss: 0.5452, step time: 0.3841\n",
      "batch: 6/17, train_dl_loss: 0.6148, train_bce_loss: 1.3076, train_bce_dl_loss: 0.6148, step time: 0.4245\n",
      "batch: 7/17, train_dl_loss: 0.5300, train_bce_loss: 1.2875, train_bce_dl_loss: 0.5300, step time: 0.3811\n",
      "batch: 8/17, train_dl_loss: 0.5825, train_bce_loss: 1.2889, train_bce_dl_loss: 0.5825, step time: 0.4223\n",
      "batch: 9/17, train_dl_loss: 0.5540, train_bce_loss: 1.3074, train_bce_dl_loss: 0.5540, step time: 0.3773\n",
      "batch: 10/17, train_dl_loss: 0.6753, train_bce_loss: 1.3167, train_bce_dl_loss: 0.6753, step time: 0.4261\n",
      "batch: 11/17, train_dl_loss: 0.6015, train_bce_loss: 1.2936, train_bce_dl_loss: 0.6015, step time: 0.3931\n",
      "batch: 12/17, train_dl_loss: 0.5985, train_bce_loss: 1.3222, train_bce_dl_loss: 0.5985, step time: 0.4619\n",
      "batch: 13/17, train_dl_loss: 0.7702, train_bce_loss: 1.3174, train_bce_dl_loss: 0.7702, step time: 0.3728\n",
      "batch: 14/17, train_dl_loss: 0.6154, train_bce_loss: 1.3231, train_bce_dl_loss: 0.6154, step time: 0.4328\n",
      "batch: 15/17, train_dl_loss: 0.5678, train_bce_loss: 1.3024, train_bce_dl_loss: 0.5678, step time: 0.3802\n",
      "batch: 16/17, train_dl_loss: 0.5757, train_bce_loss: 1.3191, train_bce_dl_loss: 0.5757, step time: 0.4100\n",
      "batch: 17/17, train_dl_loss: 0.4886, train_bce_loss: 1.3192, train_bce_dl_loss: 0.4886, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5970, LOSS train BCE: 1.3057, LOSS train BCE-DiceLoss: 0.5970, LOSS val DiceLoss: 0.6467, LOSS val BCE: 1.3132, LOSS val BCE-DiceLoss: 0.6467, METRIC val: 0.3119\n",
      "time consuming of epoch 22 is: 388.7810\n",
      "----------\n",
      "EPOCH 23/80\n",
      "batch: 0/17, train_dl_loss: 0.6096, train_bce_loss: 1.3215, train_bce_dl_loss: 0.6096, step time: 0.4251\n",
      "batch: 1/17, train_dl_loss: 0.5846, train_bce_loss: 1.3188, train_bce_dl_loss: 0.5846, step time: 0.3751\n",
      "batch: 2/17, train_dl_loss: 0.6367, train_bce_loss: 1.3209, train_bce_dl_loss: 0.6367, step time: 0.4191\n",
      "batch: 3/17, train_dl_loss: 0.6497, train_bce_loss: 1.3255, train_bce_dl_loss: 0.6497, step time: 0.3693\n",
      "batch: 4/17, train_dl_loss: 0.5275, train_bce_loss: 1.3203, train_bce_dl_loss: 0.5275, step time: 0.4357\n",
      "batch: 5/17, train_dl_loss: 0.5453, train_bce_loss: 1.3145, train_bce_dl_loss: 0.5453, step time: 0.3840\n",
      "batch: 6/17, train_dl_loss: 0.6330, train_bce_loss: 1.3150, train_bce_dl_loss: 0.6330, step time: 0.4410\n",
      "batch: 7/17, train_dl_loss: 0.5544, train_bce_loss: 1.2962, train_bce_dl_loss: 0.5544, step time: 0.3837\n",
      "batch: 8/17, train_dl_loss: 0.6006, train_bce_loss: 1.2968, train_bce_dl_loss: 0.6006, step time: 0.4317\n",
      "batch: 9/17, train_dl_loss: 0.5928, train_bce_loss: 1.3271, train_bce_dl_loss: 0.5928, step time: 0.3808\n",
      "batch: 10/17, train_dl_loss: 0.6330, train_bce_loss: 1.3128, train_bce_dl_loss: 0.6330, step time: 0.4235\n",
      "batch: 11/17, train_dl_loss: 0.5558, train_bce_loss: 1.3045, train_bce_dl_loss: 0.5558, step time: 0.4438\n",
      "batch: 12/17, train_dl_loss: 0.5524, train_bce_loss: 1.3095, train_bce_dl_loss: 0.5524, step time: 0.4251\n",
      "batch: 13/17, train_dl_loss: 0.7309, train_bce_loss: 1.3269, train_bce_dl_loss: 0.7309, step time: 0.3743\n",
      "batch: 14/17, train_dl_loss: 0.6457, train_bce_loss: 1.3297, train_bce_dl_loss: 0.6457, step time: 0.4343\n",
      "batch: 15/17, train_dl_loss: 0.5807, train_bce_loss: 1.3140, train_bce_dl_loss: 0.5807, step time: 0.3841\n",
      "batch: 16/17, train_dl_loss: 0.5856, train_bce_loss: 1.3175, train_bce_dl_loss: 0.5856, step time: 0.4184\n",
      "batch: 17/17, train_dl_loss: 0.4800, train_bce_loss: 1.3142, train_bce_dl_loss: 0.4800, step time: 0.1119\n",
      "LOSS train DiceLoss: 0.5943, LOSS train BCE: 1.3159, LOSS train BCE-DiceLoss: 0.5943, LOSS val DiceLoss: 0.6373, LOSS val BCE: 1.3157, LOSS val BCE-DiceLoss: 0.6373, METRIC val: 0.3272\n",
      "time consuming of epoch 23 is: 423.2493\n",
      "----------\n",
      "EPOCH 24/80\n",
      "batch: 0/17, train_dl_loss: 0.5390, train_bce_loss: 1.3098, train_bce_dl_loss: 0.5390, step time: 0.4465\n",
      "batch: 1/17, train_dl_loss: 0.5626, train_bce_loss: 1.3203, train_bce_dl_loss: 0.5626, step time: 0.3879\n",
      "batch: 2/17, train_dl_loss: 0.6546, train_bce_loss: 1.3255, train_bce_dl_loss: 0.6546, step time: 0.4384\n",
      "batch: 3/17, train_dl_loss: 0.6167, train_bce_loss: 1.3293, train_bce_dl_loss: 0.6167, step time: 0.3758\n",
      "batch: 4/17, train_dl_loss: 0.5197, train_bce_loss: 1.3295, train_bce_dl_loss: 0.5197, step time: 0.4209\n",
      "batch: 5/17, train_dl_loss: 0.5420, train_bce_loss: 1.3127, train_bce_dl_loss: 0.5420, step time: 0.3752\n",
      "batch: 6/17, train_dl_loss: 0.6808, train_bce_loss: 1.3433, train_bce_dl_loss: 0.6808, step time: 0.4265\n",
      "batch: 7/17, train_dl_loss: 0.5725, train_bce_loss: 1.3323, train_bce_dl_loss: 0.5725, step time: 0.3771\n",
      "batch: 8/17, train_dl_loss: 0.6223, train_bce_loss: 1.3165, train_bce_dl_loss: 0.6223, step time: 0.4337\n",
      "batch: 9/17, train_dl_loss: 0.5811, train_bce_loss: 1.3311, train_bce_dl_loss: 0.5811, step time: 0.3796\n",
      "batch: 10/17, train_dl_loss: 0.6055, train_bce_loss: 1.3163, train_bce_dl_loss: 0.6055, step time: 0.4284\n",
      "batch: 11/17, train_dl_loss: 0.5267, train_bce_loss: 1.3209, train_bce_dl_loss: 0.5267, step time: 0.4268\n",
      "batch: 12/17, train_dl_loss: 0.6160, train_bce_loss: 1.3309, train_bce_dl_loss: 0.6160, step time: 0.4387\n",
      "batch: 13/17, train_dl_loss: 0.7228, train_bce_loss: 1.3334, train_bce_dl_loss: 0.7228, step time: 0.3803\n",
      "batch: 14/17, train_dl_loss: 0.5825, train_bce_loss: 1.3404, train_bce_dl_loss: 0.5825, step time: 0.4190\n",
      "batch: 15/17, train_dl_loss: 0.5783, train_bce_loss: 1.3384, train_bce_dl_loss: 0.5783, step time: 0.3767\n",
      "batch: 16/17, train_dl_loss: 0.5755, train_bce_loss: 1.3374, train_bce_dl_loss: 0.5755, step time: 0.4270\n",
      "batch: 17/17, train_dl_loss: 0.5344, train_bce_loss: 1.3335, train_bce_dl_loss: 0.5344, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5907, LOSS train BCE: 1.3279, LOSS train BCE-DiceLoss: 0.5907, LOSS val DiceLoss: 0.6289, LOSS val BCE: 1.3309, LOSS val BCE-DiceLoss: 0.6289, METRIC val: 0.3343\n",
      "time consuming of epoch 24 is: 446.8468\n",
      "----------\n",
      "EPOCH 25/80\n",
      "batch: 0/17, train_dl_loss: 0.5818, train_bce_loss: 1.3350, train_bce_dl_loss: 0.5818, step time: 0.4324\n",
      "batch: 1/17, train_dl_loss: 0.6052, train_bce_loss: 1.3471, train_bce_dl_loss: 0.6052, step time: 0.3787\n",
      "batch: 2/17, train_dl_loss: 0.6292, train_bce_loss: 1.3294, train_bce_dl_loss: 0.6292, step time: 0.4315\n",
      "batch: 3/17, train_dl_loss: 0.6533, train_bce_loss: 1.3494, train_bce_dl_loss: 0.6533, step time: 0.3830\n",
      "batch: 4/17, train_dl_loss: 0.5469, train_bce_loss: 1.3380, train_bce_dl_loss: 0.5469, step time: 0.4196\n",
      "batch: 5/17, train_dl_loss: 0.5394, train_bce_loss: 1.3264, train_bce_dl_loss: 0.5394, step time: 0.3714\n",
      "batch: 6/17, train_dl_loss: 0.6239, train_bce_loss: 1.3432, train_bce_dl_loss: 0.6239, step time: 0.4298\n",
      "batch: 7/17, train_dl_loss: 0.4986, train_bce_loss: 1.3199, train_bce_dl_loss: 0.4986, step time: 0.3752\n",
      "batch: 8/17, train_dl_loss: 0.5459, train_bce_loss: 1.3228, train_bce_dl_loss: 0.5459, step time: 0.4378\n",
      "batch: 9/17, train_dl_loss: 0.5630, train_bce_loss: 1.3465, train_bce_dl_loss: 0.5630, step time: 0.3771\n",
      "batch: 10/17, train_dl_loss: 0.6308, train_bce_loss: 1.3364, train_bce_dl_loss: 0.6308, step time: 0.4446\n",
      "batch: 11/17, train_dl_loss: 0.5350, train_bce_loss: 1.3282, train_bce_dl_loss: 0.5350, step time: 0.4216\n",
      "batch: 12/17, train_dl_loss: 0.5404, train_bce_loss: 1.3308, train_bce_dl_loss: 0.5404, step time: 0.4401\n",
      "batch: 13/17, train_dl_loss: 0.7642, train_bce_loss: 1.3550, train_bce_dl_loss: 0.7642, step time: 0.4246\n",
      "batch: 14/17, train_dl_loss: 0.6397, train_bce_loss: 1.3569, train_bce_dl_loss: 0.6397, step time: 0.4331\n",
      "batch: 15/17, train_dl_loss: 0.5284, train_bce_loss: 1.3343, train_bce_dl_loss: 0.5284, step time: 0.4230\n",
      "batch: 16/17, train_dl_loss: 0.5329, train_bce_loss: 1.3445, train_bce_dl_loss: 0.5329, step time: 0.4200\n",
      "batch: 17/17, train_dl_loss: 0.5520, train_bce_loss: 1.3340, train_bce_dl_loss: 0.5520, step time: 0.1125\n",
      "LOSS train DiceLoss: 0.5839, LOSS train BCE: 1.3377, LOSS train BCE-DiceLoss: 0.5839, LOSS val DiceLoss: 0.6205, LOSS val BCE: 1.3391, LOSS val BCE-DiceLoss: 0.6205, METRIC val: 0.3416\n",
      "time consuming of epoch 25 is: 431.3438\n",
      "----------\n",
      "EPOCH 26/80\n",
      "batch: 0/17, train_dl_loss: 0.5521, train_bce_loss: 1.3320, train_bce_dl_loss: 0.5521, step time: 0.4226\n",
      "batch: 1/17, train_dl_loss: 0.5695, train_bce_loss: 1.3520, train_bce_dl_loss: 0.5695, step time: 0.3690\n",
      "batch: 2/17, train_dl_loss: 0.5900, train_bce_loss: 1.3467, train_bce_dl_loss: 0.5900, step time: 0.4379\n",
      "batch: 3/17, train_dl_loss: 0.5671, train_bce_loss: 1.3391, train_bce_dl_loss: 0.5671, step time: 0.3778\n",
      "batch: 4/17, train_dl_loss: 0.5232, train_bce_loss: 1.3307, train_bce_dl_loss: 0.5232, step time: 0.4357\n",
      "batch: 5/17, train_dl_loss: 0.5227, train_bce_loss: 1.3433, train_bce_dl_loss: 0.5227, step time: 0.3792\n",
      "batch: 6/17, train_dl_loss: 0.5921, train_bce_loss: 1.3479, train_bce_dl_loss: 0.5921, step time: 0.4244\n",
      "batch: 7/17, train_dl_loss: 0.5181, train_bce_loss: 1.3200, train_bce_dl_loss: 0.5181, step time: 0.3750\n",
      "batch: 8/17, train_dl_loss: 0.5284, train_bce_loss: 1.3363, train_bce_dl_loss: 0.5284, step time: 0.4350\n",
      "batch: 9/17, train_dl_loss: 0.5919, train_bce_loss: 1.3498, train_bce_dl_loss: 0.5919, step time: 0.3697\n",
      "batch: 10/17, train_dl_loss: 0.6612, train_bce_loss: 1.3423, train_bce_dl_loss: 0.6612, step time: 0.4482\n",
      "batch: 11/17, train_dl_loss: 0.5420, train_bce_loss: 1.3486, train_bce_dl_loss: 0.5420, step time: 0.3866\n",
      "batch: 12/17, train_dl_loss: 0.6339, train_bce_loss: 1.3704, train_bce_dl_loss: 0.6339, step time: 0.4187\n",
      "batch: 13/17, train_dl_loss: 0.7083, train_bce_loss: 1.3529, train_bce_dl_loss: 0.7083, step time: 0.3775\n",
      "batch: 14/17, train_dl_loss: 0.5493, train_bce_loss: 1.3609, train_bce_dl_loss: 0.5493, step time: 0.4348\n",
      "batch: 15/17, train_dl_loss: 0.5149, train_bce_loss: 1.3587, train_bce_dl_loss: 0.5149, step time: 0.3762\n",
      "batch: 16/17, train_dl_loss: 0.5144, train_bce_loss: 1.3548, train_bce_dl_loss: 0.5144, step time: 0.4168\n",
      "batch: 17/17, train_dl_loss: 0.4952, train_bce_loss: 1.3467, train_bce_dl_loss: 0.4952, step time: 0.1132\n",
      "LOSS train DiceLoss: 0.5652, LOSS train BCE: 1.3463, LOSS train BCE-DiceLoss: 0.5652, LOSS val DiceLoss: 0.6203, LOSS val BCE: 1.3480, LOSS val BCE-DiceLoss: 0.6203, METRIC val: 0.3427\n",
      "time consuming of epoch 26 is: 485.9338\n",
      "----------\n",
      "EPOCH 27/80\n",
      "batch: 0/17, train_dl_loss: 0.5569, train_bce_loss: 1.3497, train_bce_dl_loss: 0.5569, step time: 0.4173\n",
      "batch: 1/17, train_dl_loss: 0.5558, train_bce_loss: 1.3565, train_bce_dl_loss: 0.5558, step time: 0.3786\n",
      "batch: 2/17, train_dl_loss: 0.5772, train_bce_loss: 1.3544, train_bce_dl_loss: 0.5772, step time: 0.4264\n",
      "batch: 3/17, train_dl_loss: 0.6438, train_bce_loss: 1.3601, train_bce_dl_loss: 0.6438, step time: 0.3731\n",
      "batch: 4/17, train_dl_loss: 0.5128, train_bce_loss: 1.3499, train_bce_dl_loss: 0.5128, step time: 0.4187\n",
      "batch: 5/17, train_dl_loss: 0.5151, train_bce_loss: 1.3455, train_bce_dl_loss: 0.5151, step time: 0.4292\n",
      "batch: 6/17, train_dl_loss: 0.5899, train_bce_loss: 1.3509, train_bce_dl_loss: 0.5899, step time: 0.4584\n",
      "batch: 7/17, train_dl_loss: 0.5312, train_bce_loss: 1.3539, train_bce_dl_loss: 0.5312, step time: 0.4251\n",
      "batch: 8/17, train_dl_loss: 0.5715, train_bce_loss: 1.3442, train_bce_dl_loss: 0.5715, step time: 0.4336\n",
      "batch: 9/17, train_dl_loss: 0.5789, train_bce_loss: 1.3535, train_bce_dl_loss: 0.5789, step time: 0.4252\n",
      "batch: 10/17, train_dl_loss: 0.6144, train_bce_loss: 1.3560, train_bce_dl_loss: 0.6144, step time: 0.4304\n",
      "batch: 11/17, train_dl_loss: 0.5334, train_bce_loss: 1.3510, train_bce_dl_loss: 0.5334, step time: 0.4309\n",
      "batch: 12/17, train_dl_loss: 0.5331, train_bce_loss: 1.3552, train_bce_dl_loss: 0.5331, step time: 0.4415\n",
      "batch: 13/17, train_dl_loss: 0.7071, train_bce_loss: 1.3699, train_bce_dl_loss: 0.7071, step time: 0.3791\n",
      "batch: 14/17, train_dl_loss: 0.6262, train_bce_loss: 1.3689, train_bce_dl_loss: 0.6262, step time: 0.4266\n",
      "batch: 15/17, train_dl_loss: 0.5229, train_bce_loss: 1.3713, train_bce_dl_loss: 0.5229, step time: 0.3801\n",
      "batch: 16/17, train_dl_loss: 0.5220, train_bce_loss: 1.3623, train_bce_dl_loss: 0.5220, step time: 0.4180\n",
      "batch: 17/17, train_dl_loss: 0.5182, train_bce_loss: 1.3584, train_bce_dl_loss: 0.5182, step time: 0.1116\n",
      "LOSS train DiceLoss: 0.5672, LOSS train BCE: 1.3562, LOSS train BCE-DiceLoss: 0.5672, LOSS val DiceLoss: 0.6038, LOSS val BCE: 1.3571, LOSS val BCE-DiceLoss: 0.6038, METRIC val: 0.3629\n",
      "time consuming of epoch 27 is: 475.6667\n",
      "----------\n",
      "EPOCH 28/80\n",
      "batch: 0/17, train_dl_loss: 0.6014, train_bce_loss: 1.3645, train_bce_dl_loss: 0.6014, step time: 0.4390\n",
      "batch: 1/17, train_dl_loss: 0.5055, train_bce_loss: 1.3681, train_bce_dl_loss: 0.5055, step time: 0.3776\n",
      "batch: 2/17, train_dl_loss: 0.5851, train_bce_loss: 1.3560, train_bce_dl_loss: 0.5851, step time: 0.4404\n",
      "batch: 3/17, train_dl_loss: 0.6371, train_bce_loss: 1.3657, train_bce_dl_loss: 0.6371, step time: 0.3714\n",
      "batch: 4/17, train_dl_loss: 0.5361, train_bce_loss: 1.3469, train_bce_dl_loss: 0.5361, step time: 0.4260\n",
      "batch: 5/17, train_dl_loss: 0.5184, train_bce_loss: 1.3541, train_bce_dl_loss: 0.5184, step time: 0.3861\n",
      "batch: 6/17, train_dl_loss: 0.5826, train_bce_loss: 1.3602, train_bce_dl_loss: 0.5826, step time: 0.4241\n",
      "batch: 7/17, train_dl_loss: 0.5510, train_bce_loss: 1.3591, train_bce_dl_loss: 0.5510, step time: 0.3838\n",
      "batch: 8/17, train_dl_loss: 0.5189, train_bce_loss: 1.3485, train_bce_dl_loss: 0.5189, step time: 0.4387\n",
      "batch: 9/17, train_dl_loss: 0.5273, train_bce_loss: 1.3494, train_bce_dl_loss: 0.5273, step time: 0.3770\n",
      "batch: 10/17, train_dl_loss: 0.6516, train_bce_loss: 1.3668, train_bce_dl_loss: 0.6516, step time: 0.4370\n",
      "batch: 11/17, train_dl_loss: 0.5319, train_bce_loss: 1.3306, train_bce_dl_loss: 0.5319, step time: 0.3842\n",
      "batch: 12/17, train_dl_loss: 0.5625, train_bce_loss: 1.3482, train_bce_dl_loss: 0.5625, step time: 0.4426\n",
      "batch: 13/17, train_dl_loss: 0.7030, train_bce_loss: 1.3657, train_bce_dl_loss: 0.7030, step time: 0.3820\n",
      "batch: 14/17, train_dl_loss: 0.5522, train_bce_loss: 1.3720, train_bce_dl_loss: 0.5522, step time: 0.4258\n",
      "batch: 15/17, train_dl_loss: 0.5563, train_bce_loss: 1.3631, train_bce_dl_loss: 0.5563, step time: 0.3721\n",
      "batch: 16/17, train_dl_loss: 0.5170, train_bce_loss: 1.3693, train_bce_dl_loss: 0.5170, step time: 0.4141\n",
      "batch: 17/17, train_dl_loss: 0.4711, train_bce_loss: 1.3764, train_bce_dl_loss: 0.4711, step time: 0.1114\n",
      "LOSS train DiceLoss: 0.5616, LOSS train BCE: 1.3591, LOSS train BCE-DiceLoss: 0.5616, LOSS val DiceLoss: 0.6149, LOSS val BCE: 1.3646, LOSS val BCE-DiceLoss: 0.6149, METRIC val: 0.3458\n",
      "time consuming of epoch 28 is: 445.2951\n",
      "----------\n",
      "EPOCH 29/80\n",
      "batch: 0/17, train_dl_loss: 0.5500, train_bce_loss: 1.3642, train_bce_dl_loss: 0.5500, step time: 0.4345\n",
      "batch: 1/17, train_dl_loss: 0.5272, train_bce_loss: 1.3617, train_bce_dl_loss: 0.5272, step time: 0.3914\n",
      "batch: 2/17, train_dl_loss: 0.5549, train_bce_loss: 1.3648, train_bce_dl_loss: 0.5549, step time: 0.4407\n",
      "batch: 3/17, train_dl_loss: 0.6357, train_bce_loss: 1.3833, train_bce_dl_loss: 0.6357, step time: 0.3818\n",
      "batch: 4/17, train_dl_loss: 0.5427, train_bce_loss: 1.3659, train_bce_dl_loss: 0.5427, step time: 0.4537\n",
      "batch: 5/17, train_dl_loss: 0.5047, train_bce_loss: 1.3589, train_bce_dl_loss: 0.5047, step time: 0.3865\n",
      "batch: 6/17, train_dl_loss: 0.5627, train_bce_loss: 1.3662, train_bce_dl_loss: 0.5627, step time: 0.4451\n",
      "batch: 7/17, train_dl_loss: 0.5180, train_bce_loss: 1.3541, train_bce_dl_loss: 0.5180, step time: 0.4469\n",
      "batch: 8/17, train_dl_loss: 0.5398, train_bce_loss: 1.3456, train_bce_dl_loss: 0.5398, step time: 0.4301\n",
      "batch: 9/17, train_dl_loss: 0.5211, train_bce_loss: 1.3599, train_bce_dl_loss: 0.5211, step time: 0.4385\n",
      "batch: 10/17, train_dl_loss: 0.5934, train_bce_loss: 1.3565, train_bce_dl_loss: 0.5934, step time: 0.4230\n",
      "batch: 11/17, train_dl_loss: 0.5183, train_bce_loss: 1.3609, train_bce_dl_loss: 0.5183, step time: 0.4313\n",
      "batch: 12/17, train_dl_loss: 0.5325, train_bce_loss: 1.3586, train_bce_dl_loss: 0.5325, step time: 0.4312\n",
      "batch: 13/17, train_dl_loss: 0.7204, train_bce_loss: 1.3708, train_bce_dl_loss: 0.7204, step time: 0.3965\n",
      "batch: 14/17, train_dl_loss: 0.5488, train_bce_loss: 1.3731, train_bce_dl_loss: 0.5488, step time: 0.4278\n",
      "batch: 15/17, train_dl_loss: 0.5030, train_bce_loss: 1.3662, train_bce_dl_loss: 0.5030, step time: 0.3863\n",
      "batch: 16/17, train_dl_loss: 0.5007, train_bce_loss: 1.3769, train_bce_dl_loss: 0.5007, step time: 0.4304\n",
      "batch: 17/17, train_dl_loss: 0.4240, train_bce_loss: 1.3756, train_bce_dl_loss: 0.4240, step time: 0.1137\n",
      "LOSS train DiceLoss: 0.5443, LOSS train BCE: 1.3646, LOSS train BCE-DiceLoss: 0.5443, LOSS val DiceLoss: 0.6075, LOSS val BCE: 1.3713, LOSS val BCE-DiceLoss: 0.6075, METRIC val: 0.3561\n",
      "time consuming of epoch 29 is: 442.1017\n",
      "----------\n",
      "EPOCH 30/80\n",
      "batch: 0/17, train_dl_loss: 0.5453, train_bce_loss: 1.3677, train_bce_dl_loss: 0.5453, step time: 0.4259\n",
      "batch: 1/17, train_dl_loss: 0.5247, train_bce_loss: 1.3688, train_bce_dl_loss: 0.5247, step time: 0.3842\n",
      "batch: 2/17, train_dl_loss: 0.6093, train_bce_loss: 1.3767, train_bce_dl_loss: 0.6093, step time: 0.4442\n",
      "batch: 3/17, train_dl_loss: 0.5656, train_bce_loss: 1.3620, train_bce_dl_loss: 0.5656, step time: 0.3799\n",
      "batch: 4/17, train_dl_loss: 0.4978, train_bce_loss: 1.3604, train_bce_dl_loss: 0.4978, step time: 0.4306\n",
      "batch: 5/17, train_dl_loss: 0.5401, train_bce_loss: 1.3833, train_bce_dl_loss: 0.5401, step time: 0.4467\n",
      "batch: 6/17, train_dl_loss: 0.5929, train_bce_loss: 1.3800, train_bce_dl_loss: 0.5929, step time: 0.4345\n",
      "batch: 7/17, train_dl_loss: 0.5311, train_bce_loss: 1.3678, train_bce_dl_loss: 0.5311, step time: 0.4315\n",
      "batch: 8/17, train_dl_loss: 0.6096, train_bce_loss: 1.3714, train_bce_dl_loss: 0.6096, step time: 0.4468\n",
      "batch: 9/17, train_dl_loss: 0.5166, train_bce_loss: 1.3861, train_bce_dl_loss: 0.5166, step time: 0.4694\n",
      "batch: 10/17, train_dl_loss: 0.5775, train_bce_loss: 1.3747, train_bce_dl_loss: 0.5775, step time: 0.4555\n",
      "batch: 11/17, train_dl_loss: 0.5229, train_bce_loss: 1.3804, train_bce_dl_loss: 0.5229, step time: 0.4349\n",
      "batch: 12/17, train_dl_loss: 0.4961, train_bce_loss: 1.3789, train_bce_dl_loss: 0.4961, step time: 0.4473\n",
      "batch: 13/17, train_dl_loss: 0.7083, train_bce_loss: 1.3929, train_bce_dl_loss: 0.7083, step time: 0.4438\n",
      "batch: 14/17, train_dl_loss: 0.6150, train_bce_loss: 1.3926, train_bce_dl_loss: 0.6150, step time: 0.4274\n",
      "batch: 15/17, train_dl_loss: 0.4989, train_bce_loss: 1.3869, train_bce_dl_loss: 0.4989, step time: 0.4327\n",
      "batch: 16/17, train_dl_loss: 0.5192, train_bce_loss: 1.3838, train_bce_dl_loss: 0.5192, step time: 0.4308\n",
      "batch: 17/17, train_dl_loss: 0.4445, train_bce_loss: 1.3812, train_bce_dl_loss: 0.4445, step time: 0.1129\n",
      "LOSS train DiceLoss: 0.5508, LOSS train BCE: 1.3775, LOSS train BCE-DiceLoss: 0.5508, LOSS val DiceLoss: 0.6055, LOSS val BCE: 1.3798, LOSS val BCE-DiceLoss: 0.6055, METRIC val: 0.3608\n",
      "time consuming of epoch 30 is: 435.3485\n",
      "----------\n",
      "EPOCH 31/80\n",
      "batch: 0/17, train_dl_loss: 0.4997, train_bce_loss: 1.3719, train_bce_dl_loss: 0.4997, step time: 0.4222\n",
      "batch: 1/17, train_dl_loss: 0.5424, train_bce_loss: 1.3823, train_bce_dl_loss: 0.5424, step time: 0.3781\n",
      "batch: 2/17, train_dl_loss: 0.5544, train_bce_loss: 1.3718, train_bce_dl_loss: 0.5544, step time: 0.4190\n",
      "batch: 3/17, train_dl_loss: 0.5820, train_bce_loss: 1.3933, train_bce_dl_loss: 0.5820, step time: 0.3815\n",
      "batch: 4/17, train_dl_loss: 0.4972, train_bce_loss: 1.3688, train_bce_dl_loss: 0.4972, step time: 0.4466\n",
      "batch: 5/17, train_dl_loss: 0.5385, train_bce_loss: 1.3742, train_bce_dl_loss: 0.5385, step time: 0.3927\n",
      "batch: 6/17, train_dl_loss: 0.6117, train_bce_loss: 1.3978, train_bce_dl_loss: 0.6117, step time: 0.4281\n",
      "batch: 7/17, train_dl_loss: 0.4933, train_bce_loss: 1.3733, train_bce_dl_loss: 0.4933, step time: 0.3830\n",
      "batch: 8/17, train_dl_loss: 0.5185, train_bce_loss: 1.3698, train_bce_dl_loss: 0.5185, step time: 0.4256\n",
      "batch: 9/17, train_dl_loss: 0.5658, train_bce_loss: 1.3887, train_bce_dl_loss: 0.5658, step time: 0.3853\n",
      "batch: 10/17, train_dl_loss: 0.5883, train_bce_loss: 1.3694, train_bce_dl_loss: 0.5883, step time: 0.4561\n",
      "batch: 11/17, train_dl_loss: 0.5123, train_bce_loss: 1.3647, train_bce_dl_loss: 0.5123, step time: 0.4362\n",
      "batch: 12/17, train_dl_loss: 0.5344, train_bce_loss: 1.3761, train_bce_dl_loss: 0.5344, step time: 0.4647\n",
      "batch: 13/17, train_dl_loss: 0.6770, train_bce_loss: 1.3884, train_bce_dl_loss: 0.6770, step time: 0.3820\n",
      "batch: 14/17, train_dl_loss: 0.5235, train_bce_loss: 1.4044, train_bce_dl_loss: 0.5235, step time: 0.4547\n",
      "batch: 15/17, train_dl_loss: 0.4988, train_bce_loss: 1.3876, train_bce_dl_loss: 0.4988, step time: 0.3945\n",
      "batch: 16/17, train_dl_loss: 0.5006, train_bce_loss: 1.3901, train_bce_dl_loss: 0.5006, step time: 0.4205\n",
      "batch: 17/17, train_dl_loss: 0.4603, train_bce_loss: 1.3927, train_bce_dl_loss: 0.4603, step time: 0.1158\n",
      "LOSS train DiceLoss: 0.5388, LOSS train BCE: 1.3814, LOSS train BCE-DiceLoss: 0.5388, LOSS val DiceLoss: 0.6036, LOSS val BCE: 1.3828, LOSS val BCE-DiceLoss: 0.6036, METRIC val: 0.3567\n",
      "time consuming of epoch 31 is: 453.0692\n",
      "----------\n",
      "EPOCH 32/80\n",
      "batch: 0/17, train_dl_loss: 0.5203, train_bce_loss: 1.3740, train_bce_dl_loss: 0.5203, step time: 0.4468\n",
      "batch: 1/17, train_dl_loss: 0.5434, train_bce_loss: 1.4033, train_bce_dl_loss: 0.5434, step time: 0.3813\n",
      "batch: 2/17, train_dl_loss: 0.5557, train_bce_loss: 1.3878, train_bce_dl_loss: 0.5557, step time: 0.4269\n",
      "batch: 3/17, train_dl_loss: 0.5992, train_bce_loss: 1.3993, train_bce_dl_loss: 0.5992, step time: 0.3778\n",
      "batch: 4/17, train_dl_loss: 0.5140, train_bce_loss: 1.3945, train_bce_dl_loss: 0.5140, step time: 0.4450\n",
      "batch: 5/17, train_dl_loss: 0.5558, train_bce_loss: 1.3844, train_bce_dl_loss: 0.5558, step time: 0.3952\n",
      "batch: 6/17, train_dl_loss: 0.5551, train_bce_loss: 1.3875, train_bce_dl_loss: 0.5551, step time: 0.4355\n",
      "batch: 7/17, train_dl_loss: 0.4711, train_bce_loss: 1.3812, train_bce_dl_loss: 0.4711, step time: 0.3898\n",
      "batch: 8/17, train_dl_loss: 0.5279, train_bce_loss: 1.3813, train_bce_dl_loss: 0.5279, step time: 0.4391\n",
      "batch: 9/17, train_dl_loss: 0.7231, train_bce_loss: 1.4049, train_bce_dl_loss: 0.7231, step time: 0.3945\n",
      "batch: 10/17, train_dl_loss: 0.5977, train_bce_loss: 1.3857, train_bce_dl_loss: 0.5977, step time: 0.4269\n",
      "batch: 11/17, train_dl_loss: 0.4825, train_bce_loss: 1.3855, train_bce_dl_loss: 0.4825, step time: 0.4497\n",
      "batch: 12/17, train_dl_loss: 0.5136, train_bce_loss: 1.3885, train_bce_dl_loss: 0.5136, step time: 0.4425\n",
      "batch: 13/17, train_dl_loss: 0.6685, train_bce_loss: 1.4040, train_bce_dl_loss: 0.6685, step time: 0.4324\n",
      "batch: 14/17, train_dl_loss: 0.5957, train_bce_loss: 1.3978, train_bce_dl_loss: 0.5957, step time: 0.4358\n",
      "batch: 15/17, train_dl_loss: 0.5305, train_bce_loss: 1.3921, train_bce_dl_loss: 0.5305, step time: 0.3942\n",
      "batch: 16/17, train_dl_loss: 0.5686, train_bce_loss: 1.4073, train_bce_dl_loss: 0.5686, step time: 0.4313\n",
      "batch: 17/17, train_dl_loss: 0.4621, train_bce_loss: 1.4038, train_bce_dl_loss: 0.4621, step time: 0.1147\n",
      "LOSS train DiceLoss: 0.5547, LOSS train BCE: 1.3924, LOSS train BCE-DiceLoss: 0.5547, LOSS val DiceLoss: 0.5893, LOSS val BCE: 1.3881, LOSS val BCE-DiceLoss: 0.5893, METRIC val: 0.3785\n",
      "time consuming of epoch 32 is: 478.9523\n",
      "----------\n",
      "EPOCH 33/80\n",
      "batch: 0/17, train_dl_loss: 0.4813, train_bce_loss: 1.3849, train_bce_dl_loss: 0.4813, step time: 0.4405\n",
      "batch: 1/17, train_dl_loss: 0.4897, train_bce_loss: 1.3920, train_bce_dl_loss: 0.4897, step time: 0.3844\n",
      "batch: 2/17, train_dl_loss: 0.5183, train_bce_loss: 1.3910, train_bce_dl_loss: 0.5183, step time: 0.4363\n",
      "batch: 3/17, train_dl_loss: 0.6406, train_bce_loss: 1.3859, train_bce_dl_loss: 0.6406, step time: 0.3809\n",
      "batch: 4/17, train_dl_loss: 0.5007, train_bce_loss: 1.3928, train_bce_dl_loss: 0.5007, step time: 0.4588\n",
      "batch: 5/17, train_dl_loss: 0.5279, train_bce_loss: 1.3959, train_bce_dl_loss: 0.5279, step time: 0.4425\n",
      "batch: 6/17, train_dl_loss: 0.5975, train_bce_loss: 1.3975, train_bce_dl_loss: 0.5975, step time: 0.4371\n",
      "batch: 7/17, train_dl_loss: 0.5044, train_bce_loss: 1.3781, train_bce_dl_loss: 0.5044, step time: 0.4356\n",
      "batch: 8/17, train_dl_loss: 0.5374, train_bce_loss: 1.3799, train_bce_dl_loss: 0.5374, step time: 0.4407\n",
      "batch: 9/17, train_dl_loss: 0.5299, train_bce_loss: 1.3896, train_bce_dl_loss: 0.5299, step time: 0.4405\n",
      "batch: 10/17, train_dl_loss: 0.5726, train_bce_loss: 1.3825, train_bce_dl_loss: 0.5726, step time: 0.4232\n",
      "batch: 11/17, train_dl_loss: 0.4744, train_bce_loss: 1.3870, train_bce_dl_loss: 0.4744, step time: 0.4411\n",
      "batch: 12/17, train_dl_loss: 0.4825, train_bce_loss: 1.3821, train_bce_dl_loss: 0.4825, step time: 0.4342\n",
      "batch: 13/17, train_dl_loss: 0.6813, train_bce_loss: 1.4066, train_bce_dl_loss: 0.6813, step time: 0.4324\n",
      "batch: 14/17, train_dl_loss: 0.5799, train_bce_loss: 1.4150, train_bce_dl_loss: 0.5799, step time: 0.4424\n",
      "batch: 15/17, train_dl_loss: 0.5729, train_bce_loss: 1.4129, train_bce_dl_loss: 0.5729, step time: 0.4273\n",
      "batch: 16/17, train_dl_loss: 0.5324, train_bce_loss: 1.4018, train_bce_dl_loss: 0.5324, step time: 0.4383\n",
      "batch: 17/17, train_dl_loss: 0.4337, train_bce_loss: 1.3945, train_bce_dl_loss: 0.4337, step time: 0.1153\n",
      "LOSS train DiceLoss: 0.5365, LOSS train BCE: 1.3928, LOSS train BCE-DiceLoss: 0.5365, LOSS val DiceLoss: 0.6016, LOSS val BCE: 1.3936, LOSS val BCE-DiceLoss: 0.6016, METRIC val: 0.3583\n",
      "time consuming of epoch 33 is: 510.2546\n",
      "----------\n",
      "EPOCH 34/80\n",
      "batch: 0/17, train_dl_loss: 0.4805, train_bce_loss: 1.4013, train_bce_dl_loss: 0.4805, step time: 0.4617\n",
      "batch: 1/17, train_dl_loss: 0.5517, train_bce_loss: 1.4029, train_bce_dl_loss: 0.5517, step time: 0.3965\n",
      "batch: 2/17, train_dl_loss: 0.6112, train_bce_loss: 1.3985, train_bce_dl_loss: 0.6112, step time: 0.4218\n",
      "batch: 3/17, train_dl_loss: 0.5971, train_bce_loss: 1.4112, train_bce_dl_loss: 0.5971, step time: 0.3769\n",
      "batch: 4/17, train_dl_loss: 0.4761, train_bce_loss: 1.3899, train_bce_dl_loss: 0.4761, step time: 0.4382\n",
      "batch: 5/17, train_dl_loss: 0.4759, train_bce_loss: 1.3898, train_bce_dl_loss: 0.4759, step time: 0.3972\n",
      "batch: 6/17, train_dl_loss: 0.5425, train_bce_loss: 1.3939, train_bce_dl_loss: 0.5425, step time: 0.4421\n",
      "batch: 7/17, train_dl_loss: 0.5146, train_bce_loss: 1.3909, train_bce_dl_loss: 0.5146, step time: 0.3886\n",
      "batch: 8/17, train_dl_loss: 0.5505, train_bce_loss: 1.3954, train_bce_dl_loss: 0.5505, step time: 0.4361\n",
      "batch: 9/17, train_dl_loss: 0.5097, train_bce_loss: 1.3982, train_bce_dl_loss: 0.5097, step time: 0.3788\n",
      "batch: 10/17, train_dl_loss: 0.5787, train_bce_loss: 1.3935, train_bce_dl_loss: 0.5787, step time: 0.4424\n",
      "batch: 11/17, train_dl_loss: 0.4747, train_bce_loss: 1.3965, train_bce_dl_loss: 0.4747, step time: 0.3895\n",
      "batch: 12/17, train_dl_loss: 0.5085, train_bce_loss: 1.3927, train_bce_dl_loss: 0.5085, step time: 0.4365\n",
      "batch: 13/17, train_dl_loss: 0.7503, train_bce_loss: 1.4151, train_bce_dl_loss: 0.7503, step time: 0.3965\n",
      "batch: 14/17, train_dl_loss: 0.5363, train_bce_loss: 1.4244, train_bce_dl_loss: 0.5363, step time: 0.4553\n",
      "batch: 15/17, train_dl_loss: 0.4781, train_bce_loss: 1.4106, train_bce_dl_loss: 0.4781, step time: 0.3869\n",
      "batch: 16/17, train_dl_loss: 0.4980, train_bce_loss: 1.4057, train_bce_dl_loss: 0.4980, step time: 0.4331\n",
      "batch: 17/17, train_dl_loss: 0.4277, train_bce_loss: 1.3986, train_bce_dl_loss: 0.4277, step time: 0.1189\n",
      "LOSS train DiceLoss: 0.5312, LOSS train BCE: 1.4005, LOSS train BCE-DiceLoss: 0.5312, LOSS val DiceLoss: 0.5834, LOSS val BCE: 1.3980, LOSS val BCE-DiceLoss: 0.5834, METRIC val: 0.3804\n",
      "time consuming of epoch 34 is: 561.0685\n",
      "----------\n",
      "EPOCH 35/80\n",
      "batch: 0/17, train_dl_loss: 0.4978, train_bce_loss: 1.3991, train_bce_dl_loss: 0.4978, step time: 0.4421\n",
      "batch: 1/17, train_dl_loss: 0.4899, train_bce_loss: 1.4035, train_bce_dl_loss: 0.4899, step time: 0.3792\n",
      "batch: 2/17, train_dl_loss: 0.5666, train_bce_loss: 1.3968, train_bce_dl_loss: 0.5666, step time: 0.4392\n",
      "batch: 3/17, train_dl_loss: 0.6152, train_bce_loss: 1.4129, train_bce_dl_loss: 0.6152, step time: 0.4358\n",
      "batch: 4/17, train_dl_loss: 0.4837, train_bce_loss: 1.4030, train_bce_dl_loss: 0.4837, step time: 0.4425\n",
      "batch: 5/17, train_dl_loss: 0.5133, train_bce_loss: 1.3883, train_bce_dl_loss: 0.5133, step time: 0.4387\n",
      "batch: 6/17, train_dl_loss: 0.5591, train_bce_loss: 1.4104, train_bce_dl_loss: 0.5591, step time: 0.4449\n",
      "batch: 7/17, train_dl_loss: 0.4944, train_bce_loss: 1.3913, train_bce_dl_loss: 0.4944, step time: 0.4364\n",
      "batch: 8/17, train_dl_loss: 0.5414, train_bce_loss: 1.3923, train_bce_dl_loss: 0.5414, step time: 0.4519\n",
      "batch: 9/17, train_dl_loss: 0.4934, train_bce_loss: 1.4133, train_bce_dl_loss: 0.4934, step time: 0.4256\n",
      "batch: 10/17, train_dl_loss: 0.5697, train_bce_loss: 1.4121, train_bce_dl_loss: 0.5697, step time: 0.4391\n",
      "batch: 11/17, train_dl_loss: 0.5119, train_bce_loss: 1.4059, train_bce_dl_loss: 0.5119, step time: 0.4636\n",
      "batch: 12/17, train_dl_loss: 0.5423, train_bce_loss: 1.4013, train_bce_dl_loss: 0.5423, step time: 0.4284\n",
      "batch: 13/17, train_dl_loss: 0.6733, train_bce_loss: 1.4229, train_bce_dl_loss: 0.6733, step time: 0.3877\n",
      "batch: 14/17, train_dl_loss: 0.5814, train_bce_loss: 1.4235, train_bce_dl_loss: 0.5814, step time: 0.4295\n",
      "batch: 15/17, train_dl_loss: 0.5051, train_bce_loss: 1.4069, train_bce_dl_loss: 0.5051, step time: 0.3868\n",
      "batch: 16/17, train_dl_loss: 0.4969, train_bce_loss: 1.4075, train_bce_dl_loss: 0.4969, step time: 0.4439\n",
      "batch: 17/17, train_dl_loss: 0.4779, train_bce_loss: 1.4051, train_bce_dl_loss: 0.4779, step time: 0.1162\n",
      "LOSS train DiceLoss: 0.5341, LOSS train BCE: 1.4053, LOSS train BCE-DiceLoss: 0.5341, LOSS val DiceLoss: 0.5898, LOSS val BCE: 1.4025, LOSS val BCE-DiceLoss: 0.5898, METRIC val: 0.3752\n",
      "time consuming of epoch 35 is: 533.2639\n",
      "----------\n",
      "EPOCH 36/80\n",
      "batch: 0/17, train_dl_loss: 0.4904, train_bce_loss: 1.3927, train_bce_dl_loss: 0.4904, step time: 0.4314\n",
      "batch: 1/17, train_dl_loss: 0.5510, train_bce_loss: 1.4104, train_bce_dl_loss: 0.5510, step time: 0.3926\n",
      "batch: 2/17, train_dl_loss: 0.5366, train_bce_loss: 1.4068, train_bce_dl_loss: 0.5366, step time: 0.4287\n",
      "batch: 3/17, train_dl_loss: 0.5400, train_bce_loss: 1.4141, train_bce_dl_loss: 0.5400, step time: 0.3883\n",
      "batch: 4/17, train_dl_loss: 0.4702, train_bce_loss: 1.4028, train_bce_dl_loss: 0.4702, step time: 0.4471\n",
      "batch: 5/17, train_dl_loss: 0.4895, train_bce_loss: 1.3954, train_bce_dl_loss: 0.4895, step time: 0.3945\n",
      "batch: 6/17, train_dl_loss: 0.5336, train_bce_loss: 1.4249, train_bce_dl_loss: 0.5336, step time: 0.4367\n",
      "batch: 7/17, train_dl_loss: 0.4722, train_bce_loss: 1.4030, train_bce_dl_loss: 0.4722, step time: 0.4462\n",
      "batch: 8/17, train_dl_loss: 0.4900, train_bce_loss: 1.3909, train_bce_dl_loss: 0.4900, step time: 0.4564\n",
      "batch: 9/17, train_dl_loss: 0.4935, train_bce_loss: 1.4147, train_bce_dl_loss: 0.4935, step time: 0.4009\n",
      "batch: 10/17, train_dl_loss: 0.6405, train_bce_loss: 1.4139, train_bce_dl_loss: 0.6405, step time: 0.4685\n",
      "batch: 11/17, train_dl_loss: 0.5100, train_bce_loss: 1.3875, train_bce_dl_loss: 0.5100, step time: 0.4342\n",
      "batch: 12/17, train_dl_loss: 0.5431, train_bce_loss: 1.4089, train_bce_dl_loss: 0.5431, step time: 0.4521\n",
      "batch: 13/17, train_dl_loss: 0.6729, train_bce_loss: 1.4081, train_bce_dl_loss: 0.6729, step time: 0.4031\n",
      "batch: 14/17, train_dl_loss: 0.5692, train_bce_loss: 1.4181, train_bce_dl_loss: 0.5692, step time: 0.4407\n",
      "batch: 15/17, train_dl_loss: 0.4873, train_bce_loss: 1.4160, train_bce_dl_loss: 0.4873, step time: 0.3919\n",
      "batch: 16/17, train_dl_loss: 0.4789, train_bce_loss: 1.4195, train_bce_dl_loss: 0.4789, step time: 0.4358\n",
      "batch: 17/17, train_dl_loss: 0.4485, train_bce_loss: 1.4105, train_bce_dl_loss: 0.4485, step time: 0.1168\n",
      "LOSS train DiceLoss: 0.5232, LOSS train BCE: 1.4077, LOSS train BCE-DiceLoss: 0.5232, LOSS val DiceLoss: 0.6031, LOSS val BCE: 1.4105, LOSS val BCE-DiceLoss: 0.6031, METRIC val: 0.3591\n",
      "time consuming of epoch 36 is: 498.7187\n",
      "----------\n",
      "EPOCH 37/80\n",
      "batch: 0/17, train_dl_loss: 0.4981, train_bce_loss: 1.4167, train_bce_dl_loss: 0.4981, step time: 0.4476\n",
      "batch: 1/17, train_dl_loss: 0.5710, train_bce_loss: 1.4197, train_bce_dl_loss: 0.5710, step time: 0.4036\n",
      "batch: 2/17, train_dl_loss: 0.5532, train_bce_loss: 1.4188, train_bce_dl_loss: 0.5532, step time: 0.4395\n",
      "batch: 3/17, train_dl_loss: 0.6370, train_bce_loss: 1.4085, train_bce_dl_loss: 0.6370, step time: 0.3942\n",
      "batch: 4/17, train_dl_loss: 0.4472, train_bce_loss: 1.3977, train_bce_dl_loss: 0.4472, step time: 0.4318\n",
      "batch: 5/17, train_dl_loss: 0.5726, train_bce_loss: 1.4146, train_bce_dl_loss: 0.5726, step time: 0.3852\n",
      "batch: 6/17, train_dl_loss: 0.5430, train_bce_loss: 1.4136, train_bce_dl_loss: 0.5430, step time: 0.4407\n",
      "batch: 7/17, train_dl_loss: 0.5077, train_bce_loss: 1.3944, train_bce_dl_loss: 0.5077, step time: 0.3900\n",
      "batch: 8/17, train_dl_loss: 0.5190, train_bce_loss: 1.3980, train_bce_dl_loss: 0.5190, step time: 0.4354\n",
      "batch: 9/17, train_dl_loss: 0.5140, train_bce_loss: 1.4108, train_bce_dl_loss: 0.5140, step time: 0.4033\n",
      "batch: 10/17, train_dl_loss: 0.5673, train_bce_loss: 1.4021, train_bce_dl_loss: 0.5673, step time: 0.4461\n",
      "batch: 11/17, train_dl_loss: 0.5004, train_bce_loss: 1.4003, train_bce_dl_loss: 0.5004, step time: 0.3947\n",
      "batch: 12/17, train_dl_loss: 0.4828, train_bce_loss: 1.4091, train_bce_dl_loss: 0.4828, step time: 0.4514\n",
      "batch: 13/17, train_dl_loss: 0.7412, train_bce_loss: 1.4238, train_bce_dl_loss: 0.7412, step time: 0.3811\n",
      "batch: 14/17, train_dl_loss: 0.5245, train_bce_loss: 1.4338, train_bce_dl_loss: 0.5245, step time: 0.4444\n",
      "batch: 15/17, train_dl_loss: 0.4951, train_bce_loss: 1.4285, train_bce_dl_loss: 0.4951, step time: 0.3869\n",
      "batch: 16/17, train_dl_loss: 0.5351, train_bce_loss: 1.4301, train_bce_dl_loss: 0.5351, step time: 0.4190\n",
      "batch: 17/17, train_dl_loss: 0.4194, train_bce_loss: 1.4187, train_bce_dl_loss: 0.4194, step time: 0.1163\n",
      "LOSS train DiceLoss: 0.5349, LOSS train BCE: 1.4133, LOSS train BCE-DiceLoss: 0.5349, LOSS val DiceLoss: 0.6051, LOSS val BCE: 1.4153, LOSS val BCE-DiceLoss: 0.6051, METRIC val: 0.3571\n",
      "time consuming of epoch 37 is: 458.7933\n",
      "----------\n",
      "EPOCH 38/80\n",
      "batch: 0/17, train_dl_loss: 0.5273, train_bce_loss: 1.4067, train_bce_dl_loss: 0.5273, step time: 0.4292\n",
      "batch: 1/17, train_dl_loss: 0.5136, train_bce_loss: 1.4340, train_bce_dl_loss: 0.5136, step time: 0.3790\n",
      "batch: 2/17, train_dl_loss: 0.5131, train_bce_loss: 1.4027, train_bce_dl_loss: 0.5131, step time: 0.4283\n",
      "batch: 3/17, train_dl_loss: 0.5881, train_bce_loss: 1.4269, train_bce_dl_loss: 0.5881, step time: 0.3868\n",
      "batch: 4/17, train_dl_loss: 0.4875, train_bce_loss: 1.4047, train_bce_dl_loss: 0.4875, step time: 0.4382\n",
      "batch: 5/17, train_dl_loss: 0.4766, train_bce_loss: 1.4043, train_bce_dl_loss: 0.4766, step time: 0.3862\n",
      "batch: 6/17, train_dl_loss: 0.5659, train_bce_loss: 1.4190, train_bce_dl_loss: 0.5659, step time: 0.4477\n",
      "batch: 7/17, train_dl_loss: 0.4617, train_bce_loss: 1.4037, train_bce_dl_loss: 0.4617, step time: 0.3925\n",
      "batch: 8/17, train_dl_loss: 0.5316, train_bce_loss: 1.4056, train_bce_dl_loss: 0.5316, step time: 0.4460\n",
      "batch: 9/17, train_dl_loss: 0.5458, train_bce_loss: 1.4221, train_bce_dl_loss: 0.5458, step time: 0.4449\n",
      "batch: 10/17, train_dl_loss: 0.6012, train_bce_loss: 1.4227, train_bce_dl_loss: 0.6012, step time: 0.4345\n",
      "batch: 11/17, train_dl_loss: 0.4768, train_bce_loss: 1.4164, train_bce_dl_loss: 0.4768, step time: 0.4289\n",
      "batch: 12/17, train_dl_loss: 0.5141, train_bce_loss: 1.4121, train_bce_dl_loss: 0.5141, step time: 0.4417\n",
      "batch: 13/17, train_dl_loss: 0.6977, train_bce_loss: 1.4232, train_bce_dl_loss: 0.6977, step time: 0.4518\n",
      "batch: 14/17, train_dl_loss: 0.5332, train_bce_loss: 1.4379, train_bce_dl_loss: 0.5332, step time: 0.4343\n",
      "batch: 15/17, train_dl_loss: 0.4598, train_bce_loss: 1.4250, train_bce_dl_loss: 0.4598, step time: 0.3899\n",
      "batch: 16/17, train_dl_loss: 0.4861, train_bce_loss: 1.4218, train_bce_dl_loss: 0.4861, step time: 0.4262\n",
      "batch: 17/17, train_dl_loss: 0.4759, train_bce_loss: 1.4352, train_bce_dl_loss: 0.4759, step time: 0.1169\n",
      "LOSS train DiceLoss: 0.5253, LOSS train BCE: 1.4180, LOSS train BCE-DiceLoss: 0.5253, LOSS val DiceLoss: 0.5961, LOSS val BCE: 1.4179, LOSS val BCE-DiceLoss: 0.5961, METRIC val: 0.3668\n",
      "time consuming of epoch 38 is: 420.3525\n",
      "----------\n",
      "EPOCH 39/80\n",
      "batch: 0/17, train_dl_loss: 0.4818, train_bce_loss: 1.4106, train_bce_dl_loss: 0.4818, step time: 0.4501\n",
      "batch: 1/17, train_dl_loss: 0.4831, train_bce_loss: 1.4211, train_bce_dl_loss: 0.4831, step time: 0.3998\n",
      "batch: 2/17, train_dl_loss: 0.5226, train_bce_loss: 1.4130, train_bce_dl_loss: 0.5226, step time: 0.4320\n",
      "batch: 3/17, train_dl_loss: 0.6053, train_bce_loss: 1.4124, train_bce_dl_loss: 0.6053, step time: 0.3901\n",
      "batch: 4/17, train_dl_loss: 0.5224, train_bce_loss: 1.4208, train_bce_dl_loss: 0.5224, step time: 0.4480\n",
      "batch: 5/17, train_dl_loss: 0.5484, train_bce_loss: 1.4107, train_bce_dl_loss: 0.5484, step time: 0.3848\n",
      "batch: 6/17, train_dl_loss: 0.5517, train_bce_loss: 1.4293, train_bce_dl_loss: 0.5517, step time: 0.4262\n",
      "batch: 7/17, train_dl_loss: 0.4737, train_bce_loss: 1.3993, train_bce_dl_loss: 0.4737, step time: 0.3925\n",
      "batch: 8/17, train_dl_loss: 0.4958, train_bce_loss: 1.4119, train_bce_dl_loss: 0.4958, step time: 0.4535\n",
      "batch: 9/17, train_dl_loss: 0.5487, train_bce_loss: 1.4292, train_bce_dl_loss: 0.5487, step time: 0.3934\n",
      "batch: 10/17, train_dl_loss: 0.6136, train_bce_loss: 1.4244, train_bce_dl_loss: 0.6136, step time: 0.4460\n",
      "batch: 11/17, train_dl_loss: 0.5198, train_bce_loss: 1.4162, train_bce_dl_loss: 0.5198, step time: 0.3979\n",
      "batch: 12/17, train_dl_loss: 0.4808, train_bce_loss: 1.4227, train_bce_dl_loss: 0.4808, step time: 0.4283\n",
      "batch: 13/17, train_dl_loss: 0.6628, train_bce_loss: 1.4401, train_bce_dl_loss: 0.6628, step time: 0.3884\n",
      "batch: 14/17, train_dl_loss: 0.5625, train_bce_loss: 1.4411, train_bce_dl_loss: 0.5625, step time: 0.4401\n",
      "batch: 15/17, train_dl_loss: 0.4822, train_bce_loss: 1.4167, train_bce_dl_loss: 0.4822, step time: 0.3948\n",
      "batch: 16/17, train_dl_loss: 0.4976, train_bce_loss: 1.4309, train_bce_dl_loss: 0.4976, step time: 0.4278\n",
      "batch: 17/17, train_dl_loss: 0.4743, train_bce_loss: 1.4208, train_bce_dl_loss: 0.4743, step time: 0.1198\n",
      "LOSS train DiceLoss: 0.5293, LOSS train BCE: 1.4206, LOSS train BCE-DiceLoss: 0.5293, LOSS val DiceLoss: 0.5875, LOSS val BCE: 1.4204, LOSS val BCE-DiceLoss: 0.5875, METRIC val: 0.3782\n",
      "time consuming of epoch 39 is: 490.2056\n",
      "----------\n",
      "EPOCH 40/80\n",
      "batch: 0/17, train_dl_loss: 0.4961, train_bce_loss: 1.4122, train_bce_dl_loss: 0.4961, step time: 0.4429\n",
      "batch: 1/17, train_dl_loss: 0.4909, train_bce_loss: 1.4316, train_bce_dl_loss: 0.4909, step time: 0.3898\n",
      "batch: 2/17, train_dl_loss: 0.5777, train_bce_loss: 1.4168, train_bce_dl_loss: 0.5777, step time: 0.4411\n",
      "batch: 3/17, train_dl_loss: 0.5624, train_bce_loss: 1.4260, train_bce_dl_loss: 0.5624, step time: 0.4014\n",
      "batch: 4/17, train_dl_loss: 0.4832, train_bce_loss: 1.4110, train_bce_dl_loss: 0.4832, step time: 0.4376\n",
      "batch: 5/17, train_dl_loss: 0.5122, train_bce_loss: 1.4314, train_bce_dl_loss: 0.5122, step time: 0.4241\n",
      "batch: 6/17, train_dl_loss: 0.5368, train_bce_loss: 1.4266, train_bce_dl_loss: 0.5368, step time: 0.4295\n",
      "batch: 7/17, train_dl_loss: 0.5598, train_bce_loss: 1.4254, train_bce_dl_loss: 0.5598, step time: 0.4620\n",
      "batch: 8/17, train_dl_loss: 0.5160, train_bce_loss: 1.4160, train_bce_dl_loss: 0.5160, step time: 0.4516\n",
      "batch: 9/17, train_dl_loss: 0.5194, train_bce_loss: 1.4283, train_bce_dl_loss: 0.5194, step time: 0.4467\n",
      "batch: 10/17, train_dl_loss: 0.5733, train_bce_loss: 1.4228, train_bce_dl_loss: 0.5733, step time: 0.4365\n",
      "batch: 11/17, train_dl_loss: 0.4769, train_bce_loss: 1.3993, train_bce_dl_loss: 0.4769, step time: 0.4417\n",
      "batch: 12/17, train_dl_loss: 0.5517, train_bce_loss: 1.4314, train_bce_dl_loss: 0.5517, step time: 0.4312\n",
      "batch: 13/17, train_dl_loss: 0.6458, train_bce_loss: 1.4419, train_bce_dl_loss: 0.6458, step time: 0.4497\n",
      "batch: 14/17, train_dl_loss: 0.5420, train_bce_loss: 1.4476, train_bce_dl_loss: 0.5420, step time: 0.4336\n",
      "batch: 15/17, train_dl_loss: 0.5006, train_bce_loss: 1.4320, train_bce_dl_loss: 0.5006, step time: 0.3815\n",
      "batch: 16/17, train_dl_loss: 0.5283, train_bce_loss: 1.4373, train_bce_dl_loss: 0.5283, step time: 0.4378\n",
      "batch: 17/17, train_dl_loss: 0.4250, train_bce_loss: 1.4296, train_bce_dl_loss: 0.4250, step time: 0.1142\n",
      "LOSS train DiceLoss: 0.5277, LOSS train BCE: 1.4260, LOSS train BCE-DiceLoss: 0.5277, LOSS val DiceLoss: 0.5838, LOSS val BCE: 1.4266, LOSS val BCE-DiceLoss: 0.5838, METRIC val: 0.3845\n",
      "time consuming of epoch 40 is: 481.4293\n",
      "----------\n",
      "EPOCH 41/80\n",
      "batch: 0/17, train_dl_loss: 0.4828, train_bce_loss: 1.4371, train_bce_dl_loss: 0.4828, step time: 0.4433\n",
      "batch: 1/17, train_dl_loss: 0.4564, train_bce_loss: 1.4305, train_bce_dl_loss: 0.4564, step time: 0.3905\n",
      "batch: 2/17, train_dl_loss: 0.5717, train_bce_loss: 1.4326, train_bce_dl_loss: 0.5717, step time: 0.4517\n",
      "batch: 3/17, train_dl_loss: 0.6332, train_bce_loss: 1.4494, train_bce_dl_loss: 0.6332, step time: 0.3885\n",
      "batch: 4/17, train_dl_loss: 0.4823, train_bce_loss: 1.4294, train_bce_dl_loss: 0.4823, step time: 0.4327\n",
      "batch: 5/17, train_dl_loss: 0.5440, train_bce_loss: 1.4192, train_bce_dl_loss: 0.5440, step time: 0.3824\n",
      "batch: 6/17, train_dl_loss: 0.5573, train_bce_loss: 1.4342, train_bce_dl_loss: 0.5573, step time: 0.4326\n",
      "batch: 7/17, train_dl_loss: 0.4511, train_bce_loss: 1.4189, train_bce_dl_loss: 0.4511, step time: 0.3895\n",
      "batch: 8/17, train_dl_loss: 0.4984, train_bce_loss: 1.4262, train_bce_dl_loss: 0.4984, step time: 0.4347\n",
      "batch: 9/17, train_dl_loss: 0.5272, train_bce_loss: 1.4378, train_bce_dl_loss: 0.5272, step time: 0.3869\n",
      "batch: 10/17, train_dl_loss: 0.6076, train_bce_loss: 1.4135, train_bce_dl_loss: 0.6076, step time: 0.4306\n",
      "batch: 11/17, train_dl_loss: 0.5106, train_bce_loss: 1.4091, train_bce_dl_loss: 0.5106, step time: 0.4450\n",
      "batch: 12/17, train_dl_loss: 0.5605, train_bce_loss: 1.4377, train_bce_dl_loss: 0.5605, step time: 0.4295\n",
      "batch: 13/17, train_dl_loss: 0.6676, train_bce_loss: 1.4349, train_bce_dl_loss: 0.6676, step time: 0.4369\n",
      "batch: 14/17, train_dl_loss: 0.5366, train_bce_loss: 1.4459, train_bce_dl_loss: 0.5366, step time: 0.4300\n",
      "batch: 15/17, train_dl_loss: 0.4754, train_bce_loss: 1.4269, train_bce_dl_loss: 0.4754, step time: 0.4435\n",
      "batch: 16/17, train_dl_loss: 0.4831, train_bce_loss: 1.4341, train_bce_dl_loss: 0.4831, step time: 0.4412\n",
      "batch: 17/17, train_dl_loss: 0.4164, train_bce_loss: 1.4260, train_bce_dl_loss: 0.4164, step time: 0.1169\n",
      "LOSS train DiceLoss: 0.5257, LOSS train BCE: 1.4302, LOSS train BCE-DiceLoss: 0.5257, LOSS val DiceLoss: 0.6088, LOSS val BCE: 1.4281, LOSS val BCE-DiceLoss: 0.6088, METRIC val: 0.3500\n",
      "time consuming of epoch 41 is: 457.7256\n",
      "----------\n",
      "EPOCH 42/80\n",
      "batch: 0/17, train_dl_loss: 0.4854, train_bce_loss: 1.4210, train_bce_dl_loss: 0.4854, step time: 0.4452\n",
      "batch: 1/17, train_dl_loss: 0.5266, train_bce_loss: 1.4408, train_bce_dl_loss: 0.5266, step time: 0.4483\n",
      "batch: 2/17, train_dl_loss: 0.5877, train_bce_loss: 1.4375, train_bce_dl_loss: 0.5877, step time: 0.4669\n",
      "batch: 3/17, train_dl_loss: 0.5373, train_bce_loss: 1.4327, train_bce_dl_loss: 0.5373, step time: 0.4033\n",
      "batch: 4/17, train_dl_loss: 0.4956, train_bce_loss: 1.4348, train_bce_dl_loss: 0.4956, step time: 0.4480\n",
      "batch: 5/17, train_dl_loss: 0.5866, train_bce_loss: 1.4285, train_bce_dl_loss: 0.5866, step time: 0.3945\n",
      "batch: 6/17, train_dl_loss: 0.5734, train_bce_loss: 1.4449, train_bce_dl_loss: 0.5734, step time: 0.4250\n",
      "batch: 7/17, train_dl_loss: 0.4671, train_bce_loss: 1.4137, train_bce_dl_loss: 0.4671, step time: 0.3853\n",
      "batch: 8/17, train_dl_loss: 0.5254, train_bce_loss: 1.4209, train_bce_dl_loss: 0.5254, step time: 0.4260\n",
      "batch: 9/17, train_dl_loss: 0.5063, train_bce_loss: 1.4267, train_bce_dl_loss: 0.5063, step time: 0.3869\n",
      "batch: 10/17, train_dl_loss: 0.5579, train_bce_loss: 1.4128, train_bce_dl_loss: 0.5579, step time: 0.4551\n",
      "batch: 11/17, train_dl_loss: 0.4618, train_bce_loss: 1.4188, train_bce_dl_loss: 0.4618, step time: 0.4040\n",
      "batch: 12/17, train_dl_loss: 0.5158, train_bce_loss: 1.4315, train_bce_dl_loss: 0.5158, step time: 0.4200\n",
      "batch: 13/17, train_dl_loss: 0.6518, train_bce_loss: 1.4447, train_bce_dl_loss: 0.6518, step time: 0.3780\n",
      "batch: 14/17, train_dl_loss: 0.5690, train_bce_loss: 1.4562, train_bce_dl_loss: 0.5690, step time: 0.4245\n",
      "batch: 15/17, train_dl_loss: 0.4717, train_bce_loss: 1.4382, train_bce_dl_loss: 0.4717, step time: 0.3894\n",
      "batch: 16/17, train_dl_loss: 0.4584, train_bce_loss: 1.4413, train_bce_dl_loss: 0.4584, step time: 0.4420\n",
      "batch: 17/17, train_dl_loss: 0.4110, train_bce_loss: 1.4496, train_bce_dl_loss: 0.4110, step time: 0.1163\n",
      "LOSS train DiceLoss: 0.5216, LOSS train BCE: 1.4330, LOSS train BCE-DiceLoss: 0.5216, LOSS val DiceLoss: 0.5775, LOSS val BCE: 1.4306, LOSS val BCE-DiceLoss: 0.5775, METRIC val: 0.3891\n",
      "time consuming of epoch 42 is: 504.8355\n",
      "----------\n",
      "EPOCH 43/80\n",
      "batch: 0/17, train_dl_loss: 0.4737, train_bce_loss: 1.4174, train_bce_dl_loss: 0.4737, step time: 0.4334\n",
      "batch: 1/17, train_dl_loss: 0.5737, train_bce_loss: 1.4400, train_bce_dl_loss: 0.5737, step time: 0.3965\n",
      "batch: 2/17, train_dl_loss: 0.5912, train_bce_loss: 1.4397, train_bce_dl_loss: 0.5912, step time: 0.4334\n",
      "batch: 3/17, train_dl_loss: 0.5590, train_bce_loss: 1.4536, train_bce_dl_loss: 0.5590, step time: 0.3862\n",
      "batch: 4/17, train_dl_loss: 0.5482, train_bce_loss: 1.4363, train_bce_dl_loss: 0.5482, step time: 0.4195\n",
      "batch: 5/17, train_dl_loss: 0.4824, train_bce_loss: 1.4178, train_bce_dl_loss: 0.4824, step time: 0.4443\n",
      "batch: 6/17, train_dl_loss: 0.5166, train_bce_loss: 1.4436, train_bce_dl_loss: 0.5166, step time: 0.4344\n",
      "batch: 7/17, train_dl_loss: 0.4639, train_bce_loss: 1.4180, train_bce_dl_loss: 0.4639, step time: 0.4327\n",
      "batch: 8/17, train_dl_loss: 0.4939, train_bce_loss: 1.4100, train_bce_dl_loss: 0.4939, step time: 0.4325\n",
      "batch: 9/17, train_dl_loss: 0.5055, train_bce_loss: 1.4484, train_bce_dl_loss: 0.5055, step time: 0.4263\n",
      "batch: 10/17, train_dl_loss: 0.5584, train_bce_loss: 1.4323, train_bce_dl_loss: 0.5584, step time: 0.4360\n",
      "batch: 11/17, train_dl_loss: 0.5102, train_bce_loss: 1.4233, train_bce_dl_loss: 0.5102, step time: 0.4411\n",
      "batch: 12/17, train_dl_loss: 0.5157, train_bce_loss: 1.4280, train_bce_dl_loss: 0.5157, step time: 0.4289\n",
      "batch: 13/17, train_dl_loss: 0.6651, train_bce_loss: 1.4439, train_bce_dl_loss: 0.6651, step time: 0.3989\n",
      "batch: 14/17, train_dl_loss: 0.5208, train_bce_loss: 1.4526, train_bce_dl_loss: 0.5208, step time: 0.4310\n",
      "batch: 15/17, train_dl_loss: 0.4774, train_bce_loss: 1.4378, train_bce_dl_loss: 0.4774, step time: 0.3903\n",
      "batch: 16/17, train_dl_loss: 0.4769, train_bce_loss: 1.4375, train_bce_dl_loss: 0.4769, step time: 0.4419\n",
      "batch: 17/17, train_dl_loss: 0.4764, train_bce_loss: 1.4342, train_bce_dl_loss: 0.4764, step time: 0.1161\n",
      "LOSS train DiceLoss: 0.5227, LOSS train BCE: 1.4341, LOSS train BCE-DiceLoss: 0.5227, LOSS val DiceLoss: 0.5812, LOSS val BCE: 1.4336, LOSS val BCE-DiceLoss: 0.5812, METRIC val: 0.3846\n",
      "time consuming of epoch 43 is: 531.9069\n",
      "----------\n",
      "EPOCH 44/80\n",
      "batch: 0/17, train_dl_loss: 0.4985, train_bce_loss: 1.4476, train_bce_dl_loss: 0.4985, step time: 0.4375\n",
      "batch: 1/17, train_dl_loss: 0.4994, train_bce_loss: 1.4503, train_bce_dl_loss: 0.4994, step time: 0.4027\n",
      "batch: 2/17, train_dl_loss: 0.5901, train_bce_loss: 1.4314, train_bce_dl_loss: 0.5901, step time: 0.4539\n",
      "batch: 3/17, train_dl_loss: 0.5427, train_bce_loss: 1.4237, train_bce_dl_loss: 0.5427, step time: 0.3893\n",
      "batch: 4/17, train_dl_loss: 0.4839, train_bce_loss: 1.4407, train_bce_dl_loss: 0.4839, step time: 0.4390\n",
      "batch: 5/17, train_dl_loss: 0.4978, train_bce_loss: 1.4177, train_bce_dl_loss: 0.4978, step time: 0.3983\n",
      "batch: 6/17, train_dl_loss: 0.5241, train_bce_loss: 1.4402, train_bce_dl_loss: 0.5241, step time: 0.4326\n",
      "batch: 7/17, train_dl_loss: 0.4432, train_bce_loss: 1.4163, train_bce_dl_loss: 0.4432, step time: 0.4018\n",
      "batch: 8/17, train_dl_loss: 0.5006, train_bce_loss: 1.4287, train_bce_dl_loss: 0.5006, step time: 0.4368\n",
      "batch: 9/17, train_dl_loss: 0.4870, train_bce_loss: 1.4352, train_bce_dl_loss: 0.4870, step time: 0.3874\n",
      "batch: 10/17, train_dl_loss: 0.5506, train_bce_loss: 1.4391, train_bce_dl_loss: 0.5506, step time: 0.4450\n",
      "batch: 11/17, train_dl_loss: 0.4608, train_bce_loss: 1.4241, train_bce_dl_loss: 0.4608, step time: 0.4369\n",
      "batch: 12/17, train_dl_loss: 0.5054, train_bce_loss: 1.4197, train_bce_dl_loss: 0.5054, step time: 0.4584\n",
      "batch: 13/17, train_dl_loss: 0.6930, train_bce_loss: 1.4478, train_bce_dl_loss: 0.6930, step time: 0.4343\n",
      "batch: 14/17, train_dl_loss: 0.4962, train_bce_loss: 1.4610, train_bce_dl_loss: 0.4962, step time: 0.4404\n",
      "batch: 15/17, train_dl_loss: 0.4737, train_bce_loss: 1.4433, train_bce_dl_loss: 0.4737, step time: 0.3824\n",
      "batch: 16/17, train_dl_loss: 0.5132, train_bce_loss: 1.4463, train_bce_dl_loss: 0.5132, step time: 0.4248\n",
      "batch: 17/17, train_dl_loss: 0.4042, train_bce_loss: 1.4421, train_bce_dl_loss: 0.4042, step time: 0.1174\n",
      "LOSS train DiceLoss: 0.5091, LOSS train BCE: 1.4364, LOSS train BCE-DiceLoss: 0.5091, LOSS val DiceLoss: 0.5802, LOSS val BCE: 1.4370, LOSS val BCE-DiceLoss: 0.5802, METRIC val: 0.3846\n",
      "time consuming of epoch 44 is: 496.7794\n",
      "----------\n",
      "EPOCH 45/80\n",
      "batch: 0/17, train_dl_loss: 0.4953, train_bce_loss: 1.4422, train_bce_dl_loss: 0.4953, step time: 0.4391\n",
      "batch: 1/17, train_dl_loss: 0.5068, train_bce_loss: 1.4428, train_bce_dl_loss: 0.5068, step time: 0.3911\n",
      "batch: 2/17, train_dl_loss: 0.5207, train_bce_loss: 1.4371, train_bce_dl_loss: 0.5207, step time: 0.4501\n",
      "batch: 3/17, train_dl_loss: 0.5345, train_bce_loss: 1.4425, train_bce_dl_loss: 0.5345, step time: 0.3934\n",
      "batch: 4/17, train_dl_loss: 0.4853, train_bce_loss: 1.4271, train_bce_dl_loss: 0.4853, step time: 0.4432\n",
      "batch: 5/17, train_dl_loss: 0.5064, train_bce_loss: 1.4326, train_bce_dl_loss: 0.5064, step time: 0.3841\n",
      "batch: 6/17, train_dl_loss: 0.5519, train_bce_loss: 1.4489, train_bce_dl_loss: 0.5519, step time: 0.4470\n",
      "batch: 7/17, train_dl_loss: 0.4937, train_bce_loss: 1.4262, train_bce_dl_loss: 0.4937, step time: 0.3892\n",
      "batch: 8/17, train_dl_loss: 0.4827, train_bce_loss: 1.4348, train_bce_dl_loss: 0.4827, step time: 0.4648\n",
      "batch: 9/17, train_dl_loss: 0.4751, train_bce_loss: 1.4384, train_bce_dl_loss: 0.4751, step time: 0.3861\n",
      "batch: 10/17, train_dl_loss: 0.6381, train_bce_loss: 1.4407, train_bce_dl_loss: 0.6381, step time: 0.4758\n",
      "batch: 11/17, train_dl_loss: 0.5142, train_bce_loss: 1.4195, train_bce_dl_loss: 0.5142, step time: 0.3963\n",
      "batch: 12/17, train_dl_loss: 0.5070, train_bce_loss: 1.4306, train_bce_dl_loss: 0.5070, step time: 0.4534\n",
      "batch: 13/17, train_dl_loss: 0.6600, train_bce_loss: 1.4600, train_bce_dl_loss: 0.6600, step time: 0.3842\n",
      "batch: 14/17, train_dl_loss: 0.5308, train_bce_loss: 1.4520, train_bce_dl_loss: 0.5308, step time: 0.4415\n",
      "batch: 15/17, train_dl_loss: 0.4615, train_bce_loss: 1.4410, train_bce_dl_loss: 0.4615, step time: 0.3802\n",
      "batch: 16/17, train_dl_loss: 0.5263, train_bce_loss: 1.4477, train_bce_dl_loss: 0.5263, step time: 0.4204\n",
      "batch: 17/17, train_dl_loss: 0.4294, train_bce_loss: 1.4367, train_bce_dl_loss: 0.4294, step time: 0.1169\n",
      "LOSS train DiceLoss: 0.5178, LOSS train BCE: 1.4389, LOSS train BCE-DiceLoss: 0.5178, LOSS val DiceLoss: 0.5755, LOSS val BCE: 1.4393, LOSS val BCE-DiceLoss: 0.5755, METRIC val: 0.3908\n",
      "time consuming of epoch 45 is: 466.2455\n",
      "----------\n",
      "EPOCH 46/80\n",
      "batch: 0/17, train_dl_loss: 0.4952, train_bce_loss: 1.4512, train_bce_dl_loss: 0.4952, step time: 0.4401\n",
      "batch: 1/17, train_dl_loss: 0.5024, train_bce_loss: 1.4508, train_bce_dl_loss: 0.5024, step time: 0.3958\n",
      "batch: 2/17, train_dl_loss: 0.5085, train_bce_loss: 1.4449, train_bce_dl_loss: 0.5085, step time: 0.4347\n",
      "batch: 3/17, train_dl_loss: 0.5592, train_bce_loss: 1.4481, train_bce_dl_loss: 0.5592, step time: 0.3887\n",
      "batch: 4/17, train_dl_loss: 0.4837, train_bce_loss: 1.4477, train_bce_dl_loss: 0.4837, step time: 0.4520\n",
      "batch: 5/17, train_dl_loss: 0.4586, train_bce_loss: 1.4436, train_bce_dl_loss: 0.4586, step time: 0.4390\n",
      "batch: 6/17, train_dl_loss: 0.5581, train_bce_loss: 1.4472, train_bce_dl_loss: 0.5581, step time: 0.4488\n",
      "batch: 7/17, train_dl_loss: 0.4700, train_bce_loss: 1.4310, train_bce_dl_loss: 0.4700, step time: 0.4344\n",
      "batch: 8/17, train_dl_loss: 0.4694, train_bce_loss: 1.4392, train_bce_dl_loss: 0.4694, step time: 0.4412\n",
      "batch: 9/17, train_dl_loss: 0.4868, train_bce_loss: 1.4362, train_bce_dl_loss: 0.4868, step time: 0.4465\n",
      "batch: 10/17, train_dl_loss: 0.6300, train_bce_loss: 1.4440, train_bce_dl_loss: 0.6300, step time: 0.4405\n",
      "batch: 11/17, train_dl_loss: 0.5081, train_bce_loss: 1.4306, train_bce_dl_loss: 0.5081, step time: 0.4446\n",
      "batch: 12/17, train_dl_loss: 0.5091, train_bce_loss: 1.4315, train_bce_dl_loss: 0.5091, step time: 0.4431\n",
      "batch: 13/17, train_dl_loss: 0.6452, train_bce_loss: 1.4482, train_bce_dl_loss: 0.6452, step time: 0.4358\n",
      "batch: 14/17, train_dl_loss: 0.5336, train_bce_loss: 1.4538, train_bce_dl_loss: 0.5336, step time: 0.4366\n",
      "batch: 15/17, train_dl_loss: 0.4738, train_bce_loss: 1.4545, train_bce_dl_loss: 0.4738, step time: 0.4316\n",
      "batch: 16/17, train_dl_loss: 0.4729, train_bce_loss: 1.4465, train_bce_dl_loss: 0.4729, step time: 0.4286\n",
      "batch: 17/17, train_dl_loss: 0.6428, train_bce_loss: 1.4646, train_bce_dl_loss: 0.6428, step time: 0.1171\n",
      "LOSS train DiceLoss: 0.5226, LOSS train BCE: 1.4452, LOSS train BCE-DiceLoss: 0.5226, LOSS val DiceLoss: 0.5810, LOSS val BCE: 1.4432, LOSS val BCE-DiceLoss: 0.5810, METRIC val: 0.3846\n",
      "time consuming of epoch 46 is: 487.5365\n",
      "----------\n",
      "EPOCH 47/80\n",
      "batch: 0/17, train_dl_loss: 0.5802, train_bce_loss: 1.4625, train_bce_dl_loss: 0.5802, step time: 0.4367\n",
      "batch: 1/17, train_dl_loss: 0.4765, train_bce_loss: 1.4407, train_bce_dl_loss: 0.4765, step time: 0.3922\n",
      "batch: 2/17, train_dl_loss: 0.5100, train_bce_loss: 1.4399, train_bce_dl_loss: 0.5100, step time: 0.4337\n",
      "batch: 3/17, train_dl_loss: 0.5393, train_bce_loss: 1.4498, train_bce_dl_loss: 0.5393, step time: 0.3855\n",
      "batch: 4/17, train_dl_loss: 0.5025, train_bce_loss: 1.4510, train_bce_dl_loss: 0.5025, step time: 0.4304\n",
      "batch: 5/17, train_dl_loss: 0.4510, train_bce_loss: 1.4375, train_bce_dl_loss: 0.4510, step time: 0.3837\n",
      "batch: 6/17, train_dl_loss: 0.5169, train_bce_loss: 1.4453, train_bce_dl_loss: 0.5169, step time: 0.4294\n",
      "batch: 7/17, train_dl_loss: 0.4617, train_bce_loss: 1.4425, train_bce_dl_loss: 0.4617, step time: 0.3849\n",
      "batch: 8/17, train_dl_loss: 0.4601, train_bce_loss: 1.4248, train_bce_dl_loss: 0.4601, step time: 0.4318\n",
      "batch: 9/17, train_dl_loss: 0.5478, train_bce_loss: 1.4553, train_bce_dl_loss: 0.5478, step time: 0.3879\n",
      "batch: 10/17, train_dl_loss: 0.5820, train_bce_loss: 1.4501, train_bce_dl_loss: 0.5820, step time: 0.4425\n",
      "batch: 11/17, train_dl_loss: 0.4716, train_bce_loss: 1.4350, train_bce_dl_loss: 0.4716, step time: 0.4363\n",
      "batch: 12/17, train_dl_loss: 0.4604, train_bce_loss: 1.4323, train_bce_dl_loss: 0.4604, step time: 0.4279\n",
      "batch: 13/17, train_dl_loss: 0.6232, train_bce_loss: 1.4489, train_bce_dl_loss: 0.6232, step time: 0.3832\n",
      "batch: 14/17, train_dl_loss: 0.4746, train_bce_loss: 1.4626, train_bce_dl_loss: 0.4746, step time: 0.4460\n",
      "batch: 15/17, train_dl_loss: 0.5055, train_bce_loss: 1.4499, train_bce_dl_loss: 0.5055, step time: 0.3936\n",
      "batch: 16/17, train_dl_loss: 0.4776, train_bce_loss: 1.4480, train_bce_dl_loss: 0.4776, step time: 0.4381\n",
      "batch: 17/17, train_dl_loss: 0.4680, train_bce_loss: 1.4418, train_bce_dl_loss: 0.4680, step time: 0.1219\n",
      "LOSS train DiceLoss: 0.5061, LOSS train BCE: 1.4454, LOSS train BCE-DiceLoss: 0.5061, LOSS val DiceLoss: 0.5728, LOSS val BCE: 1.4430, LOSS val BCE-DiceLoss: 0.5728, METRIC val: 0.3934\n",
      "time consuming of epoch 47 is: 468.7725\n",
      "----------\n",
      "EPOCH 48/80\n",
      "batch: 0/17, train_dl_loss: 0.4486, train_bce_loss: 1.4349, train_bce_dl_loss: 0.4486, step time: 0.4431\n",
      "batch: 1/17, train_dl_loss: 0.4786, train_bce_loss: 1.4430, train_bce_dl_loss: 0.4786, step time: 0.3936\n",
      "batch: 2/17, train_dl_loss: 0.5280, train_bce_loss: 1.4497, train_bce_dl_loss: 0.5280, step time: 0.4435\n",
      "batch: 3/17, train_dl_loss: 0.5486, train_bce_loss: 1.4462, train_bce_dl_loss: 0.5486, step time: 0.3872\n",
      "batch: 4/17, train_dl_loss: 0.4940, train_bce_loss: 1.4634, train_bce_dl_loss: 0.4940, step time: 0.4425\n",
      "batch: 5/17, train_dl_loss: 0.5024, train_bce_loss: 1.4336, train_bce_dl_loss: 0.5024, step time: 0.3886\n",
      "batch: 6/17, train_dl_loss: 0.5576, train_bce_loss: 1.4499, train_bce_dl_loss: 0.5576, step time: 0.4508\n",
      "batch: 7/17, train_dl_loss: 0.4489, train_bce_loss: 1.4305, train_bce_dl_loss: 0.4489, step time: 0.3937\n",
      "batch: 8/17, train_dl_loss: 0.5293, train_bce_loss: 1.4458, train_bce_dl_loss: 0.5293, step time: 0.4592\n",
      "batch: 9/17, train_dl_loss: 0.4644, train_bce_loss: 1.4482, train_bce_dl_loss: 0.4644, step time: 0.4071\n",
      "batch: 10/17, train_dl_loss: 0.5538, train_bce_loss: 1.4342, train_bce_dl_loss: 0.5538, step time: 0.4501\n",
      "batch: 11/17, train_dl_loss: 0.4374, train_bce_loss: 1.4277, train_bce_dl_loss: 0.4374, step time: 0.4101\n",
      "batch: 12/17, train_dl_loss: 0.4712, train_bce_loss: 1.4418, train_bce_dl_loss: 0.4712, step time: 0.4457\n",
      "batch: 13/17, train_dl_loss: 0.6427, train_bce_loss: 1.4617, train_bce_dl_loss: 0.6427, step time: 0.3953\n",
      "batch: 14/17, train_dl_loss: 0.5156, train_bce_loss: 1.4619, train_bce_dl_loss: 0.5156, step time: 0.4320\n",
      "batch: 15/17, train_dl_loss: 0.4881, train_bce_loss: 1.4559, train_bce_dl_loss: 0.4881, step time: 0.3876\n",
      "batch: 16/17, train_dl_loss: 0.4884, train_bce_loss: 1.4508, train_bce_dl_loss: 0.4884, step time: 0.4153\n",
      "batch: 17/17, train_dl_loss: 0.4362, train_bce_loss: 1.4576, train_bce_dl_loss: 0.4362, step time: 0.1148\n",
      "LOSS train DiceLoss: 0.5019, LOSS train BCE: 1.4465, LOSS train BCE-DiceLoss: 0.5019, LOSS val DiceLoss: 0.5763, LOSS val BCE: 1.4467, LOSS val BCE-DiceLoss: 0.5763, METRIC val: 0.3895\n",
      "time consuming of epoch 48 is: 472.9250\n",
      "----------\n",
      "EPOCH 49/80\n",
      "batch: 0/17, train_dl_loss: 0.4594, train_bce_loss: 1.4503, train_bce_dl_loss: 0.4594, step time: 0.4731\n",
      "batch: 1/17, train_dl_loss: 0.5333, train_bce_loss: 1.4540, train_bce_dl_loss: 0.5333, step time: 0.3767\n",
      "batch: 2/17, train_dl_loss: 0.5305, train_bce_loss: 1.4521, train_bce_dl_loss: 0.5305, step time: 0.4190\n",
      "batch: 3/17, train_dl_loss: 0.5940, train_bce_loss: 1.4502, train_bce_dl_loss: 0.5940, step time: 0.3845\n",
      "batch: 4/17, train_dl_loss: 0.4591, train_bce_loss: 1.4529, train_bce_dl_loss: 0.4591, step time: 0.4531\n",
      "batch: 5/17, train_dl_loss: 0.4693, train_bce_loss: 1.4556, train_bce_dl_loss: 0.4693, step time: 0.3870\n",
      "batch: 6/17, train_dl_loss: 0.5277, train_bce_loss: 1.4608, train_bce_dl_loss: 0.5277, step time: 0.4379\n",
      "batch: 7/17, train_dl_loss: 0.4630, train_bce_loss: 1.4324, train_bce_dl_loss: 0.4630, step time: 0.3912\n",
      "batch: 8/17, train_dl_loss: 0.5220, train_bce_loss: 1.4482, train_bce_dl_loss: 0.5220, step time: 0.4397\n",
      "batch: 9/17, train_dl_loss: 0.4924, train_bce_loss: 1.4424, train_bce_dl_loss: 0.4924, step time: 0.3839\n",
      "batch: 10/17, train_dl_loss: 0.6614, train_bce_loss: 1.4567, train_bce_dl_loss: 0.6614, step time: 0.4235\n",
      "batch: 11/17, train_dl_loss: 0.4895, train_bce_loss: 1.4509, train_bce_dl_loss: 0.4895, step time: 0.4278\n",
      "batch: 12/17, train_dl_loss: 0.4798, train_bce_loss: 1.4449, train_bce_dl_loss: 0.4798, step time: 0.4408\n",
      "batch: 13/17, train_dl_loss: 0.6341, train_bce_loss: 1.4622, train_bce_dl_loss: 0.6341, step time: 0.4317\n",
      "batch: 14/17, train_dl_loss: 0.5122, train_bce_loss: 1.4524, train_bce_dl_loss: 0.5122, step time: 0.4171\n",
      "batch: 15/17, train_dl_loss: 0.5402, train_bce_loss: 1.4563, train_bce_dl_loss: 0.5402, step time: 0.4373\n",
      "batch: 16/17, train_dl_loss: 0.4946, train_bce_loss: 1.4570, train_bce_dl_loss: 0.4946, step time: 0.4222\n",
      "batch: 17/17, train_dl_loss: 0.4161, train_bce_loss: 1.4461, train_bce_dl_loss: 0.4161, step time: 0.1149\n",
      "LOSS train DiceLoss: 0.5155, LOSS train BCE: 1.4514, LOSS train BCE-DiceLoss: 0.5155, LOSS val DiceLoss: 0.5678, LOSS val BCE: 1.4492, LOSS val BCE-DiceLoss: 0.5678, METRIC val: 0.3996\n",
      "time consuming of epoch 49 is: 431.0207\n",
      "----------\n",
      "EPOCH 50/80\n",
      "batch: 0/17, train_dl_loss: 0.4569, train_bce_loss: 1.4530, train_bce_dl_loss: 0.4569, step time: 0.4435\n",
      "batch: 1/17, train_dl_loss: 0.5692, train_bce_loss: 1.4735, train_bce_dl_loss: 0.5692, step time: 0.3823\n",
      "batch: 2/17, train_dl_loss: 0.5094, train_bce_loss: 1.4645, train_bce_dl_loss: 0.5094, step time: 0.4306\n",
      "batch: 3/17, train_dl_loss: 0.5261, train_bce_loss: 1.4582, train_bce_dl_loss: 0.5261, step time: 0.3828\n",
      "batch: 4/17, train_dl_loss: 0.4773, train_bce_loss: 1.4440, train_bce_dl_loss: 0.4773, step time: 0.4683\n",
      "batch: 5/17, train_dl_loss: 0.4805, train_bce_loss: 1.4509, train_bce_dl_loss: 0.4805, step time: 0.3795\n",
      "batch: 6/17, train_dl_loss: 0.5545, train_bce_loss: 1.4659, train_bce_dl_loss: 0.5545, step time: 0.4383\n",
      "batch: 7/17, train_dl_loss: 0.5108, train_bce_loss: 1.4573, train_bce_dl_loss: 0.5108, step time: 0.3812\n",
      "batch: 8/17, train_dl_loss: 0.4748, train_bce_loss: 1.4301, train_bce_dl_loss: 0.4748, step time: 0.4221\n",
      "batch: 9/17, train_dl_loss: 0.4653, train_bce_loss: 1.4517, train_bce_dl_loss: 0.4653, step time: 0.3781\n",
      "batch: 10/17, train_dl_loss: 0.5454, train_bce_loss: 1.4408, train_bce_dl_loss: 0.5454, step time: 0.4239\n",
      "batch: 11/17, train_dl_loss: 0.4708, train_bce_loss: 1.4282, train_bce_dl_loss: 0.4708, step time: 0.4435\n",
      "batch: 12/17, train_dl_loss: 0.5226, train_bce_loss: 1.4470, train_bce_dl_loss: 0.5226, step time: 0.4257\n",
      "batch: 13/17, train_dl_loss: 0.6551, train_bce_loss: 1.4514, train_bce_dl_loss: 0.6551, step time: 0.3765\n",
      "batch: 14/17, train_dl_loss: 0.5212, train_bce_loss: 1.4643, train_bce_dl_loss: 0.5212, step time: 0.4359\n",
      "batch: 15/17, train_dl_loss: 0.4978, train_bce_loss: 1.4440, train_bce_dl_loss: 0.4978, step time: 0.3774\n",
      "batch: 16/17, train_dl_loss: 0.5108, train_bce_loss: 1.4523, train_bce_dl_loss: 0.5108, step time: 0.4176\n",
      "batch: 17/17, train_dl_loss: 0.4219, train_bce_loss: 1.4565, train_bce_dl_loss: 0.4219, step time: 0.1143\n",
      "LOSS train DiceLoss: 0.5095, LOSS train BCE: 1.4519, LOSS train BCE-DiceLoss: 0.5095, LOSS val DiceLoss: 0.5762, LOSS val BCE: 1.4497, LOSS val BCE-DiceLoss: 0.5762, METRIC val: 0.3901\n",
      "time consuming of epoch 50 is: 421.7480\n",
      "----------\n",
      "EPOCH 51/80\n",
      "batch: 0/17, train_dl_loss: 0.4539, train_bce_loss: 1.4524, train_bce_dl_loss: 0.4539, step time: 0.4294\n",
      "batch: 1/17, train_dl_loss: 0.4730, train_bce_loss: 1.4573, train_bce_dl_loss: 0.4730, step time: 0.3839\n",
      "batch: 2/17, train_dl_loss: 0.4976, train_bce_loss: 1.4501, train_bce_dl_loss: 0.4976, step time: 0.4229\n",
      "batch: 3/17, train_dl_loss: 0.5328, train_bce_loss: 1.4631, train_bce_dl_loss: 0.5328, step time: 0.3836\n",
      "batch: 4/17, train_dl_loss: 0.4864, train_bce_loss: 1.4592, train_bce_dl_loss: 0.4864, step time: 0.4204\n",
      "batch: 5/17, train_dl_loss: 0.4722, train_bce_loss: 1.4582, train_bce_dl_loss: 0.4722, step time: 0.3824\n",
      "batch: 6/17, train_dl_loss: 0.5478, train_bce_loss: 1.4642, train_bce_dl_loss: 0.5478, step time: 0.4332\n",
      "batch: 7/17, train_dl_loss: 0.4654, train_bce_loss: 1.4420, train_bce_dl_loss: 0.4654, step time: 0.4295\n",
      "batch: 8/17, train_dl_loss: 0.4482, train_bce_loss: 1.4407, train_bce_dl_loss: 0.4482, step time: 0.4366\n",
      "batch: 9/17, train_dl_loss: 0.4818, train_bce_loss: 1.4539, train_bce_dl_loss: 0.4818, step time: 0.3892\n",
      "batch: 10/17, train_dl_loss: 0.5998, train_bce_loss: 1.4430, train_bce_dl_loss: 0.5998, step time: 0.4365\n",
      "batch: 11/17, train_dl_loss: 0.4876, train_bce_loss: 1.4533, train_bce_dl_loss: 0.4876, step time: 0.4398\n",
      "batch: 12/17, train_dl_loss: 0.4787, train_bce_loss: 1.4434, train_bce_dl_loss: 0.4787, step time: 0.4449\n",
      "batch: 13/17, train_dl_loss: 0.6923, train_bce_loss: 1.4680, train_bce_dl_loss: 0.6923, step time: 0.3805\n",
      "batch: 14/17, train_dl_loss: 0.5605, train_bce_loss: 1.4754, train_bce_dl_loss: 0.5605, step time: 0.4443\n",
      "batch: 15/17, train_dl_loss: 0.4844, train_bce_loss: 1.4489, train_bce_dl_loss: 0.4844, step time: 0.3899\n",
      "batch: 16/17, train_dl_loss: 0.5148, train_bce_loss: 1.4598, train_bce_dl_loss: 0.5148, step time: 0.4190\n",
      "batch: 17/17, train_dl_loss: 0.4374, train_bce_loss: 1.4564, train_bce_dl_loss: 0.4374, step time: 0.1140\n",
      "LOSS train DiceLoss: 0.5064, LOSS train BCE: 1.4550, LOSS train BCE-DiceLoss: 0.5064, LOSS val DiceLoss: 0.5675, LOSS val BCE: 1.4513, LOSS val BCE-DiceLoss: 0.5675, METRIC val: 0.4004\n",
      "time consuming of epoch 51 is: 462.8919\n",
      "----------\n",
      "EPOCH 52/80\n",
      "batch: 0/17, train_dl_loss: 0.5211, train_bce_loss: 1.4627, train_bce_dl_loss: 0.5211, step time: 0.4199\n",
      "batch: 1/17, train_dl_loss: 0.4837, train_bce_loss: 1.4524, train_bce_dl_loss: 0.4837, step time: 0.3804\n",
      "batch: 2/17, train_dl_loss: 0.5548, train_bce_loss: 1.4568, train_bce_dl_loss: 0.5548, step time: 0.4723\n",
      "batch: 3/17, train_dl_loss: 0.5234, train_bce_loss: 1.4492, train_bce_dl_loss: 0.5234, step time: 0.3727\n",
      "batch: 4/17, train_dl_loss: 0.4447, train_bce_loss: 1.4632, train_bce_dl_loss: 0.4447, step time: 0.4235\n",
      "batch: 5/17, train_dl_loss: 0.5079, train_bce_loss: 1.4588, train_bce_dl_loss: 0.5079, step time: 0.3883\n",
      "batch: 6/17, train_dl_loss: 0.5067, train_bce_loss: 1.4619, train_bce_dl_loss: 0.5067, step time: 0.4384\n",
      "batch: 7/17, train_dl_loss: 0.4514, train_bce_loss: 1.4440, train_bce_dl_loss: 0.4514, step time: 0.3829\n",
      "batch: 8/17, train_dl_loss: 0.4808, train_bce_loss: 1.4368, train_bce_dl_loss: 0.4808, step time: 0.4795\n",
      "batch: 9/17, train_dl_loss: 0.5302, train_bce_loss: 1.4836, train_bce_dl_loss: 0.5302, step time: 0.4510\n",
      "batch: 10/17, train_dl_loss: 0.5825, train_bce_loss: 1.4637, train_bce_dl_loss: 0.5825, step time: 0.4432\n",
      "batch: 11/17, train_dl_loss: 0.4676, train_bce_loss: 1.4605, train_bce_dl_loss: 0.4676, step time: 0.4310\n",
      "batch: 12/17, train_dl_loss: 0.4559, train_bce_loss: 1.4475, train_bce_dl_loss: 0.4559, step time: 0.4349\n",
      "batch: 13/17, train_dl_loss: 0.6541, train_bce_loss: 1.4678, train_bce_dl_loss: 0.6541, step time: 0.4249\n",
      "batch: 14/17, train_dl_loss: 0.4880, train_bce_loss: 1.4718, train_bce_dl_loss: 0.4880, step time: 0.4325\n",
      "batch: 15/17, train_dl_loss: 0.4904, train_bce_loss: 1.4551, train_bce_dl_loss: 0.4904, step time: 0.3817\n",
      "batch: 16/17, train_dl_loss: 0.4883, train_bce_loss: 1.4530, train_bce_dl_loss: 0.4883, step time: 0.4311\n",
      "batch: 17/17, train_dl_loss: 0.5610, train_bce_loss: 1.4717, train_bce_dl_loss: 0.5610, step time: 0.1121\n",
      "LOSS train DiceLoss: 0.5107, LOSS train BCE: 1.4589, LOSS train BCE-DiceLoss: 0.5107, LOSS val DiceLoss: 0.5707, LOSS val BCE: 1.4506, LOSS val BCE-DiceLoss: 0.5707, METRIC val: 0.3960\n",
      "time consuming of epoch 52 is: 435.2991\n",
      "----------\n",
      "EPOCH 53/80\n",
      "batch: 0/17, train_dl_loss: 0.4993, train_bce_loss: 1.4576, train_bce_dl_loss: 0.4993, step time: 0.4318\n",
      "batch: 1/17, train_dl_loss: 0.4665, train_bce_loss: 1.4765, train_bce_dl_loss: 0.4665, step time: 0.3811\n",
      "batch: 2/17, train_dl_loss: 0.5718, train_bce_loss: 1.4674, train_bce_dl_loss: 0.5718, step time: 0.4812\n",
      "batch: 3/17, train_dl_loss: 0.5574, train_bce_loss: 1.4702, train_bce_dl_loss: 0.5574, step time: 0.3752\n",
      "batch: 4/17, train_dl_loss: 0.5056, train_bce_loss: 1.4762, train_bce_dl_loss: 0.5056, step time: 0.4331\n",
      "batch: 5/17, train_dl_loss: 0.4521, train_bce_loss: 1.4579, train_bce_dl_loss: 0.4521, step time: 0.3845\n",
      "batch: 6/17, train_dl_loss: 0.5353, train_bce_loss: 1.4653, train_bce_dl_loss: 0.5353, step time: 0.4429\n",
      "batch: 7/17, train_dl_loss: 0.4711, train_bce_loss: 1.4584, train_bce_dl_loss: 0.4711, step time: 0.4307\n",
      "batch: 8/17, train_dl_loss: 0.4990, train_bce_loss: 1.4471, train_bce_dl_loss: 0.4990, step time: 0.4301\n",
      "batch: 9/17, train_dl_loss: 0.4940, train_bce_loss: 1.4557, train_bce_dl_loss: 0.4940, step time: 0.4678\n",
      "batch: 10/17, train_dl_loss: 0.5600, train_bce_loss: 1.4675, train_bce_dl_loss: 0.5600, step time: 0.4311\n",
      "batch: 11/17, train_dl_loss: 0.4856, train_bce_loss: 1.4390, train_bce_dl_loss: 0.4856, step time: 0.4439\n",
      "batch: 12/17, train_dl_loss: 0.5419, train_bce_loss: 1.4641, train_bce_dl_loss: 0.5419, step time: 0.4286\n",
      "batch: 13/17, train_dl_loss: 0.6305, train_bce_loss: 1.4646, train_bce_dl_loss: 0.6305, step time: 0.4288\n",
      "batch: 14/17, train_dl_loss: 0.4738, train_bce_loss: 1.4655, train_bce_dl_loss: 0.4738, step time: 0.4264\n",
      "batch: 15/17, train_dl_loss: 0.5254, train_bce_loss: 1.4557, train_bce_dl_loss: 0.5254, step time: 0.3884\n",
      "batch: 16/17, train_dl_loss: 0.4832, train_bce_loss: 1.4577, train_bce_dl_loss: 0.4832, step time: 0.4345\n",
      "batch: 17/17, train_dl_loss: 0.5619, train_bce_loss: 1.4687, train_bce_dl_loss: 0.5619, step time: 0.1125\n",
      "LOSS train DiceLoss: 0.5175, LOSS train BCE: 1.4619, LOSS train BCE-DiceLoss: 0.5175, LOSS val DiceLoss: 0.5665, LOSS val BCE: 1.4473, LOSS val BCE-DiceLoss: 0.5665, METRIC val: 0.4012\n",
      "time consuming of epoch 53 is: 411.3061\n",
      "----------\n",
      "EPOCH 54/80\n",
      "batch: 0/17, train_dl_loss: 0.4503, train_bce_loss: 1.4466, train_bce_dl_loss: 0.4503, step time: 0.4418\n",
      "batch: 1/17, train_dl_loss: 0.5338, train_bce_loss: 1.4760, train_bce_dl_loss: 0.5338, step time: 0.3823\n",
      "batch: 2/17, train_dl_loss: 0.5086, train_bce_loss: 1.4499, train_bce_dl_loss: 0.5086, step time: 0.4370\n",
      "batch: 3/17, train_dl_loss: 0.5545, train_bce_loss: 1.4611, train_bce_dl_loss: 0.5545, step time: 0.3792\n",
      "batch: 4/17, train_dl_loss: 0.4553, train_bce_loss: 1.4436, train_bce_dl_loss: 0.4553, step time: 0.4258\n",
      "batch: 5/17, train_dl_loss: 0.4746, train_bce_loss: 1.4448, train_bce_dl_loss: 0.4746, step time: 0.3775\n",
      "batch: 6/17, train_dl_loss: 0.5015, train_bce_loss: 1.4716, train_bce_dl_loss: 0.5015, step time: 0.4427\n",
      "batch: 7/17, train_dl_loss: 0.4998, train_bce_loss: 1.4531, train_bce_dl_loss: 0.4998, step time: 0.3912\n",
      "batch: 8/17, train_dl_loss: 0.4932, train_bce_loss: 1.4582, train_bce_dl_loss: 0.4932, step time: 0.4221\n",
      "batch: 9/17, train_dl_loss: 0.5011, train_bce_loss: 1.4607, train_bce_dl_loss: 0.5011, step time: 0.3847\n",
      "batch: 10/17, train_dl_loss: 0.5742, train_bce_loss: 1.4632, train_bce_dl_loss: 0.5742, step time: 0.4397\n",
      "batch: 11/17, train_dl_loss: 0.4702, train_bce_loss: 1.4335, train_bce_dl_loss: 0.4702, step time: 0.3834\n",
      "batch: 12/17, train_dl_loss: 0.4716, train_bce_loss: 1.4465, train_bce_dl_loss: 0.4716, step time: 0.4344\n",
      "batch: 13/17, train_dl_loss: 0.6371, train_bce_loss: 1.4632, train_bce_dl_loss: 0.6371, step time: 0.3866\n",
      "batch: 14/17, train_dl_loss: 0.5126, train_bce_loss: 1.4735, train_bce_dl_loss: 0.5126, step time: 0.4199\n",
      "batch: 15/17, train_dl_loss: 0.4611, train_bce_loss: 1.4513, train_bce_dl_loss: 0.4611, step time: 0.3816\n",
      "batch: 16/17, train_dl_loss: 0.4716, train_bce_loss: 1.4592, train_bce_dl_loss: 0.4716, step time: 0.4123\n",
      "batch: 17/17, train_dl_loss: 0.4736, train_bce_loss: 1.4489, train_bce_dl_loss: 0.4736, step time: 0.1123\n",
      "LOSS train DiceLoss: 0.5025, LOSS train BCE: 1.4558, LOSS train BCE-DiceLoss: 0.5025, LOSS val DiceLoss: 0.5669, LOSS val BCE: 1.4486, LOSS val BCE-DiceLoss: 0.5669, METRIC val: 0.4010\n",
      "time consuming of epoch 54 is: 420.1019\n",
      "----------\n",
      "EPOCH 55/80\n",
      "batch: 0/17, train_dl_loss: 0.4961, train_bce_loss: 1.4564, train_bce_dl_loss: 0.4961, step time: 0.4457\n",
      "batch: 1/17, train_dl_loss: 0.5181, train_bce_loss: 1.4530, train_bce_dl_loss: 0.5181, step time: 0.3977\n",
      "batch: 2/17, train_dl_loss: 0.5372, train_bce_loss: 1.4590, train_bce_dl_loss: 0.5372, step time: 0.4721\n",
      "batch: 3/17, train_dl_loss: 0.5827, train_bce_loss: 1.4685, train_bce_dl_loss: 0.5827, step time: 0.3751\n",
      "batch: 4/17, train_dl_loss: 0.4171, train_bce_loss: 1.4512, train_bce_dl_loss: 0.4171, step time: 0.4482\n",
      "batch: 5/17, train_dl_loss: 0.4681, train_bce_loss: 1.4444, train_bce_dl_loss: 0.4681, step time: 0.3886\n",
      "batch: 6/17, train_dl_loss: 0.5378, train_bce_loss: 1.4691, train_bce_dl_loss: 0.5378, step time: 0.4251\n",
      "batch: 7/17, train_dl_loss: 0.5213, train_bce_loss: 1.4698, train_bce_dl_loss: 0.5213, step time: 0.3834\n",
      "batch: 8/17, train_dl_loss: 0.4541, train_bce_loss: 1.4630, train_bce_dl_loss: 0.4541, step time: 0.4431\n",
      "batch: 9/17, train_dl_loss: 0.4505, train_bce_loss: 1.4749, train_bce_dl_loss: 0.4505, step time: 0.3943\n",
      "batch: 10/17, train_dl_loss: 0.6174, train_bce_loss: 1.4677, train_bce_dl_loss: 0.6174, step time: 0.4338\n",
      "batch: 11/17, train_dl_loss: 0.5199, train_bce_loss: 1.4550, train_bce_dl_loss: 0.5199, step time: 0.3934\n",
      "batch: 12/17, train_dl_loss: 0.5302, train_bce_loss: 1.4650, train_bce_dl_loss: 0.5302, step time: 0.4324\n",
      "batch: 13/17, train_dl_loss: 0.6491, train_bce_loss: 1.4616, train_bce_dl_loss: 0.6491, step time: 0.3856\n",
      "batch: 14/17, train_dl_loss: 0.4863, train_bce_loss: 1.4634, train_bce_dl_loss: 0.4863, step time: 0.4345\n",
      "batch: 15/17, train_dl_loss: 0.4872, train_bce_loss: 1.4620, train_bce_dl_loss: 0.4872, step time: 0.4552\n",
      "batch: 16/17, train_dl_loss: 0.5013, train_bce_loss: 1.4599, train_bce_dl_loss: 0.5013, step time: 0.4154\n",
      "batch: 17/17, train_dl_loss: 0.4195, train_bce_loss: 1.4548, train_bce_dl_loss: 0.4195, step time: 0.1130\n",
      "LOSS train DiceLoss: 0.5108, LOSS train BCE: 1.4610, LOSS train BCE-DiceLoss: 0.5108, LOSS val DiceLoss: 0.5634, LOSS val BCE: 1.4499, LOSS val BCE-DiceLoss: 0.5634, METRIC val: 0.4047\n",
      "time consuming of epoch 55 is: 447.3670\n",
      "----------\n",
      "EPOCH 56/80\n",
      "batch: 0/17, train_dl_loss: 0.4748, train_bce_loss: 1.4564, train_bce_dl_loss: 0.4748, step time: 0.4367\n",
      "batch: 1/17, train_dl_loss: 0.5118, train_bce_loss: 1.4741, train_bce_dl_loss: 0.5118, step time: 0.3755\n",
      "batch: 2/17, train_dl_loss: 0.4921, train_bce_loss: 1.4620, train_bce_dl_loss: 0.4921, step time: 0.4405\n",
      "batch: 3/17, train_dl_loss: 0.5413, train_bce_loss: 1.4550, train_bce_dl_loss: 0.5413, step time: 0.3810\n",
      "batch: 4/17, train_dl_loss: 0.4243, train_bce_loss: 1.4537, train_bce_dl_loss: 0.4243, step time: 0.4314\n",
      "batch: 5/17, train_dl_loss: 0.4633, train_bce_loss: 1.4590, train_bce_dl_loss: 0.4633, step time: 0.3793\n",
      "batch: 6/17, train_dl_loss: 0.5256, train_bce_loss: 1.4737, train_bce_dl_loss: 0.5256, step time: 0.4276\n",
      "batch: 7/17, train_dl_loss: 0.4454, train_bce_loss: 1.4608, train_bce_dl_loss: 0.4454, step time: 0.3791\n",
      "batch: 8/17, train_dl_loss: 0.4851, train_bce_loss: 1.4383, train_bce_dl_loss: 0.4851, step time: 0.4207\n",
      "batch: 9/17, train_dl_loss: 0.4573, train_bce_loss: 1.4627, train_bce_dl_loss: 0.4573, step time: 0.4431\n",
      "batch: 10/17, train_dl_loss: 0.5488, train_bce_loss: 1.4636, train_bce_dl_loss: 0.5488, step time: 0.4321\n",
      "batch: 11/17, train_dl_loss: 0.4803, train_bce_loss: 1.4419, train_bce_dl_loss: 0.4803, step time: 0.5083\n",
      "batch: 12/17, train_dl_loss: 0.4851, train_bce_loss: 1.4467, train_bce_dl_loss: 0.4851, step time: 0.4397\n",
      "batch: 13/17, train_dl_loss: 0.6170, train_bce_loss: 1.4657, train_bce_dl_loss: 0.6170, step time: 0.3796\n",
      "batch: 14/17, train_dl_loss: 0.5473, train_bce_loss: 1.4746, train_bce_dl_loss: 0.5473, step time: 0.4359\n",
      "batch: 15/17, train_dl_loss: 0.4372, train_bce_loss: 1.4620, train_bce_dl_loss: 0.4372, step time: 0.3806\n",
      "batch: 16/17, train_dl_loss: 0.4736, train_bce_loss: 1.4689, train_bce_dl_loss: 0.4736, step time: 0.4231\n",
      "batch: 17/17, train_dl_loss: 0.3891, train_bce_loss: 1.4707, train_bce_dl_loss: 0.3891, step time: 0.1126\n",
      "LOSS train DiceLoss: 0.4889, LOSS train BCE: 1.4606, LOSS train BCE-DiceLoss: 0.4889, LOSS val DiceLoss: 0.5609, LOSS val BCE: 1.4550, LOSS val BCE-DiceLoss: 0.5609, METRIC val: 0.4072\n",
      "time consuming of epoch 56 is: 420.6948\n",
      "----------\n",
      "EPOCH 57/80\n",
      "batch: 0/17, train_dl_loss: 0.4543, train_bce_loss: 1.4435, train_bce_dl_loss: 0.4543, step time: 0.4470\n",
      "batch: 1/17, train_dl_loss: 0.4434, train_bce_loss: 1.4644, train_bce_dl_loss: 0.4434, step time: 0.3797\n",
      "batch: 2/17, train_dl_loss: 0.4919, train_bce_loss: 1.4602, train_bce_dl_loss: 0.4919, step time: 0.4195\n",
      "batch: 3/17, train_dl_loss: 0.5248, train_bce_loss: 1.4562, train_bce_dl_loss: 0.5248, step time: 0.3812\n",
      "batch: 4/17, train_dl_loss: 0.4681, train_bce_loss: 1.4523, train_bce_dl_loss: 0.4681, step time: 0.4198\n",
      "batch: 5/17, train_dl_loss: 0.4814, train_bce_loss: 1.4529, train_bce_dl_loss: 0.4814, step time: 0.3755\n",
      "batch: 6/17, train_dl_loss: 0.4911, train_bce_loss: 1.4788, train_bce_dl_loss: 0.4911, step time: 0.4464\n",
      "batch: 7/17, train_dl_loss: 0.4743, train_bce_loss: 1.4662, train_bce_dl_loss: 0.4743, step time: 0.3829\n",
      "batch: 8/17, train_dl_loss: 0.4526, train_bce_loss: 1.4578, train_bce_dl_loss: 0.4526, step time: 0.4343\n",
      "batch: 9/17, train_dl_loss: 0.4760, train_bce_loss: 1.4602, train_bce_dl_loss: 0.4760, step time: 0.3741\n",
      "batch: 10/17, train_dl_loss: 0.5586, train_bce_loss: 1.4620, train_bce_dl_loss: 0.5586, step time: 0.4270\n",
      "batch: 11/17, train_dl_loss: 0.4374, train_bce_loss: 1.4343, train_bce_dl_loss: 0.4374, step time: 0.4280\n",
      "batch: 12/17, train_dl_loss: 0.4718, train_bce_loss: 1.4617, train_bce_dl_loss: 0.4718, step time: 0.4371\n",
      "batch: 13/17, train_dl_loss: 0.5802, train_bce_loss: 1.4683, train_bce_dl_loss: 0.5802, step time: 0.3813\n",
      "batch: 14/17, train_dl_loss: 0.4725, train_bce_loss: 1.4719, train_bce_dl_loss: 0.4725, step time: 0.4239\n",
      "batch: 15/17, train_dl_loss: 0.4483, train_bce_loss: 1.4662, train_bce_dl_loss: 0.4483, step time: 0.3881\n",
      "batch: 16/17, train_dl_loss: 0.4799, train_bce_loss: 1.4640, train_bce_dl_loss: 0.4799, step time: 0.4347\n",
      "batch: 17/17, train_dl_loss: 0.4128, train_bce_loss: 1.4671, train_bce_dl_loss: 0.4128, step time: 0.1126\n",
      "LOSS train DiceLoss: 0.4788, LOSS train BCE: 1.4604, LOSS train BCE-DiceLoss: 0.4788, LOSS val DiceLoss: 0.5609, LOSS val BCE: 1.4561, LOSS val BCE-DiceLoss: 0.5609, METRIC val: 0.4078\n",
      "time consuming of epoch 57 is: 433.0752\n",
      "----------\n",
      "EPOCH 58/80\n",
      "batch: 0/17, train_dl_loss: 0.4920, train_bce_loss: 1.4672, train_bce_dl_loss: 0.4920, step time: 0.4371\n",
      "batch: 1/17, train_dl_loss: 0.5082, train_bce_loss: 1.4679, train_bce_dl_loss: 0.5082, step time: 0.3830\n",
      "batch: 2/17, train_dl_loss: 0.5202, train_bce_loss: 1.4468, train_bce_dl_loss: 0.5202, step time: 0.4299\n",
      "batch: 3/17, train_dl_loss: 0.5913, train_bce_loss: 1.4642, train_bce_dl_loss: 0.5913, step time: 0.3777\n",
      "batch: 4/17, train_dl_loss: 0.4394, train_bce_loss: 1.4652, train_bce_dl_loss: 0.4394, step time: 0.4325\n",
      "batch: 5/17, train_dl_loss: 0.4414, train_bce_loss: 1.4570, train_bce_dl_loss: 0.4414, step time: 0.4216\n",
      "batch: 6/17, train_dl_loss: 0.5176, train_bce_loss: 1.4757, train_bce_dl_loss: 0.5176, step time: 0.4468\n",
      "batch: 7/17, train_dl_loss: 0.4529, train_bce_loss: 1.4510, train_bce_dl_loss: 0.4529, step time: 0.4426\n",
      "batch: 8/17, train_dl_loss: 0.4769, train_bce_loss: 1.4560, train_bce_dl_loss: 0.4769, step time: 0.4332\n",
      "batch: 9/17, train_dl_loss: 0.4604, train_bce_loss: 1.4656, train_bce_dl_loss: 0.4604, step time: 0.4228\n",
      "batch: 10/17, train_dl_loss: 0.5681, train_bce_loss: 1.4593, train_bce_dl_loss: 0.5681, step time: 0.4385\n",
      "batch: 11/17, train_dl_loss: 0.5524, train_bce_loss: 1.4520, train_bce_dl_loss: 0.5524, step time: 0.4414\n",
      "batch: 12/17, train_dl_loss: 0.4524, train_bce_loss: 1.4551, train_bce_dl_loss: 0.4524, step time: 0.4246\n",
      "batch: 13/17, train_dl_loss: 0.5783, train_bce_loss: 1.4838, train_bce_dl_loss: 0.5783, step time: 0.4196\n",
      "batch: 14/17, train_dl_loss: 0.5062, train_bce_loss: 1.4800, train_bce_dl_loss: 0.5062, step time: 0.4229\n",
      "batch: 15/17, train_dl_loss: 0.4456, train_bce_loss: 1.4578, train_bce_dl_loss: 0.4456, step time: 0.4447\n",
      "batch: 16/17, train_dl_loss: 0.4773, train_bce_loss: 1.4716, train_bce_dl_loss: 0.4773, step time: 0.4333\n",
      "batch: 17/17, train_dl_loss: 0.4138, train_bce_loss: 1.4581, train_bce_dl_loss: 0.4138, step time: 0.1137\n",
      "LOSS train DiceLoss: 0.4941, LOSS train BCE: 1.4630, LOSS train BCE-DiceLoss: 0.4941, LOSS val DiceLoss: 0.5586, LOSS val BCE: 1.4567, LOSS val BCE-DiceLoss: 0.5586, METRIC val: 0.4103\n",
      "time consuming of epoch 58 is: 449.1666\n",
      "----------\n",
      "EPOCH 59/80\n",
      "batch: 0/17, train_dl_loss: 0.4832, train_bce_loss: 1.4584, train_bce_dl_loss: 0.4832, step time: 0.4752\n",
      "batch: 1/17, train_dl_loss: 0.4818, train_bce_loss: 1.4562, train_bce_dl_loss: 0.4818, step time: 0.4218\n",
      "batch: 2/17, train_dl_loss: 0.4779, train_bce_loss: 1.4582, train_bce_dl_loss: 0.4779, step time: 0.4352\n",
      "batch: 3/17, train_dl_loss: 0.5572, train_bce_loss: 1.4605, train_bce_dl_loss: 0.5572, step time: 0.3789\n",
      "batch: 4/17, train_dl_loss: 0.4346, train_bce_loss: 1.4583, train_bce_dl_loss: 0.4346, step time: 0.4306\n",
      "batch: 5/17, train_dl_loss: 0.4863, train_bce_loss: 1.4707, train_bce_dl_loss: 0.4863, step time: 0.3802\n",
      "batch: 6/17, train_dl_loss: 0.5530, train_bce_loss: 1.4680, train_bce_dl_loss: 0.5530, step time: 0.4185\n",
      "batch: 7/17, train_dl_loss: 0.5074, train_bce_loss: 1.4730, train_bce_dl_loss: 0.5074, step time: 0.3877\n",
      "batch: 8/17, train_dl_loss: 0.4673, train_bce_loss: 1.4630, train_bce_dl_loss: 0.4673, step time: 0.4234\n",
      "batch: 9/17, train_dl_loss: 0.4426, train_bce_loss: 1.4724, train_bce_dl_loss: 0.4426, step time: 0.3771\n",
      "batch: 10/17, train_dl_loss: 0.5714, train_bce_loss: 1.4626, train_bce_dl_loss: 0.5714, step time: 0.4246\n",
      "batch: 11/17, train_dl_loss: 0.4894, train_bce_loss: 1.4606, train_bce_dl_loss: 0.4894, step time: 0.3816\n",
      "batch: 12/17, train_dl_loss: 0.4713, train_bce_loss: 1.4563, train_bce_dl_loss: 0.4713, step time: 0.4259\n",
      "batch: 13/17, train_dl_loss: 0.6429, train_bce_loss: 1.4682, train_bce_dl_loss: 0.6429, step time: 0.3794\n",
      "batch: 14/17, train_dl_loss: 0.4815, train_bce_loss: 1.4843, train_bce_dl_loss: 0.4815, step time: 0.4405\n",
      "batch: 15/17, train_dl_loss: 0.4567, train_bce_loss: 1.4711, train_bce_dl_loss: 0.4567, step time: 0.3841\n",
      "batch: 16/17, train_dl_loss: 0.5217, train_bce_loss: 1.4773, train_bce_dl_loss: 0.5217, step time: 0.4170\n",
      "batch: 17/17, train_dl_loss: 0.4143, train_bce_loss: 1.4721, train_bce_dl_loss: 0.4143, step time: 0.1137\n",
      "LOSS train DiceLoss: 0.4967, LOSS train BCE: 1.4662, LOSS train BCE-DiceLoss: 0.4967, LOSS val DiceLoss: 0.5626, LOSS val BCE: 1.4577, LOSS val BCE-DiceLoss: 0.5626, METRIC val: 0.4047\n",
      "time consuming of epoch 59 is: 463.9343\n",
      "----------\n",
      "EPOCH 60/80\n",
      "batch: 0/17, train_dl_loss: 0.4530, train_bce_loss: 1.4492, train_bce_dl_loss: 0.4530, step time: 0.4301\n",
      "batch: 1/17, train_dl_loss: 0.4688, train_bce_loss: 1.4762, train_bce_dl_loss: 0.4688, step time: 0.3832\n",
      "batch: 2/17, train_dl_loss: 0.5068, train_bce_loss: 1.4655, train_bce_dl_loss: 0.5068, step time: 0.4250\n",
      "batch: 3/17, train_dl_loss: 0.5263, train_bce_loss: 1.4612, train_bce_dl_loss: 0.5263, step time: 0.3828\n",
      "batch: 4/17, train_dl_loss: 0.4290, train_bce_loss: 1.4590, train_bce_dl_loss: 0.4290, step time: 0.4201\n",
      "batch: 5/17, train_dl_loss: 0.4711, train_bce_loss: 1.4733, train_bce_dl_loss: 0.4711, step time: 0.4314\n",
      "batch: 6/17, train_dl_loss: 0.5265, train_bce_loss: 1.4716, train_bce_dl_loss: 0.5265, step time: 0.4470\n",
      "batch: 7/17, train_dl_loss: 0.4502, train_bce_loss: 1.4558, train_bce_dl_loss: 0.4502, step time: 0.4254\n",
      "batch: 8/17, train_dl_loss: 0.4887, train_bce_loss: 1.4526, train_bce_dl_loss: 0.4887, step time: 0.4280\n",
      "batch: 9/17, train_dl_loss: 0.5404, train_bce_loss: 1.4828, train_bce_dl_loss: 0.5404, step time: 0.4282\n",
      "batch: 10/17, train_dl_loss: 0.5514, train_bce_loss: 1.4659, train_bce_dl_loss: 0.5514, step time: 0.4397\n",
      "batch: 11/17, train_dl_loss: 0.4651, train_bce_loss: 1.4382, train_bce_dl_loss: 0.4651, step time: 0.4395\n",
      "batch: 12/17, train_dl_loss: 0.4763, train_bce_loss: 1.4582, train_bce_dl_loss: 0.4763, step time: 0.4350\n",
      "batch: 13/17, train_dl_loss: 0.6596, train_bce_loss: 1.4820, train_bce_dl_loss: 0.6596, step time: 0.3822\n",
      "batch: 14/17, train_dl_loss: 0.5240, train_bce_loss: 1.4944, train_bce_dl_loss: 0.5240, step time: 0.4414\n",
      "batch: 15/17, train_dl_loss: 0.4723, train_bce_loss: 1.4806, train_bce_dl_loss: 0.4723, step time: 0.3803\n",
      "batch: 16/17, train_dl_loss: 0.4677, train_bce_loss: 1.4694, train_bce_dl_loss: 0.4677, step time: 0.4309\n",
      "batch: 17/17, train_dl_loss: 0.4631, train_bce_loss: 1.4625, train_bce_dl_loss: 0.4631, step time: 0.1120\n",
      "LOSS train DiceLoss: 0.4967, LOSS train BCE: 1.4666, LOSS train BCE-DiceLoss: 0.4967, LOSS val DiceLoss: 0.5588, LOSS val BCE: 1.4584, LOSS val BCE-DiceLoss: 0.5588, METRIC val: 0.4091\n",
      "time consuming of epoch 60 is: 443.5273\n",
      "----------\n",
      "EPOCH 61/80\n",
      "batch: 0/17, train_dl_loss: 0.4246, train_bce_loss: 1.4658, train_bce_dl_loss: 0.4246, step time: 0.4275\n",
      "batch: 1/17, train_dl_loss: 0.4665, train_bce_loss: 1.4568, train_bce_dl_loss: 0.4665, step time: 0.3779\n",
      "batch: 2/17, train_dl_loss: 0.4692, train_bce_loss: 1.4584, train_bce_dl_loss: 0.4692, step time: 0.4327\n",
      "batch: 3/17, train_dl_loss: 0.5424, train_bce_loss: 1.4655, train_bce_dl_loss: 0.5424, step time: 0.3816\n",
      "batch: 4/17, train_dl_loss: 0.5079, train_bce_loss: 1.4702, train_bce_dl_loss: 0.5079, step time: 0.4363\n",
      "batch: 5/17, train_dl_loss: 0.4546, train_bce_loss: 1.4627, train_bce_dl_loss: 0.4546, step time: 0.3792\n",
      "batch: 6/17, train_dl_loss: 0.4872, train_bce_loss: 1.4758, train_bce_dl_loss: 0.4872, step time: 0.4275\n",
      "batch: 7/17, train_dl_loss: 0.4823, train_bce_loss: 1.4595, train_bce_dl_loss: 0.4823, step time: 0.3833\n",
      "batch: 8/17, train_dl_loss: 0.4868, train_bce_loss: 1.4636, train_bce_dl_loss: 0.4868, step time: 0.4263\n",
      "batch: 9/17, train_dl_loss: 0.4635, train_bce_loss: 1.4729, train_bce_dl_loss: 0.4635, step time: 0.3775\n",
      "batch: 10/17, train_dl_loss: 0.5558, train_bce_loss: 1.4662, train_bce_dl_loss: 0.5558, step time: 0.4300\n",
      "batch: 11/17, train_dl_loss: 0.4892, train_bce_loss: 1.4680, train_bce_dl_loss: 0.4892, step time: 0.4388\n",
      "batch: 12/17, train_dl_loss: 0.4704, train_bce_loss: 1.4653, train_bce_dl_loss: 0.4704, step time: 0.4440\n",
      "batch: 13/17, train_dl_loss: 0.6599, train_bce_loss: 1.4752, train_bce_dl_loss: 0.6599, step time: 0.3841\n",
      "batch: 14/17, train_dl_loss: 0.5028, train_bce_loss: 1.4814, train_bce_dl_loss: 0.5028, step time: 0.4437\n",
      "batch: 15/17, train_dl_loss: 0.4798, train_bce_loss: 1.4669, train_bce_dl_loss: 0.4798, step time: 0.3888\n",
      "batch: 16/17, train_dl_loss: 0.4783, train_bce_loss: 1.4742, train_bce_dl_loss: 0.4783, step time: 0.4283\n",
      "batch: 17/17, train_dl_loss: 0.4494, train_bce_loss: 1.4640, train_bce_dl_loss: 0.4494, step time: 0.1121\n",
      "LOSS train DiceLoss: 0.4928, LOSS train BCE: 1.4674, LOSS train BCE-DiceLoss: 0.4928, LOSS val DiceLoss: 0.5577, LOSS val BCE: 1.4611, LOSS val BCE-DiceLoss: 0.5577, METRIC val: 0.4109\n",
      "time consuming of epoch 61 is: 441.0699\n",
      "----------\n",
      "EPOCH 62/80\n",
      "batch: 0/17, train_dl_loss: 0.4490, train_bce_loss: 1.4633, train_bce_dl_loss: 0.4490, step time: 0.4428\n",
      "batch: 1/17, train_dl_loss: 0.4658, train_bce_loss: 1.4707, train_bce_dl_loss: 0.4658, step time: 0.3830\n",
      "batch: 2/17, train_dl_loss: 0.4908, train_bce_loss: 1.4541, train_bce_dl_loss: 0.4908, step time: 0.4408\n",
      "batch: 3/17, train_dl_loss: 0.5270, train_bce_loss: 1.4707, train_bce_dl_loss: 0.5270, step time: 0.3844\n",
      "batch: 4/17, train_dl_loss: 0.4242, train_bce_loss: 1.4669, train_bce_dl_loss: 0.4242, step time: 0.4224\n",
      "batch: 5/17, train_dl_loss: 0.4675, train_bce_loss: 1.4545, train_bce_dl_loss: 0.4675, step time: 0.3832\n",
      "batch: 6/17, train_dl_loss: 0.5185, train_bce_loss: 1.4697, train_bce_dl_loss: 0.5185, step time: 0.4385\n",
      "batch: 7/17, train_dl_loss: 0.4610, train_bce_loss: 1.4526, train_bce_dl_loss: 0.4610, step time: 0.3802\n",
      "batch: 8/17, train_dl_loss: 0.4560, train_bce_loss: 1.4569, train_bce_dl_loss: 0.4560, step time: 0.4394\n",
      "batch: 9/17, train_dl_loss: 0.4550, train_bce_loss: 1.4666, train_bce_dl_loss: 0.4550, step time: 0.3813\n",
      "batch: 10/17, train_dl_loss: 0.5656, train_bce_loss: 1.4679, train_bce_dl_loss: 0.5656, step time: 0.4251\n",
      "batch: 11/17, train_dl_loss: 0.5762, train_bce_loss: 1.4748, train_bce_dl_loss: 0.5762, step time: 0.4441\n",
      "batch: 12/17, train_dl_loss: 0.4556, train_bce_loss: 1.4699, train_bce_dl_loss: 0.4556, step time: 0.4267\n",
      "batch: 13/17, train_dl_loss: 0.5802, train_bce_loss: 1.4788, train_bce_dl_loss: 0.5802, step time: 0.3788\n",
      "batch: 14/17, train_dl_loss: 0.4853, train_bce_loss: 1.4834, train_bce_dl_loss: 0.4853, step time: 0.4436\n",
      "batch: 15/17, train_dl_loss: 0.4447, train_bce_loss: 1.4769, train_bce_dl_loss: 0.4447, step time: 0.3963\n",
      "batch: 16/17, train_dl_loss: 0.4649, train_bce_loss: 1.4727, train_bce_dl_loss: 0.4649, step time: 0.4146\n",
      "batch: 17/17, train_dl_loss: 0.4024, train_bce_loss: 1.4719, train_bce_dl_loss: 0.4024, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.4828, LOSS train BCE: 1.4679, LOSS train BCE-DiceLoss: 0.4828, LOSS val DiceLoss: 0.5576, LOSS val BCE: 1.4614, LOSS val BCE-DiceLoss: 0.5576, METRIC val: 0.4114\n",
      "time consuming of epoch 62 is: 428.3719\n",
      "----------\n",
      "EPOCH 63/80\n",
      "batch: 0/17, train_dl_loss: 0.5357, train_bce_loss: 1.4698, train_bce_dl_loss: 0.5357, step time: 0.4394\n",
      "batch: 1/17, train_dl_loss: 0.4781, train_bce_loss: 1.4738, train_bce_dl_loss: 0.4781, step time: 0.3858\n",
      "batch: 2/17, train_dl_loss: 0.4612, train_bce_loss: 1.4748, train_bce_dl_loss: 0.4612, step time: 0.4404\n",
      "batch: 3/17, train_dl_loss: 0.5753, train_bce_loss: 1.4761, train_bce_dl_loss: 0.5753, step time: 0.3763\n",
      "batch: 4/17, train_dl_loss: 0.4705, train_bce_loss: 1.4553, train_bce_dl_loss: 0.4705, step time: 0.4313\n",
      "batch: 5/17, train_dl_loss: 0.4296, train_bce_loss: 1.4627, train_bce_dl_loss: 0.4296, step time: 0.3875\n",
      "batch: 6/17, train_dl_loss: 0.4897, train_bce_loss: 1.4768, train_bce_dl_loss: 0.4897, step time: 0.4396\n",
      "batch: 7/17, train_dl_loss: 0.4483, train_bce_loss: 1.4608, train_bce_dl_loss: 0.4483, step time: 0.3790\n",
      "batch: 8/17, train_dl_loss: 0.4428, train_bce_loss: 1.4519, train_bce_dl_loss: 0.4428, step time: 0.4384\n",
      "batch: 9/17, train_dl_loss: 0.4554, train_bce_loss: 1.4771, train_bce_dl_loss: 0.4554, step time: 0.3875\n",
      "batch: 10/17, train_dl_loss: 0.5450, train_bce_loss: 1.4555, train_bce_dl_loss: 0.5450, step time: 0.4310\n",
      "batch: 11/17, train_dl_loss: 0.4720, train_bce_loss: 1.4480, train_bce_dl_loss: 0.4720, step time: 0.3801\n",
      "batch: 12/17, train_dl_loss: 0.5025, train_bce_loss: 1.4755, train_bce_dl_loss: 0.5025, step time: 0.4342\n",
      "batch: 13/17, train_dl_loss: 0.5947, train_bce_loss: 1.4784, train_bce_dl_loss: 0.5947, step time: 0.3836\n",
      "batch: 14/17, train_dl_loss: 0.5308, train_bce_loss: 1.4932, train_bce_dl_loss: 0.5308, step time: 0.4692\n",
      "batch: 15/17, train_dl_loss: 0.4462, train_bce_loss: 1.4790, train_bce_dl_loss: 0.4462, step time: 0.3753\n",
      "batch: 16/17, train_dl_loss: 0.4370, train_bce_loss: 1.4778, train_bce_dl_loss: 0.4370, step time: 0.4316\n",
      "batch: 17/17, train_dl_loss: 0.4237, train_bce_loss: 1.4730, train_bce_dl_loss: 0.4237, step time: 0.1136\n",
      "LOSS train DiceLoss: 0.4855, LOSS train BCE: 1.4700, LOSS train BCE-DiceLoss: 0.4855, LOSS val DiceLoss: 0.5591, LOSS val BCE: 1.4624, LOSS val BCE-DiceLoss: 0.5591, METRIC val: 0.4091\n",
      "time consuming of epoch 63 is: 424.9065\n",
      "----------\n",
      "EPOCH 64/80\n",
      "batch: 0/17, train_dl_loss: 0.4841, train_bce_loss: 1.4626, train_bce_dl_loss: 0.4841, step time: 0.4236\n",
      "batch: 1/17, train_dl_loss: 0.4552, train_bce_loss: 1.4766, train_bce_dl_loss: 0.4552, step time: 0.3779\n",
      "batch: 2/17, train_dl_loss: 0.4805, train_bce_loss: 1.4803, train_bce_dl_loss: 0.4805, step time: 0.4307\n",
      "batch: 3/17, train_dl_loss: 0.5204, train_bce_loss: 1.4711, train_bce_dl_loss: 0.5204, step time: 0.3743\n",
      "batch: 4/17, train_dl_loss: 0.4621, train_bce_loss: 1.4533, train_bce_dl_loss: 0.4621, step time: 0.4271\n",
      "batch: 5/17, train_dl_loss: 0.4241, train_bce_loss: 1.4617, train_bce_dl_loss: 0.4241, step time: 0.3827\n",
      "batch: 6/17, train_dl_loss: 0.4947, train_bce_loss: 1.4752, train_bce_dl_loss: 0.4947, step time: 0.4455\n",
      "batch: 7/17, train_dl_loss: 0.4743, train_bce_loss: 1.4691, train_bce_dl_loss: 0.4743, step time: 0.3906\n",
      "batch: 8/17, train_dl_loss: 0.4610, train_bce_loss: 1.4745, train_bce_dl_loss: 0.4610, step time: 0.4301\n",
      "batch: 9/17, train_dl_loss: 0.5056, train_bce_loss: 1.4744, train_bce_dl_loss: 0.5056, step time: 0.3905\n",
      "batch: 10/17, train_dl_loss: 0.5454, train_bce_loss: 1.4676, train_bce_dl_loss: 0.5454, step time: 0.4409\n",
      "batch: 11/17, train_dl_loss: 0.4680, train_bce_loss: 1.4410, train_bce_dl_loss: 0.4680, step time: 0.4847\n",
      "batch: 12/17, train_dl_loss: 0.5098, train_bce_loss: 1.4610, train_bce_dl_loss: 0.5098, step time: 0.4297\n",
      "batch: 13/17, train_dl_loss: 0.6411, train_bce_loss: 1.4646, train_bce_dl_loss: 0.6411, step time: 0.3752\n",
      "batch: 14/17, train_dl_loss: 0.4787, train_bce_loss: 1.4690, train_bce_dl_loss: 0.4787, step time: 0.4219\n",
      "batch: 15/17, train_dl_loss: 0.5110, train_bce_loss: 1.4731, train_bce_dl_loss: 0.5110, step time: 0.3854\n",
      "batch: 16/17, train_dl_loss: 0.4651, train_bce_loss: 1.4746, train_bce_dl_loss: 0.4651, step time: 0.4252\n",
      "batch: 17/17, train_dl_loss: 0.3981, train_bce_loss: 1.4658, train_bce_dl_loss: 0.3981, step time: 0.1124\n",
      "LOSS train DiceLoss: 0.4877, LOSS train BCE: 1.4675, LOSS train BCE-DiceLoss: 0.4877, LOSS val DiceLoss: 0.5599, LOSS val BCE: 1.4628, LOSS val BCE-DiceLoss: 0.5599, METRIC val: 0.4081\n",
      "time consuming of epoch 64 is: 436.0091\n",
      "----------\n",
      "EPOCH 65/80\n",
      "batch: 0/17, train_dl_loss: 0.4663, train_bce_loss: 1.4579, train_bce_dl_loss: 0.4663, step time: 0.4439\n",
      "batch: 1/17, train_dl_loss: 0.4687, train_bce_loss: 1.4668, train_bce_dl_loss: 0.4687, step time: 0.3799\n",
      "batch: 2/17, train_dl_loss: 0.4860, train_bce_loss: 1.4537, train_bce_dl_loss: 0.4860, step time: 0.4377\n",
      "batch: 3/17, train_dl_loss: 0.5438, train_bce_loss: 1.4691, train_bce_dl_loss: 0.5438, step time: 0.3794\n",
      "batch: 4/17, train_dl_loss: 0.4200, train_bce_loss: 1.4575, train_bce_dl_loss: 0.4200, step time: 0.4294\n",
      "batch: 5/17, train_dl_loss: 0.4372, train_bce_loss: 1.4619, train_bce_dl_loss: 0.4372, step time: 0.3863\n",
      "batch: 6/17, train_dl_loss: 0.5544, train_bce_loss: 1.4769, train_bce_dl_loss: 0.5544, step time: 0.4234\n",
      "batch: 7/17, train_dl_loss: 0.4397, train_bce_loss: 1.4617, train_bce_dl_loss: 0.4397, step time: 0.4643\n",
      "batch: 8/17, train_dl_loss: 0.4546, train_bce_loss: 1.4501, train_bce_dl_loss: 0.4546, step time: 0.4324\n",
      "batch: 9/17, train_dl_loss: 0.4592, train_bce_loss: 1.4704, train_bce_dl_loss: 0.4592, step time: 0.4448\n",
      "batch: 10/17, train_dl_loss: 0.5746, train_bce_loss: 1.4780, train_bce_dl_loss: 0.5746, step time: 0.4411\n",
      "batch: 11/17, train_dl_loss: 0.4616, train_bce_loss: 1.4607, train_bce_dl_loss: 0.4616, step time: 0.4391\n",
      "batch: 12/17, train_dl_loss: 0.5242, train_bce_loss: 1.4688, train_bce_dl_loss: 0.5242, step time: 0.4386\n",
      "batch: 13/17, train_dl_loss: 0.6256, train_bce_loss: 1.4845, train_bce_dl_loss: 0.6256, step time: 0.4242\n",
      "batch: 14/17, train_dl_loss: 0.4911, train_bce_loss: 1.4884, train_bce_dl_loss: 0.4911, step time: 0.4352\n",
      "batch: 15/17, train_dl_loss: 0.4574, train_bce_loss: 1.4638, train_bce_dl_loss: 0.4574, step time: 0.3868\n",
      "batch: 16/17, train_dl_loss: 0.4529, train_bce_loss: 1.4735, train_bce_dl_loss: 0.4529, step time: 0.4304\n",
      "batch: 17/17, train_dl_loss: 0.4475, train_bce_loss: 1.4671, train_bce_dl_loss: 0.4475, step time: 0.1139\n",
      "LOSS train DiceLoss: 0.4869, LOSS train BCE: 1.4673, LOSS train BCE-DiceLoss: 0.4869, LOSS val DiceLoss: 0.5579, LOSS val BCE: 1.4637, LOSS val BCE-DiceLoss: 0.5579, METRIC val: 0.4106\n",
      "time consuming of epoch 65 is: 420.4936\n",
      "----------\n",
      "EPOCH 66/80\n",
      "batch: 0/17, train_dl_loss: 0.5134, train_bce_loss: 1.4600, train_bce_dl_loss: 0.5134, step time: 0.4365\n",
      "batch: 1/17, train_dl_loss: 0.4502, train_bce_loss: 1.4753, train_bce_dl_loss: 0.4502, step time: 0.3961\n",
      "batch: 2/17, train_dl_loss: 0.4983, train_bce_loss: 1.4781, train_bce_dl_loss: 0.4983, step time: 0.4404\n",
      "batch: 3/17, train_dl_loss: 0.5396, train_bce_loss: 1.4756, train_bce_dl_loss: 0.5396, step time: 0.3805\n",
      "batch: 4/17, train_dl_loss: 0.4373, train_bce_loss: 1.4648, train_bce_dl_loss: 0.4373, step time: 0.4448\n",
      "batch: 5/17, train_dl_loss: 0.4425, train_bce_loss: 1.4541, train_bce_dl_loss: 0.4425, step time: 0.3849\n",
      "batch: 6/17, train_dl_loss: 0.5244, train_bce_loss: 1.4734, train_bce_dl_loss: 0.5244, step time: 0.4187\n",
      "batch: 7/17, train_dl_loss: 0.4427, train_bce_loss: 1.4540, train_bce_dl_loss: 0.4427, step time: 0.3768\n",
      "batch: 8/17, train_dl_loss: 0.4553, train_bce_loss: 1.4662, train_bce_dl_loss: 0.4553, step time: 0.4368\n",
      "batch: 9/17, train_dl_loss: 0.4669, train_bce_loss: 1.4818, train_bce_dl_loss: 0.4669, step time: 0.3807\n",
      "batch: 10/17, train_dl_loss: 0.5480, train_bce_loss: 1.4593, train_bce_dl_loss: 0.5480, step time: 0.4414\n",
      "batch: 11/17, train_dl_loss: 0.5300, train_bce_loss: 1.4557, train_bce_dl_loss: 0.5300, step time: 0.4505\n",
      "batch: 12/17, train_dl_loss: 0.4684, train_bce_loss: 1.4695, train_bce_dl_loss: 0.4684, step time: 0.4254\n",
      "batch: 13/17, train_dl_loss: 0.6181, train_bce_loss: 1.4803, train_bce_dl_loss: 0.6181, step time: 0.3824\n",
      "batch: 14/17, train_dl_loss: 0.5038, train_bce_loss: 1.4755, train_bce_dl_loss: 0.5038, step time: 0.4259\n",
      "batch: 15/17, train_dl_loss: 0.4675, train_bce_loss: 1.4778, train_bce_dl_loss: 0.4675, step time: 0.3815\n",
      "batch: 16/17, train_dl_loss: 0.4319, train_bce_loss: 1.4794, train_bce_dl_loss: 0.4319, step time: 0.4354\n",
      "batch: 17/17, train_dl_loss: 0.4612, train_bce_loss: 1.4815, train_bce_dl_loss: 0.4612, step time: 0.1130\n",
      "LOSS train DiceLoss: 0.4889, LOSS train BCE: 1.4701, LOSS train BCE-DiceLoss: 0.4889, LOSS val DiceLoss: 0.5572, LOSS val BCE: 1.4644, LOSS val BCE-DiceLoss: 0.5572, METRIC val: 0.4110\n",
      "time consuming of epoch 66 is: 430.0394\n",
      "----------\n",
      "EPOCH 67/80\n",
      "batch: 0/17, train_dl_loss: 0.4360, train_bce_loss: 1.4506, train_bce_dl_loss: 0.4360, step time: 0.4413\n",
      "batch: 1/17, train_dl_loss: 0.4606, train_bce_loss: 1.4638, train_bce_dl_loss: 0.4606, step time: 0.3810\n",
      "batch: 2/17, train_dl_loss: 0.4812, train_bce_loss: 1.4756, train_bce_dl_loss: 0.4812, step time: 0.4167\n",
      "batch: 3/17, train_dl_loss: 0.5381, train_bce_loss: 1.4822, train_bce_dl_loss: 0.5381, step time: 0.3763\n",
      "batch: 4/17, train_dl_loss: 0.4447, train_bce_loss: 1.4628, train_bce_dl_loss: 0.4447, step time: 0.4403\n",
      "batch: 5/17, train_dl_loss: 0.4495, train_bce_loss: 1.4773, train_bce_dl_loss: 0.4495, step time: 0.4663\n",
      "batch: 6/17, train_dl_loss: 0.4882, train_bce_loss: 1.4861, train_bce_dl_loss: 0.4882, step time: 0.4506\n",
      "batch: 7/17, train_dl_loss: 0.4734, train_bce_loss: 1.4524, train_bce_dl_loss: 0.4734, step time: 0.4278\n",
      "batch: 8/17, train_dl_loss: 0.4553, train_bce_loss: 1.4654, train_bce_dl_loss: 0.4553, step time: 0.4428\n",
      "batch: 9/17, train_dl_loss: 0.4682, train_bce_loss: 1.4719, train_bce_dl_loss: 0.4682, step time: 0.4289\n",
      "batch: 10/17, train_dl_loss: 0.5505, train_bce_loss: 1.4563, train_bce_dl_loss: 0.5505, step time: 0.4184\n",
      "batch: 11/17, train_dl_loss: 0.4365, train_bce_loss: 1.4825, train_bce_dl_loss: 0.4365, step time: 0.4437\n",
      "batch: 12/17, train_dl_loss: 0.5299, train_bce_loss: 1.4828, train_bce_dl_loss: 0.5299, step time: 0.4334\n",
      "batch: 13/17, train_dl_loss: 0.5580, train_bce_loss: 1.4874, train_bce_dl_loss: 0.5580, step time: 0.4335\n",
      "batch: 14/17, train_dl_loss: 0.4927, train_bce_loss: 1.4827, train_bce_dl_loss: 0.4927, step time: 0.4295\n",
      "batch: 15/17, train_dl_loss: 0.4386, train_bce_loss: 1.4693, train_bce_dl_loss: 0.4386, step time: 0.4331\n",
      "batch: 16/17, train_dl_loss: 0.4670, train_bce_loss: 1.4719, train_bce_dl_loss: 0.4670, step time: 0.4306\n",
      "batch: 17/17, train_dl_loss: 0.3923, train_bce_loss: 1.4679, train_bce_dl_loss: 0.3923, step time: 0.1122\n",
      "LOSS train DiceLoss: 0.4756, LOSS train BCE: 1.4716, LOSS train BCE-DiceLoss: 0.4756, LOSS val DiceLoss: 0.5589, LOSS val BCE: 1.4653, LOSS val BCE-DiceLoss: 0.5589, METRIC val: 0.4092\n",
      "time consuming of epoch 67 is: 436.8716\n",
      "----------\n",
      "EPOCH 68/80\n",
      "batch: 0/17, train_dl_loss: 0.4470, train_bce_loss: 1.4660, train_bce_dl_loss: 0.4470, step time: 0.4475\n",
      "batch: 1/17, train_dl_loss: 0.4949, train_bce_loss: 1.4815, train_bce_dl_loss: 0.4949, step time: 0.3969\n",
      "batch: 2/17, train_dl_loss: 0.4893, train_bce_loss: 1.4681, train_bce_dl_loss: 0.4893, step time: 0.4420\n",
      "batch: 3/17, train_dl_loss: 0.6163, train_bce_loss: 1.4932, train_bce_dl_loss: 0.6163, step time: 0.3779\n",
      "batch: 4/17, train_dl_loss: 0.4200, train_bce_loss: 1.4614, train_bce_dl_loss: 0.4200, step time: 0.4212\n",
      "batch: 5/17, train_dl_loss: 0.5312, train_bce_loss: 1.4771, train_bce_dl_loss: 0.5312, step time: 0.3869\n",
      "batch: 6/17, train_dl_loss: 0.5007, train_bce_loss: 1.4757, train_bce_dl_loss: 0.5007, step time: 0.4346\n",
      "batch: 7/17, train_dl_loss: 0.4696, train_bce_loss: 1.4577, train_bce_dl_loss: 0.4696, step time: 0.3859\n",
      "batch: 8/17, train_dl_loss: 0.5251, train_bce_loss: 1.4515, train_bce_dl_loss: 0.5251, step time: 0.4194\n",
      "batch: 9/17, train_dl_loss: 0.4765, train_bce_loss: 1.4792, train_bce_dl_loss: 0.4765, step time: 0.3734\n",
      "batch: 10/17, train_dl_loss: 0.6202, train_bce_loss: 1.4615, train_bce_dl_loss: 0.6202, step time: 0.4497\n",
      "batch: 11/17, train_dl_loss: 0.4641, train_bce_loss: 1.4420, train_bce_dl_loss: 0.4641, step time: 0.3881\n",
      "batch: 12/17, train_dl_loss: 0.4576, train_bce_loss: 1.4670, train_bce_dl_loss: 0.4576, step time: 0.4227\n",
      "batch: 13/17, train_dl_loss: 0.5842, train_bce_loss: 1.4767, train_bce_dl_loss: 0.5842, step time: 0.3755\n",
      "batch: 14/17, train_dl_loss: 0.4622, train_bce_loss: 1.4803, train_bce_dl_loss: 0.4622, step time: 0.4351\n",
      "batch: 15/17, train_dl_loss: 0.4966, train_bce_loss: 1.4772, train_bce_dl_loss: 0.4966, step time: 0.3809\n",
      "batch: 16/17, train_dl_loss: 0.4706, train_bce_loss: 1.4849, train_bce_dl_loss: 0.4706, step time: 0.4137\n",
      "batch: 17/17, train_dl_loss: 0.4089, train_bce_loss: 1.4722, train_bce_dl_loss: 0.4089, step time: 0.1128\n",
      "LOSS train DiceLoss: 0.4964, LOSS train BCE: 1.4707, LOSS train BCE-DiceLoss: 0.4964, LOSS val DiceLoss: 0.5569, LOSS val BCE: 1.4658, LOSS val BCE-DiceLoss: 0.5569, METRIC val: 0.4115\n",
      "time consuming of epoch 68 is: 472.2798\n",
      "----------\n",
      "EPOCH 69/80\n",
      "batch: 0/17, train_dl_loss: 0.4717, train_bce_loss: 1.4620, train_bce_dl_loss: 0.4717, step time: 0.4261\n",
      "batch: 1/17, train_dl_loss: 0.4805, train_bce_loss: 1.4723, train_bce_dl_loss: 0.4805, step time: 0.3747\n",
      "batch: 2/17, train_dl_loss: 0.5008, train_bce_loss: 1.4745, train_bce_dl_loss: 0.5008, step time: 0.4255\n",
      "batch: 3/17, train_dl_loss: 0.5278, train_bce_loss: 1.4669, train_bce_dl_loss: 0.5278, step time: 0.3737\n",
      "batch: 4/17, train_dl_loss: 0.4413, train_bce_loss: 1.4665, train_bce_dl_loss: 0.4413, step time: 0.4231\n",
      "batch: 5/17, train_dl_loss: 0.4791, train_bce_loss: 1.4638, train_bce_dl_loss: 0.4791, step time: 0.4240\n",
      "batch: 6/17, train_dl_loss: 0.5008, train_bce_loss: 1.4774, train_bce_dl_loss: 0.5008, step time: 0.4412\n",
      "batch: 7/17, train_dl_loss: 0.4661, train_bce_loss: 1.4605, train_bce_dl_loss: 0.4661, step time: 0.4458\n",
      "batch: 8/17, train_dl_loss: 0.4514, train_bce_loss: 1.4737, train_bce_dl_loss: 0.4514, step time: 0.4516\n",
      "batch: 9/17, train_dl_loss: 0.4597, train_bce_loss: 1.4781, train_bce_dl_loss: 0.4597, step time: 0.4310\n",
      "batch: 10/17, train_dl_loss: 0.5442, train_bce_loss: 1.4704, train_bce_dl_loss: 0.5442, step time: 0.4372\n",
      "batch: 11/17, train_dl_loss: 0.5204, train_bce_loss: 1.4755, train_bce_dl_loss: 0.5204, step time: 0.4386\n",
      "batch: 12/17, train_dl_loss: 0.4879, train_bce_loss: 1.4674, train_bce_dl_loss: 0.4879, step time: 0.4172\n",
      "batch: 13/17, train_dl_loss: 0.6008, train_bce_loss: 1.4844, train_bce_dl_loss: 0.6008, step time: 0.3831\n",
      "batch: 14/17, train_dl_loss: 0.4749, train_bce_loss: 1.4772, train_bce_dl_loss: 0.4749, step time: 0.4399\n",
      "batch: 15/17, train_dl_loss: 0.4757, train_bce_loss: 1.4789, train_bce_dl_loss: 0.4757, step time: 0.3862\n",
      "batch: 16/17, train_dl_loss: 0.4669, train_bce_loss: 1.4732, train_bce_dl_loss: 0.4669, step time: 0.4350\n",
      "batch: 17/17, train_dl_loss: 0.3978, train_bce_loss: 1.4685, train_bce_dl_loss: 0.3978, step time: 0.1125\n",
      "LOSS train DiceLoss: 0.4860, LOSS train BCE: 1.4717, LOSS train BCE-DiceLoss: 0.4860, LOSS val DiceLoss: 0.5576, LOSS val BCE: 1.4661, LOSS val BCE-DiceLoss: 0.5576, METRIC val: 0.4106\n",
      "time consuming of epoch 69 is: 460.7607\n",
      "----------\n",
      "EPOCH 70/80\n",
      "batch: 0/17, train_dl_loss: 0.4437, train_bce_loss: 1.4732, train_bce_dl_loss: 0.4437, step time: 0.4309\n",
      "batch: 1/17, train_dl_loss: 0.5134, train_bce_loss: 1.4806, train_bce_dl_loss: 0.5134, step time: 0.3804\n",
      "batch: 2/17, train_dl_loss: 0.5011, train_bce_loss: 1.4812, train_bce_dl_loss: 0.5011, step time: 0.4171\n",
      "batch: 3/17, train_dl_loss: 0.5343, train_bce_loss: 1.4739, train_bce_dl_loss: 0.5343, step time: 0.3849\n",
      "batch: 4/17, train_dl_loss: 0.4415, train_bce_loss: 1.4622, train_bce_dl_loss: 0.4415, step time: 0.4283\n",
      "batch: 5/17, train_dl_loss: 0.4866, train_bce_loss: 1.4806, train_bce_dl_loss: 0.4866, step time: 0.3837\n",
      "batch: 6/17, train_dl_loss: 0.4849, train_bce_loss: 1.4757, train_bce_dl_loss: 0.4849, step time: 0.4186\n",
      "batch: 7/17, train_dl_loss: 0.4326, train_bce_loss: 1.4566, train_bce_dl_loss: 0.4326, step time: 0.3833\n",
      "batch: 8/17, train_dl_loss: 0.4581, train_bce_loss: 1.4504, train_bce_dl_loss: 0.4581, step time: 0.4291\n",
      "batch: 9/17, train_dl_loss: 0.4688, train_bce_loss: 1.4863, train_bce_dl_loss: 0.4688, step time: 0.4406\n",
      "batch: 10/17, train_dl_loss: 0.5370, train_bce_loss: 1.4795, train_bce_dl_loss: 0.5370, step time: 0.4629\n",
      "batch: 11/17, train_dl_loss: 0.4681, train_bce_loss: 1.4790, train_bce_dl_loss: 0.4681, step time: 0.4361\n",
      "batch: 12/17, train_dl_loss: 0.4306, train_bce_loss: 1.4609, train_bce_dl_loss: 0.4306, step time: 0.4317\n",
      "batch: 13/17, train_dl_loss: 0.5939, train_bce_loss: 1.4830, train_bce_dl_loss: 0.5939, step time: 0.3947\n",
      "batch: 14/17, train_dl_loss: 0.4772, train_bce_loss: 1.4819, train_bce_dl_loss: 0.4772, step time: 0.4233\n",
      "batch: 15/17, train_dl_loss: 0.4408, train_bce_loss: 1.4837, train_bce_dl_loss: 0.4408, step time: 0.3827\n",
      "batch: 16/17, train_dl_loss: 0.4572, train_bce_loss: 1.4725, train_bce_dl_loss: 0.4572, step time: 0.4201\n",
      "batch: 17/17, train_dl_loss: 0.3949, train_bce_loss: 1.4762, train_bce_dl_loss: 0.3949, step time: 0.1147\n",
      "LOSS train DiceLoss: 0.4758, LOSS train BCE: 1.4743, LOSS train BCE-DiceLoss: 0.4758, LOSS val DiceLoss: 0.5586, LOSS val BCE: 1.4661, LOSS val BCE-DiceLoss: 0.5586, METRIC val: 0.4093\n",
      "time consuming of epoch 70 is: 447.0173\n",
      "----------\n",
      "EPOCH 71/80\n",
      "batch: 0/17, train_dl_loss: 0.4662, train_bce_loss: 1.4595, train_bce_dl_loss: 0.4662, step time: 0.4400\n",
      "batch: 1/17, train_dl_loss: 0.4425, train_bce_loss: 1.4778, train_bce_dl_loss: 0.4425, step time: 0.3888\n",
      "batch: 2/17, train_dl_loss: 0.4503, train_bce_loss: 1.4678, train_bce_dl_loss: 0.4503, step time: 0.4361\n",
      "batch: 3/17, train_dl_loss: 0.5557, train_bce_loss: 1.4809, train_bce_dl_loss: 0.5557, step time: 0.3915\n",
      "batch: 4/17, train_dl_loss: 0.4480, train_bce_loss: 1.4739, train_bce_dl_loss: 0.4480, step time: 0.4493\n",
      "batch: 5/17, train_dl_loss: 0.4672, train_bce_loss: 1.4873, train_bce_dl_loss: 0.4672, step time: 0.4418\n",
      "batch: 6/17, train_dl_loss: 0.5646, train_bce_loss: 1.4912, train_bce_dl_loss: 0.5646, step time: 0.4493\n",
      "batch: 7/17, train_dl_loss: 0.4704, train_bce_loss: 1.4725, train_bce_dl_loss: 0.4704, step time: 0.4372\n",
      "batch: 8/17, train_dl_loss: 0.5015, train_bce_loss: 1.4577, train_bce_dl_loss: 0.5015, step time: 0.4323\n",
      "batch: 9/17, train_dl_loss: 0.5424, train_bce_loss: 1.4935, train_bce_dl_loss: 0.5424, step time: 0.4500\n",
      "batch: 10/17, train_dl_loss: 0.5519, train_bce_loss: 1.4604, train_bce_dl_loss: 0.5519, step time: 0.4361\n",
      "batch: 11/17, train_dl_loss: 0.4580, train_bce_loss: 1.4630, train_bce_dl_loss: 0.4580, step time: 0.4359\n",
      "batch: 12/17, train_dl_loss: 0.4485, train_bce_loss: 1.4604, train_bce_dl_loss: 0.4485, step time: 0.4462\n",
      "batch: 13/17, train_dl_loss: 0.6437, train_bce_loss: 1.4933, train_bce_dl_loss: 0.6437, step time: 0.4433\n",
      "batch: 14/17, train_dl_loss: 0.4687, train_bce_loss: 1.4783, train_bce_dl_loss: 0.4687, step time: 0.4395\n",
      "batch: 15/17, train_dl_loss: 0.5153, train_bce_loss: 1.4784, train_bce_dl_loss: 0.5153, step time: 0.4450\n",
      "batch: 16/17, train_dl_loss: 0.4473, train_bce_loss: 1.4839, train_bce_dl_loss: 0.4473, step time: 0.4217\n",
      "batch: 17/17, train_dl_loss: 0.3926, train_bce_loss: 1.4767, train_bce_dl_loss: 0.3926, step time: 0.1157\n",
      "LOSS train DiceLoss: 0.4908, LOSS train BCE: 1.4754, LOSS train BCE-DiceLoss: 0.4908, LOSS val DiceLoss: 0.5586, LOSS val BCE: 1.4670, LOSS val BCE-DiceLoss: 0.5586, METRIC val: 0.4094\n",
      "time consuming of epoch 71 is: 474.4248\n",
      "----------\n",
      "EPOCH 72/80\n",
      "batch: 0/17, train_dl_loss: 0.4427, train_bce_loss: 1.4785, train_bce_dl_loss: 0.4427, step time: 0.4313\n",
      "batch: 1/17, train_dl_loss: 0.4565, train_bce_loss: 1.4748, train_bce_dl_loss: 0.4565, step time: 0.3954\n",
      "batch: 2/17, train_dl_loss: 0.4860, train_bce_loss: 1.4802, train_bce_dl_loss: 0.4860, step time: 0.4271\n",
      "batch: 3/17, train_dl_loss: 0.5043, train_bce_loss: 1.4752, train_bce_dl_loss: 0.5043, step time: 0.3785\n",
      "batch: 4/17, train_dl_loss: 0.4280, train_bce_loss: 1.4735, train_bce_dl_loss: 0.4280, step time: 0.4517\n",
      "batch: 5/17, train_dl_loss: 0.4559, train_bce_loss: 1.4566, train_bce_dl_loss: 0.4559, step time: 0.3811\n",
      "batch: 6/17, train_dl_loss: 0.5079, train_bce_loss: 1.4837, train_bce_dl_loss: 0.5079, step time: 0.4298\n",
      "batch: 7/17, train_dl_loss: 0.4739, train_bce_loss: 1.4710, train_bce_dl_loss: 0.4739, step time: 0.3950\n",
      "batch: 8/17, train_dl_loss: 0.4542, train_bce_loss: 1.4600, train_bce_dl_loss: 0.4542, step time: 0.4516\n",
      "batch: 9/17, train_dl_loss: 0.4448, train_bce_loss: 1.4831, train_bce_dl_loss: 0.4448, step time: 0.3827\n",
      "batch: 10/17, train_dl_loss: 0.5255, train_bce_loss: 1.4678, train_bce_dl_loss: 0.5255, step time: 0.4382\n",
      "batch: 11/17, train_dl_loss: 0.5187, train_bce_loss: 1.4697, train_bce_dl_loss: 0.5187, step time: 0.4512\n",
      "batch: 12/17, train_dl_loss: 0.5688, train_bce_loss: 1.4707, train_bce_dl_loss: 0.5688, step time: 0.4277\n",
      "batch: 13/17, train_dl_loss: 0.5903, train_bce_loss: 1.4726, train_bce_dl_loss: 0.5903, step time: 0.3906\n",
      "batch: 14/17, train_dl_loss: 0.5123, train_bce_loss: 1.4871, train_bce_dl_loss: 0.5123, step time: 0.4324\n",
      "batch: 15/17, train_dl_loss: 0.4842, train_bce_loss: 1.4762, train_bce_dl_loss: 0.4842, step time: 0.3894\n",
      "batch: 16/17, train_dl_loss: 0.4609, train_bce_loss: 1.4765, train_bce_dl_loss: 0.4609, step time: 0.4211\n",
      "batch: 17/17, train_dl_loss: 0.4523, train_bce_loss: 1.4730, train_bce_dl_loss: 0.4523, step time: 0.1180\n",
      "LOSS train DiceLoss: 0.4871, LOSS train BCE: 1.4739, LOSS train BCE-DiceLoss: 0.4871, LOSS val DiceLoss: 0.5582, LOSS val BCE: 1.4676, LOSS val BCE-DiceLoss: 0.5582, METRIC val: 0.4099\n",
      "time consuming of epoch 72 is: 473.0293\n",
      "----------\n",
      "EPOCH 73/80\n",
      "batch: 0/17, train_dl_loss: 0.4681, train_bce_loss: 1.4618, train_bce_dl_loss: 0.4681, step time: 0.4477\n",
      "batch: 1/17, train_dl_loss: 0.4486, train_bce_loss: 1.4770, train_bce_dl_loss: 0.4486, step time: 0.3983\n",
      "batch: 2/17, train_dl_loss: 0.4877, train_bce_loss: 1.4669, train_bce_dl_loss: 0.4877, step time: 0.4285\n",
      "batch: 3/17, train_dl_loss: 0.5042, train_bce_loss: 1.4790, train_bce_dl_loss: 0.5042, step time: 0.3925\n",
      "batch: 4/17, train_dl_loss: 0.4199, train_bce_loss: 1.4761, train_bce_dl_loss: 0.4199, step time: 0.5177\n",
      "batch: 5/17, train_dl_loss: 0.4734, train_bce_loss: 1.4709, train_bce_dl_loss: 0.4734, step time: 0.4458\n",
      "batch: 6/17, train_dl_loss: 0.4869, train_bce_loss: 1.4793, train_bce_dl_loss: 0.4869, step time: 0.4381\n",
      "batch: 7/17, train_dl_loss: 0.4406, train_bce_loss: 1.4600, train_bce_dl_loss: 0.4406, step time: 0.4398\n",
      "batch: 8/17, train_dl_loss: 0.4527, train_bce_loss: 1.4797, train_bce_dl_loss: 0.4527, step time: 0.4512\n",
      "batch: 9/17, train_dl_loss: 0.5086, train_bce_loss: 1.4903, train_bce_dl_loss: 0.5086, step time: 0.4254\n",
      "batch: 10/17, train_dl_loss: 0.5443, train_bce_loss: 1.4751, train_bce_dl_loss: 0.5443, step time: 0.4420\n",
      "batch: 11/17, train_dl_loss: 0.4680, train_bce_loss: 1.4762, train_bce_dl_loss: 0.4680, step time: 0.4534\n",
      "batch: 12/17, train_dl_loss: 0.4709, train_bce_loss: 1.4603, train_bce_dl_loss: 0.4709, step time: 0.4301\n",
      "batch: 13/17, train_dl_loss: 0.5994, train_bce_loss: 1.4854, train_bce_dl_loss: 0.5994, step time: 0.4469\n",
      "batch: 14/17, train_dl_loss: 0.4708, train_bce_loss: 1.4806, train_bce_dl_loss: 0.4708, step time: 0.4273\n",
      "batch: 15/17, train_dl_loss: 0.4635, train_bce_loss: 1.4809, train_bce_dl_loss: 0.4635, step time: 0.4465\n",
      "batch: 16/17, train_dl_loss: 0.4458, train_bce_loss: 1.4824, train_bce_dl_loss: 0.4458, step time: 0.4177\n",
      "batch: 17/17, train_dl_loss: 0.4515, train_bce_loss: 1.4729, train_bce_dl_loss: 0.4515, step time: 0.1173\n",
      "LOSS train DiceLoss: 0.4780, LOSS train BCE: 1.4753, LOSS train BCE-DiceLoss: 0.4780, LOSS val DiceLoss: 0.5577, LOSS val BCE: 1.4674, LOSS val BCE-DiceLoss: 0.5577, METRIC val: 0.4107\n",
      "time consuming of epoch 73 is: 464.6740\n",
      "----------\n",
      "EPOCH 74/80\n",
      "batch: 0/17, train_dl_loss: 0.5258, train_bce_loss: 1.4701, train_bce_dl_loss: 0.5258, step time: 0.4383\n",
      "batch: 1/17, train_dl_loss: 0.4431, train_bce_loss: 1.4728, train_bce_dl_loss: 0.4431, step time: 0.3895\n",
      "batch: 2/17, train_dl_loss: 0.5327, train_bce_loss: 1.4746, train_bce_dl_loss: 0.5327, step time: 0.4443\n",
      "batch: 3/17, train_dl_loss: 0.5440, train_bce_loss: 1.4831, train_bce_dl_loss: 0.5440, step time: 0.4326\n",
      "batch: 4/17, train_dl_loss: 0.4724, train_bce_loss: 1.4756, train_bce_dl_loss: 0.4724, step time: 0.4460\n",
      "batch: 5/17, train_dl_loss: 0.5242, train_bce_loss: 1.4901, train_bce_dl_loss: 0.5242, step time: 0.4323\n",
      "batch: 6/17, train_dl_loss: 0.5478, train_bce_loss: 1.4890, train_bce_dl_loss: 0.5478, step time: 0.4340\n",
      "batch: 7/17, train_dl_loss: 0.4496, train_bce_loss: 1.4553, train_bce_dl_loss: 0.4496, step time: 0.4459\n",
      "batch: 8/17, train_dl_loss: 0.4636, train_bce_loss: 1.4807, train_bce_dl_loss: 0.4636, step time: 0.4524\n",
      "batch: 9/17, train_dl_loss: 0.4723, train_bce_loss: 1.4876, train_bce_dl_loss: 0.4723, step time: 0.4371\n",
      "batch: 10/17, train_dl_loss: 0.5958, train_bce_loss: 1.4732, train_bce_dl_loss: 0.5958, step time: 0.4297\n",
      "batch: 11/17, train_dl_loss: 0.4566, train_bce_loss: 1.4462, train_bce_dl_loss: 0.4566, step time: 0.4465\n",
      "batch: 12/17, train_dl_loss: 0.4373, train_bce_loss: 1.4602, train_bce_dl_loss: 0.4373, step time: 0.4266\n",
      "batch: 13/17, train_dl_loss: 0.5898, train_bce_loss: 1.4773, train_bce_dl_loss: 0.5898, step time: 0.3906\n",
      "batch: 14/17, train_dl_loss: 0.5216, train_bce_loss: 1.5004, train_bce_dl_loss: 0.5216, step time: 0.4521\n",
      "batch: 15/17, train_dl_loss: 0.4877, train_bce_loss: 1.4851, train_bce_dl_loss: 0.4877, step time: 0.3976\n",
      "batch: 16/17, train_dl_loss: 0.5162, train_bce_loss: 1.4876, train_bce_dl_loss: 0.5162, step time: 0.4193\n",
      "batch: 17/17, train_dl_loss: 0.4459, train_bce_loss: 1.4706, train_bce_dl_loss: 0.4459, step time: 0.1167\n",
      "LOSS train DiceLoss: 0.5015, LOSS train BCE: 1.4767, LOSS train BCE-DiceLoss: 0.5015, LOSS val DiceLoss: 0.5574, LOSS val BCE: 1.4673, LOSS val BCE-DiceLoss: 0.5574, METRIC val: 0.4109\n",
      "time consuming of epoch 74 is: 485.7605\n",
      "----------\n",
      "EPOCH 75/80\n",
      "batch: 0/17, train_dl_loss: 0.4366, train_bce_loss: 1.4613, train_bce_dl_loss: 0.4366, step time: 0.4494\n",
      "batch: 1/17, train_dl_loss: 0.4608, train_bce_loss: 1.4793, train_bce_dl_loss: 0.4608, step time: 0.3857\n",
      "batch: 2/17, train_dl_loss: 0.4971, train_bce_loss: 1.4762, train_bce_dl_loss: 0.4971, step time: 0.4486\n",
      "batch: 3/17, train_dl_loss: 0.5444, train_bce_loss: 1.4672, train_bce_dl_loss: 0.5444, step time: 0.3901\n",
      "batch: 4/17, train_dl_loss: 0.4894, train_bce_loss: 1.4580, train_bce_dl_loss: 0.4894, step time: 0.4395\n",
      "batch: 5/17, train_dl_loss: 0.4811, train_bce_loss: 1.4668, train_bce_dl_loss: 0.4811, step time: 0.4448\n",
      "batch: 6/17, train_dl_loss: 0.4868, train_bce_loss: 1.4767, train_bce_dl_loss: 0.4868, step time: 0.4345\n",
      "batch: 7/17, train_dl_loss: 0.4372, train_bce_loss: 1.4596, train_bce_dl_loss: 0.4372, step time: 0.4454\n",
      "batch: 8/17, train_dl_loss: 0.4768, train_bce_loss: 1.4724, train_bce_dl_loss: 0.4768, step time: 0.4382\n",
      "batch: 9/17, train_dl_loss: 0.4725, train_bce_loss: 1.4814, train_bce_dl_loss: 0.4725, step time: 0.4470\n",
      "batch: 10/17, train_dl_loss: 0.5630, train_bce_loss: 1.4686, train_bce_dl_loss: 0.5630, step time: 0.4356\n",
      "batch: 11/17, train_dl_loss: 0.4436, train_bce_loss: 1.4550, train_bce_dl_loss: 0.4436, step time: 0.4274\n",
      "batch: 12/17, train_dl_loss: 0.5039, train_bce_loss: 1.4664, train_bce_dl_loss: 0.5039, step time: 0.4417\n",
      "batch: 13/17, train_dl_loss: 0.5873, train_bce_loss: 1.4903, train_bce_dl_loss: 0.5873, step time: 0.4279\n",
      "batch: 14/17, train_dl_loss: 0.4611, train_bce_loss: 1.4833, train_bce_dl_loss: 0.4611, step time: 0.4418\n",
      "batch: 15/17, train_dl_loss: 0.4407, train_bce_loss: 1.4784, train_bce_dl_loss: 0.4407, step time: 0.4321\n",
      "batch: 16/17, train_dl_loss: 0.4697, train_bce_loss: 1.4855, train_bce_dl_loss: 0.4697, step time: 0.4181\n",
      "batch: 17/17, train_dl_loss: 0.6378, train_bce_loss: 1.4939, train_bce_dl_loss: 0.6378, step time: 0.1137\n",
      "LOSS train DiceLoss: 0.4939, LOSS train BCE: 1.4734, LOSS train BCE-DiceLoss: 0.4939, LOSS val DiceLoss: 0.5579, LOSS val BCE: 1.4677, LOSS val BCE-DiceLoss: 0.5579, METRIC val: 0.4105\n",
      "time consuming of epoch 75 is: 471.1096\n",
      "----------\n",
      "EPOCH 76/80\n",
      "batch: 0/17, train_dl_loss: 0.4420, train_bce_loss: 1.4575, train_bce_dl_loss: 0.4420, step time: 0.4513\n",
      "batch: 1/17, train_dl_loss: 0.4685, train_bce_loss: 1.4840, train_bce_dl_loss: 0.4685, step time: 0.3977\n",
      "batch: 2/17, train_dl_loss: 0.5130, train_bce_loss: 1.4753, train_bce_dl_loss: 0.5130, step time: 0.4254\n",
      "batch: 3/17, train_dl_loss: 0.5611, train_bce_loss: 1.4660, train_bce_dl_loss: 0.5611, step time: 0.3838\n",
      "batch: 4/17, train_dl_loss: 0.4947, train_bce_loss: 1.4739, train_bce_dl_loss: 0.4947, step time: 0.4328\n",
      "batch: 5/17, train_dl_loss: 0.4628, train_bce_loss: 1.4800, train_bce_dl_loss: 0.4628, step time: 0.3990\n",
      "batch: 6/17, train_dl_loss: 0.5050, train_bce_loss: 1.4779, train_bce_dl_loss: 0.5050, step time: 0.4484\n",
      "batch: 7/17, train_dl_loss: 0.4275, train_bce_loss: 1.4605, train_bce_dl_loss: 0.4275, step time: 0.3956\n",
      "batch: 8/17, train_dl_loss: 0.4395, train_bce_loss: 1.4591, train_bce_dl_loss: 0.4395, step time: 0.4425\n",
      "batch: 9/17, train_dl_loss: 0.4795, train_bce_loss: 1.4745, train_bce_dl_loss: 0.4795, step time: 0.3852\n",
      "batch: 10/17, train_dl_loss: 0.5532, train_bce_loss: 1.4683, train_bce_dl_loss: 0.5532, step time: 0.4382\n",
      "batch: 11/17, train_dl_loss: 0.4834, train_bce_loss: 1.4795, train_bce_dl_loss: 0.4834, step time: 0.3908\n",
      "batch: 12/17, train_dl_loss: 0.5245, train_bce_loss: 1.4675, train_bce_dl_loss: 0.5245, step time: 0.4717\n",
      "batch: 13/17, train_dl_loss: 0.6284, train_bce_loss: 1.4835, train_bce_dl_loss: 0.6284, step time: 0.3849\n",
      "batch: 14/17, train_dl_loss: 0.4593, train_bce_loss: 1.4842, train_bce_dl_loss: 0.4593, step time: 0.4293\n",
      "batch: 15/17, train_dl_loss: 0.4660, train_bce_loss: 1.4818, train_bce_dl_loss: 0.4660, step time: 0.3895\n",
      "batch: 16/17, train_dl_loss: 0.4557, train_bce_loss: 1.4693, train_bce_dl_loss: 0.4557, step time: 0.4339\n",
      "batch: 17/17, train_dl_loss: 0.3885, train_bce_loss: 1.4816, train_bce_dl_loss: 0.3885, step time: 0.1168\n",
      "LOSS train DiceLoss: 0.4863, LOSS train BCE: 1.4736, LOSS train BCE-DiceLoss: 0.4863, LOSS val DiceLoss: 0.5578, LOSS val BCE: 1.4678, LOSS val BCE-DiceLoss: 0.5578, METRIC val: 0.4105\n",
      "time consuming of epoch 76 is: 498.5540\n",
      "----------\n",
      "EPOCH 77/80\n",
      "batch: 0/17, train_dl_loss: 0.4896, train_bce_loss: 1.4598, train_bce_dl_loss: 0.4896, step time: 0.4327\n",
      "batch: 1/17, train_dl_loss: 0.4813, train_bce_loss: 1.4930, train_bce_dl_loss: 0.4813, step time: 0.4346\n",
      "batch: 2/17, train_dl_loss: 0.5162, train_bce_loss: 1.4675, train_bce_dl_loss: 0.5162, step time: 0.4227\n",
      "batch: 3/17, train_dl_loss: 0.5496, train_bce_loss: 1.4736, train_bce_dl_loss: 0.5496, step time: 0.4411\n",
      "batch: 4/17, train_dl_loss: 0.4352, train_bce_loss: 1.4595, train_bce_dl_loss: 0.4352, step time: 0.4319\n",
      "batch: 5/17, train_dl_loss: 0.4950, train_bce_loss: 1.4630, train_bce_dl_loss: 0.4950, step time: 0.4436\n",
      "batch: 6/17, train_dl_loss: 0.5140, train_bce_loss: 1.4859, train_bce_dl_loss: 0.5140, step time: 0.4276\n",
      "batch: 7/17, train_dl_loss: 0.4217, train_bce_loss: 1.4669, train_bce_dl_loss: 0.4217, step time: 0.4487\n",
      "batch: 8/17, train_dl_loss: 0.4581, train_bce_loss: 1.4505, train_bce_dl_loss: 0.4581, step time: 0.4297\n",
      "batch: 9/17, train_dl_loss: 0.5499, train_bce_loss: 1.4831, train_bce_dl_loss: 0.5499, step time: 0.4347\n",
      "batch: 10/17, train_dl_loss: 0.5382, train_bce_loss: 1.4784, train_bce_dl_loss: 0.5382, step time: 0.4403\n",
      "batch: 11/17, train_dl_loss: 0.4516, train_bce_loss: 1.4661, train_bce_dl_loss: 0.4516, step time: 0.4325\n",
      "batch: 12/17, train_dl_loss: 0.4800, train_bce_loss: 1.4693, train_bce_dl_loss: 0.4800, step time: 0.4463\n",
      "batch: 13/17, train_dl_loss: 0.6041, train_bce_loss: 1.4823, train_bce_dl_loss: 0.6041, step time: 0.4387\n",
      "batch: 14/17, train_dl_loss: 0.4989, train_bce_loss: 1.4848, train_bce_dl_loss: 0.4989, step time: 0.4901\n",
      "batch: 15/17, train_dl_loss: 0.4500, train_bce_loss: 1.4782, train_bce_dl_loss: 0.4500, step time: 0.4389\n",
      "batch: 16/17, train_dl_loss: 0.4497, train_bce_loss: 1.4736, train_bce_dl_loss: 0.4497, step time: 0.4385\n",
      "batch: 17/17, train_dl_loss: 0.4455, train_bce_loss: 1.4711, train_bce_dl_loss: 0.4455, step time: 0.1138\n",
      "LOSS train DiceLoss: 0.4905, LOSS train BCE: 1.4726, LOSS train BCE-DiceLoss: 0.4905, LOSS val DiceLoss: 0.5579, LOSS val BCE: 1.4679, LOSS val BCE-DiceLoss: 0.5579, METRIC val: 0.4104\n",
      "time consuming of epoch 77 is: 491.1984\n",
      "----------\n",
      "EPOCH 78/80\n",
      "batch: 0/17, train_dl_loss: 0.4349, train_bce_loss: 1.4573, train_bce_dl_loss: 0.4349, step time: 0.4495\n",
      "batch: 1/17, train_dl_loss: 0.4451, train_bce_loss: 1.4765, train_bce_dl_loss: 0.4451, step time: 0.3868\n",
      "batch: 2/17, train_dl_loss: 0.5611, train_bce_loss: 1.4789, train_bce_dl_loss: 0.5611, step time: 0.4199\n",
      "batch: 3/17, train_dl_loss: 0.5036, train_bce_loss: 1.4825, train_bce_dl_loss: 0.5036, step time: 0.3816\n",
      "batch: 4/17, train_dl_loss: 0.4430, train_bce_loss: 1.4796, train_bce_dl_loss: 0.4430, step time: 0.4557\n",
      "batch: 5/17, train_dl_loss: 0.4655, train_bce_loss: 1.4668, train_bce_dl_loss: 0.4655, step time: 0.3923\n",
      "batch: 6/17, train_dl_loss: 0.4952, train_bce_loss: 1.4853, train_bce_dl_loss: 0.4952, step time: 0.4388\n",
      "batch: 7/17, train_dl_loss: 0.4739, train_bce_loss: 1.4572, train_bce_dl_loss: 0.4739, step time: 0.4214\n",
      "batch: 8/17, train_dl_loss: 0.4996, train_bce_loss: 1.4778, train_bce_dl_loss: 0.4996, step time: 0.4471\n",
      "batch: 9/17, train_dl_loss: 0.4947, train_bce_loss: 1.4768, train_bce_dl_loss: 0.4947, step time: 0.3964\n",
      "batch: 10/17, train_dl_loss: 0.5700, train_bce_loss: 1.4793, train_bce_dl_loss: 0.5700, step time: 0.4487\n",
      "batch: 11/17, train_dl_loss: 0.4194, train_bce_loss: 1.4601, train_bce_dl_loss: 0.4194, step time: 0.3871\n",
      "batch: 12/17, train_dl_loss: 0.4547, train_bce_loss: 1.4643, train_bce_dl_loss: 0.4547, step time: 0.4316\n",
      "batch: 13/17, train_dl_loss: 0.6049, train_bce_loss: 1.4912, train_bce_dl_loss: 0.6049, step time: 0.3935\n",
      "batch: 14/17, train_dl_loss: 0.4475, train_bce_loss: 1.4795, train_bce_dl_loss: 0.4475, step time: 0.4277\n",
      "batch: 15/17, train_dl_loss: 0.4589, train_bce_loss: 1.4827, train_bce_dl_loss: 0.4589, step time: 0.3800\n",
      "batch: 16/17, train_dl_loss: 0.4465, train_bce_loss: 1.4769, train_bce_dl_loss: 0.4465, step time: 0.4152\n",
      "batch: 17/17, train_dl_loss: 0.4254, train_bce_loss: 1.4848, train_bce_dl_loss: 0.4254, step time: 0.1151\n",
      "LOSS train DiceLoss: 0.4802, LOSS train BCE: 1.4754, LOSS train BCE-DiceLoss: 0.4802, LOSS val DiceLoss: 0.5580, LOSS val BCE: 1.4679, LOSS val BCE-DiceLoss: 0.5580, METRIC val: 0.4103\n",
      "time consuming of epoch 78 is: 460.2455\n",
      "----------\n",
      "EPOCH 79/80\n",
      "batch: 0/17, train_dl_loss: 0.4343, train_bce_loss: 1.4668, train_bce_dl_loss: 0.4343, step time: 0.4449\n",
      "batch: 1/17, train_dl_loss: 0.4898, train_bce_loss: 1.4826, train_bce_dl_loss: 0.4898, step time: 0.3851\n",
      "batch: 2/17, train_dl_loss: 0.5107, train_bce_loss: 1.4790, train_bce_dl_loss: 0.5107, step time: 0.4342\n",
      "batch: 3/17, train_dl_loss: 0.5562, train_bce_loss: 1.4754, train_bce_dl_loss: 0.5562, step time: 0.3760\n",
      "batch: 4/17, train_dl_loss: 0.4329, train_bce_loss: 1.4701, train_bce_dl_loss: 0.4329, step time: 0.4596\n",
      "batch: 5/17, train_dl_loss: 0.4375, train_bce_loss: 1.4647, train_bce_dl_loss: 0.4375, step time: 0.3898\n",
      "batch: 6/17, train_dl_loss: 0.5122, train_bce_loss: 1.4753, train_bce_dl_loss: 0.5122, step time: 0.4306\n",
      "batch: 7/17, train_dl_loss: 0.4709, train_bce_loss: 1.4792, train_bce_dl_loss: 0.4709, step time: 0.3855\n",
      "batch: 8/17, train_dl_loss: 0.4290, train_bce_loss: 1.4776, train_bce_dl_loss: 0.4290, step time: 0.4324\n",
      "batch: 9/17, train_dl_loss: 0.4887, train_bce_loss: 1.4855, train_bce_dl_loss: 0.4887, step time: 0.3794\n",
      "batch: 10/17, train_dl_loss: 0.5271, train_bce_loss: 1.4682, train_bce_dl_loss: 0.5271, step time: 0.4297\n",
      "batch: 11/17, train_dl_loss: 0.5380, train_bce_loss: 1.4883, train_bce_dl_loss: 0.5380, step time: 0.4368\n",
      "batch: 12/17, train_dl_loss: 0.5002, train_bce_loss: 1.4674, train_bce_dl_loss: 0.5002, step time: 0.4302\n",
      "batch: 13/17, train_dl_loss: 0.5730, train_bce_loss: 1.4838, train_bce_dl_loss: 0.5730, step time: 0.3919\n",
      "batch: 14/17, train_dl_loss: 0.4887, train_bce_loss: 1.4960, train_bce_dl_loss: 0.4887, step time: 0.4389\n",
      "batch: 15/17, train_dl_loss: 0.4487, train_bce_loss: 1.4735, train_bce_dl_loss: 0.4487, step time: 0.4115\n",
      "batch: 16/17, train_dl_loss: 0.4557, train_bce_loss: 1.4852, train_bce_dl_loss: 0.4557, step time: 0.4352\n",
      "batch: 17/17, train_dl_loss: 0.4507, train_bce_loss: 1.4734, train_bce_dl_loss: 0.4507, step time: 0.1164\n",
      "LOSS train DiceLoss: 0.4858, LOSS train BCE: 1.4773, LOSS train BCE-DiceLoss: 0.4858, LOSS val DiceLoss: 0.5579, LOSS val BCE: 1.4679, LOSS val BCE-DiceLoss: 0.5579, METRIC val: 0.4104\n",
      "time consuming of epoch 79 is: 446.4203\n",
      "----------\n",
      "EPOCH 80/80\n",
      "batch: 0/17, train_dl_loss: 0.4716, train_bce_loss: 1.4719, train_bce_dl_loss: 0.4716, step time: 0.4388\n",
      "batch: 1/17, train_dl_loss: 0.5280, train_bce_loss: 1.4920, train_bce_dl_loss: 0.5280, step time: 0.3892\n",
      "batch: 2/17, train_dl_loss: 0.4737, train_bce_loss: 1.4697, train_bce_dl_loss: 0.4737, step time: 0.4239\n",
      "batch: 3/17, train_dl_loss: 0.5932, train_bce_loss: 1.4827, train_bce_dl_loss: 0.5932, step time: 0.3846\n",
      "batch: 4/17, train_dl_loss: 0.4295, train_bce_loss: 1.4675, train_bce_dl_loss: 0.4295, step time: 0.4387\n",
      "batch: 5/17, train_dl_loss: 0.4394, train_bce_loss: 1.4815, train_bce_dl_loss: 0.4394, step time: 0.4081\n",
      "batch: 6/17, train_dl_loss: 0.5114, train_bce_loss: 1.4870, train_bce_dl_loss: 0.5114, step time: 0.4321\n",
      "batch: 7/17, train_dl_loss: 0.4494, train_bce_loss: 1.4619, train_bce_dl_loss: 0.4494, step time: 0.3898\n",
      "batch: 8/17, train_dl_loss: 0.4564, train_bce_loss: 1.4640, train_bce_dl_loss: 0.4564, step time: 0.4260\n",
      "batch: 9/17, train_dl_loss: 0.4372, train_bce_loss: 1.4757, train_bce_dl_loss: 0.4372, step time: 0.4261\n",
      "batch: 10/17, train_dl_loss: 0.5546, train_bce_loss: 1.4742, train_bce_dl_loss: 0.5546, step time: 0.4345\n",
      "batch: 11/17, train_dl_loss: 0.4523, train_bce_loss: 1.4648, train_bce_dl_loss: 0.4523, step time: 0.4435\n",
      "batch: 12/17, train_dl_loss: 0.5797, train_bce_loss: 1.4911, train_bce_dl_loss: 0.5797, step time: 0.4241\n",
      "batch: 13/17, train_dl_loss: 0.5872, train_bce_loss: 1.4890, train_bce_dl_loss: 0.5872, step time: 0.3907\n",
      "batch: 14/17, train_dl_loss: 0.4755, train_bce_loss: 1.4818, train_bce_dl_loss: 0.4755, step time: 0.4271\n",
      "batch: 15/17, train_dl_loss: 0.4506, train_bce_loss: 1.4727, train_bce_dl_loss: 0.4506, step time: 0.3785\n",
      "batch: 16/17, train_dl_loss: 0.4760, train_bce_loss: 1.4814, train_bce_dl_loss: 0.4760, step time: 0.4340\n",
      "batch: 17/17, train_dl_loss: 0.4456, train_bce_loss: 1.4712, train_bce_dl_loss: 0.4456, step time: 0.1171\n",
      "LOSS train DiceLoss: 0.4895, LOSS train BCE: 1.4767, LOSS train BCE-DiceLoss: 0.4895, LOSS val DiceLoss: 0.5579, LOSS val BCE: 1.4679, LOSS val BCE-DiceLoss: 0.5579, METRIC val: 0.4103\n",
      "time consuming of epoch 80 is: 450.9571\n"
     ]
    }
   ],
   "source": [
    "train_loop(model=unet_model,\n",
    "           train_loader=train_loader,\n",
    "           val_loader=val_loader,\n",
    "           diceloss_function=dice_loss_fn,\n",
    "           bce_function=bce_loss_fn,\n",
    "           bce_diceloss_function=criterion,\n",
    "           metric=dice_metric,\n",
    "           optimizer=optimizer,\n",
    "           lr_scheduler=lr_scheduler,\n",
    "           config=config,\n",
    "           output_dir=OUTPUT_DIR,\n",
    "           output_file=OUTPUT_FILE,\n",
    "           device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce45284c",
   "metadata": {
    "papermill": {
     "duration": 0.130749,
     "end_time": "2024-08-27T22:29:46.723606",
     "exception": false,
     "start_time": "2024-08-27T22:29:46.592857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plot Training/Validation Losses & Validation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0111ccf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T22:29:46.994686Z",
     "iopub.status.busy": "2024-08-27T22:29:46.994241Z",
     "iopub.status.idle": "2024-08-27T22:29:47.924361Z",
     "shell.execute_reply": "2024-08-27T22:29:47.923278Z"
    },
    "papermill": {
     "duration": 1.070204,
     "end_time": "2024-08-27T22:29:47.926545",
     "exception": false,
     "start_time": "2024-08-27T22:29:46.856341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load txt file\n",
    "path = f\"/kaggle/working/{config['ID']}_train_val_losses.csv\"\n",
    "train_val_losses = pd.read_csv(path)\n",
    "\n",
    "# Plot and Save Train & Val Losses as png in output dir\n",
    "training_plot(train_val_losses, OUTPUT_DIR, config)\n",
    "\n",
    "# Plot and Save Val Metric as png in output dir\n",
    "validation_metric_plot(train_val_losses, OUTPUT_DIR, config)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 4050810,
     "sourceId": 36363,
     "sourceType": "competition"
    },
    {
     "datasetId": 5021316,
     "sourceId": 8604320,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5115113,
     "sourceId": 8620534,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36146.858229,
   "end_time": "2024-08-27T22:29:51.200908",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-27T12:27:24.342679",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
